{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# import all packages needed\n",
    "import string, copy, math\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from base64 import b64decode as decode\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.nn import CrossEntropyLoss, MSELoss, TransformerEncoder, TransformerEncoderLayer\n",
    "import torch.nn.functional as F\n",
    "import torch.fft as fft\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from transformers import GPT2Tokenizer, GPT2Config, GPT2PreTrainedModel, GPT2Model, RobertaTokenizer, RobertaPreTrainedModel, RobertaForCausalLM, RobertaModel, RobertaConfig, EncoderDecoderModel\n",
    "from transformers.modeling_outputs import BaseModelOutputWithPastAndCrossAttentions, CausalLMOutputWithCrossAttentions\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE, Unigram, WordPiece, WordLevel\n",
    "from tokenizers.trainers import BpeTrainer, UnigramTrainer, WordPieceTrainer, WordLevelTrainer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# The only time we need to define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing / Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_data_id</th>\n",
       "      <th>waveform_id</th>\n",
       "      <th>lead_id</th>\n",
       "      <th>lead_byte_count_total</th>\n",
       "      <th>lead_time_offset</th>\n",
       "      <th>waveform_data</th>\n",
       "      <th>lead_sample_count_total</th>\n",
       "      <th>lead_amplitude</th>\n",
       "      <th>lead_data_crc32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1200</td>\n",
       "      <td>0</td>\n",
       "      <td>0x0C000C000C000C000C000C000D000E000E000F001000...</td>\n",
       "      <td>600</td>\n",
       "      <td>4.88</td>\n",
       "      <td>1081043306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1200</td>\n",
       "      <td>0</td>\n",
       "      <td>0x170017001800180018001A001C001D001F0020002200...</td>\n",
       "      <td>600</td>\n",
       "      <td>4.88</td>\n",
       "      <td>2443089335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1200</td>\n",
       "      <td>0</td>\n",
       "      <td>0x580059005C005F006200640066006A006D006F007000...</td>\n",
       "      <td>600</td>\n",
       "      <td>4.88</td>\n",
       "      <td>4278478049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1200</td>\n",
       "      <td>0</td>\n",
       "      <td>0x6B006D007000730077007A007C008000830086008700...</td>\n",
       "      <td>600</td>\n",
       "      <td>4.88</td>\n",
       "      <td>1285239324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1200</td>\n",
       "      <td>0</td>\n",
       "      <td>0x5D005E006100650068006C006F007200750079007B00...</td>\n",
       "      <td>600</td>\n",
       "      <td>4.88</td>\n",
       "      <td>172911202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163367</td>\n",
       "      <td>162505</td>\n",
       "      <td>19892</td>\n",
       "      <td>4</td>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "      <td>0x230020001E001B0018001600130011000E000B000A00...</td>\n",
       "      <td>300</td>\n",
       "      <td>4.88</td>\n",
       "      <td>4035603671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163368</td>\n",
       "      <td>162506</td>\n",
       "      <td>19892</td>\n",
       "      <td>5</td>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "      <td>0x20001F001C001A001800170016001400130011001000...</td>\n",
       "      <td>300</td>\n",
       "      <td>4.88</td>\n",
       "      <td>356224165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163369</td>\n",
       "      <td>162507</td>\n",
       "      <td>19892</td>\n",
       "      <td>6</td>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "      <td>0xE0FFE1FFE3FFE4FFE6FFE8FFE9FFEBFFEDFFEEFFEFFF...</td>\n",
       "      <td>300</td>\n",
       "      <td>4.88</td>\n",
       "      <td>222806952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163370</td>\n",
       "      <td>162508</td>\n",
       "      <td>19892</td>\n",
       "      <td>7</td>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "      <td>0xF1FFF1FFF1FFF1FFF4FFF4FFF5FFF6FFF7FFF7FFF8FF...</td>\n",
       "      <td>300</td>\n",
       "      <td>4.88</td>\n",
       "      <td>2876442497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163371</td>\n",
       "      <td>162509</td>\n",
       "      <td>19892</td>\n",
       "      <td>8</td>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "      <td>0x2A002700240022001F001D001A001700160013001000...</td>\n",
       "      <td>300</td>\n",
       "      <td>4.88</td>\n",
       "      <td>1876080742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163372 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lead_data_id  waveform_id  lead_id  lead_byte_count_total  \\\n",
       "0                  1            2        4                   1200   \n",
       "1                  2            2        5                   1200   \n",
       "2                  3            2        6                   1200   \n",
       "3                  4            2        7                   1200   \n",
       "4                  5            2        8                   1200   \n",
       "...              ...          ...      ...                    ...   \n",
       "163367        162505        19892        4                    600   \n",
       "163368        162506        19892        5                    600   \n",
       "163369        162507        19892        6                    600   \n",
       "163370        162508        19892        7                    600   \n",
       "163371        162509        19892        8                    600   \n",
       "\n",
       "        lead_time_offset                                      waveform_data  \\\n",
       "0                      0  0x0C000C000C000C000C000C000D000E000E000F001000...   \n",
       "1                      0  0x170017001800180018001A001C001D001F0020002200...   \n",
       "2                      0  0x580059005C005F006200640066006A006D006F007000...   \n",
       "3                      0  0x6B006D007000730077007A007C008000830086008700...   \n",
       "4                      0  0x5D005E006100650068006C006F007200750079007B00...   \n",
       "...                  ...                                                ...   \n",
       "163367                 0  0x230020001E001B0018001600130011000E000B000A00...   \n",
       "163368                 0  0x20001F001C001A001800170016001400130011001000...   \n",
       "163369                 0  0xE0FFE1FFE3FFE4FFE6FFE8FFE9FFEBFFEDFFEEFFEFFF...   \n",
       "163370                 0  0xF1FFF1FFF1FFF1FFF4FFF4FFF5FFF6FFF7FFF7FFF8FF...   \n",
       "163371                 0  0x2A002700240022001F001D001A001700160013001000...   \n",
       "\n",
       "        lead_sample_count_total  lead_amplitude  lead_data_crc32  \n",
       "0                           600            4.88       1081043306  \n",
       "1                           600            4.88       2443089335  \n",
       "2                           600            4.88       4278478049  \n",
       "3                           600            4.88       1285239324  \n",
       "4                           600            4.88        172911202  \n",
       "...                         ...             ...              ...  \n",
       "163367                      300            4.88       4035603671  \n",
       "163368                      300            4.88        356224165  \n",
       "163369                      300            4.88        222806952  \n",
       "163370                      300            4.88       2876442497  \n",
       "163371                      300            4.88       1876080742  \n",
       "\n",
       "[163372 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data\n",
    "waveform_data = pd.read_csv(\"data/10000/waveform-10000.csv\")\n",
    "lead_data = pd.read_csv(\"data/10000/lead_data-10000.csv\")\n",
    "diagnosis_data = pd.read_csv(\"data/10000/diagnosis-10000.csv\")\n",
    "\n",
    "lead_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use class base64 to decode waveform data\n",
    "def to_array(wf):\n",
    "    barr = bytearray.fromhex(wf[2:])\n",
    "    vals = np.array(barr)\n",
    "    return vals.view(np.int16).astype(np.float32)\n",
    "\n",
    "\n",
    "# add decoded data as a column to lead dataz\n",
    "waveforms = list(lead_data['waveform_data'])\n",
    "lead_data['decoded_waveform'] = [to_array(i) for i in waveforms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        exam_id  lead_id                                   decoded_waveform\n",
      "249           8        4  [-9.0, -9.0, -8.0, -8.0, -7.0, -7.0, -7.0, -4....\n",
      "250           8        5  [-11.0, -10.0, -6.0, -4.0, -1.0, 3.0, 3.0, 5.0...\n",
      "259           8        6  [4.0, 4.0, 5.0, 7.0, 10.0, 12.0, 12.0, 12.0, 1...\n",
      "265           8        7  [-7.0, -7.0, -5.0, -3.0, 0.0, 2.0, 3.0, 3.0, 2...\n",
      "266           8        8  [-21.0, -20.0, -18.0, -14.0, -11.0, -9.0, -8.0...\n",
      "...         ...      ...                                                ...\n",
      "162619    10001        7  [-132.0, -136.0, -140.0, -133.0, -126.0, -101....\n",
      "162620    10001        8  [-274.0, -293.0, -312.0, -297.0, -282.0, -248....\n",
      "162621    10001       10  [-154.0, -198.0, -242.0, -247.0, -252.0, -224....\n",
      "162622    10001       12  [72.0, 19.0, -34.0, -71.0, -108.0, -129.0, -15...\n",
      "162623    10001       13  [112.0, 72.0, 32.0, -2.0, -36.0, -58.0, -80.0,...\n",
      "\n",
      "[41460 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# merge waveform data and lead data\n",
    "waveform_lead = lead_data.merge(waveform_data, how = \"left\", left_on = \"waveform_id\", right_on = \"waveform_id\", suffixes = (None, None))\n",
    "\n",
    "# sort by exam id and lead id\n",
    "waveform_lead.sort_values(by = [\"waveform_id\", \"lead_id\"], inplace = True)\n",
    "waveform_lead = waveform_lead[waveform_lead.lead_sample_count_total == 2500]\n",
    "waveform_lead = waveform_lead[['exam_id', 'lead_id', 'decoded_waveform']]\n",
    "print(waveform_lead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge waveform data and lead data\n",
    "waveform_lead = lead_data.merge(waveform_data, how = \"left\", left_on = \"waveform_id\", right_on = \"waveform_id\", suffixes = (None, None))\n",
    "\n",
    "# sort by exam id and lead id\n",
    "waveform_lead.sort_values(by = [\"waveform_id\", \"lead_id\"], inplace = True)\n",
    "\n",
    "# adding the diagnosis and labels\n",
    "waveform_and_diag = pd.merge(waveform_lead[['exam_id', 'lead_id', 'decoded_waveform', 'waveform_type_id']], diagnosis_data[[\"exam_id\", \"FullText\", \"original_diagnosis\"]], left_on= \"exam_id\", right_on=\"exam_id\")\n",
    "\n",
    "\n",
    "# concatenate all leads into a single array\n",
    "waveform_lead_concat = waveform_lead.groupby([\"exam_id\", \"waveform_type_id\"])['decoded_waveform'].apply(lambda x: tuple(x)).reset_index()\n",
    "\n",
    "\n",
    "# remove irregular observations, concat tuple into numpy array\n",
    "waveform_lead_concat = waveform_lead_concat[waveform_lead_concat[\"decoded_waveform\"].apply(lambda x: len(x[0]) == 2500)]\n",
    "waveform_lead_concat = waveform_lead_concat[waveform_lead_concat[\"decoded_waveform\"].apply(lambda x: len(x) == 8)]\n",
    "   \n",
    "\n",
    "waveform_lead_concat['decoded_waveform'] = waveform_lead_concat['decoded_waveform'].apply(lambda x: np.vstack(x))\n",
    "waveform_lead_rhythm = waveform_lead_concat[waveform_lead_concat['waveform_type_id'] == 4]\n",
    "\n",
    "def drop_nans(ary):\n",
    "    return np.asarray(ary)[np.logical_not(np.isnan(ary))]\n",
    "\n",
    "def remove_offset(ary):\n",
    "    return np.asarray(ary) - np.mean(drop_nans(ary))\n",
    "\n",
    "\n",
    "def zero_origin(ary):\n",
    "    return ary - ary[0]\n",
    "\n",
    "\n",
    "def signalclipper(ary, magnitude = .015):\n",
    "    return np.clip(ary, magnitude*-1, magnitude)\n",
    "\n",
    "\n",
    "def ECG_filter(ary, low_cut = .5, high_cut = 30):\n",
    "    filter_coefs = signal.butter(4, [low_cut,high_cut], 'bp', fs=1000, output='sos') #500hz sample rate\n",
    "    #ary = remove_offset(ary)\n",
    "    ary = zero_origin(ary)\n",
    "    # ary = np.array(clip_intial_time(ary)).reshape(-1)\n",
    "    ary = drop_nans(ary)\n",
    "    ary = signal.sosfilt(filter_coefs, ary)\n",
    "    #ary = signalclipper(ary)\n",
    "    return ary\n",
    "\n",
    "\n",
    "\n",
    "def normalize(ary):\n",
    "    ary = remove_offset(ary)\n",
    "    ary = ary/np.max(drop_nans(ary))\n",
    "    return ary\n",
    "\n",
    "waveform_lead_rhythm[\"decoded_waveform\"] = waveform_lead_rhythm[\"decoded_waveform\"].apply(lambda value: normalize(value))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "exams = diagnosis_data[\"exam_id\"].unique()\n",
    "\n",
    "diagnosis_data = diagnosis_data[diagnosis_data['original_diagnosis'] == 1].dropna()\n",
    "\n",
    "searchfor = ['previous', 'unconfirmed', 'compared', 'interpretation', 'significant']\n",
    "diagnosis_data = diagnosis_data.loc[diagnosis_data['FullText'].str.contains('|'.join(searchfor)) != 1]\n",
    "\n",
    "diagnosis_data.sort_values(by=[\"exam_id\", \"statement_number\"], inplace=True)\n",
    "diagnoses = []\n",
    "curr_id = 0\n",
    "curr_string = \"\"\n",
    "\n",
    "\n",
    "# making the tokens\n",
    "tokens = set()\n",
    "done = False\n",
    "prefixed_phrase = \"\"\n",
    "for i, row in diagnosis_data.iterrows():\n",
    "    if curr_id == 0:\n",
    "        curr_id = row[\"exam_id\"]\n",
    "    \n",
    "    if (row[\"exam_id\"] != curr_id and curr_string != \"\") or done:        \n",
    "        if curr_id == row[\"exam_id\"]:\n",
    "            continue\n",
    "            \n",
    "        curr_string = curr_string.lower().replace(\" ,\", \"\")\n",
    "        val = [curr_id, curr_string[:-2]]\n",
    "        diagnoses.append(val)\n",
    "        curr_string = \"\"\n",
    "        curr_id = row[\"exam_id\"]\n",
    "        done = False\n",
    "    \n",
    "    if \"*\" in row[\"FullText\"] or \"(\" in row[\"FullText\"]:\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    \n",
    "    if row[\"FullText\"][-4:] == \"with\" or row[\"FullText\"][-1] == \"&\":\n",
    "        prefixed_phrase = row[\"FullText\"].lower() + \" \"\n",
    "        curr_string += row[\"FullText\"] + \" @\"\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    \n",
    "    if curr_string and curr_string[-1] == \"@\":\n",
    "        curr_string = curr_string[:-1]\n",
    "        curr_string += row[\"FullText\"] + \"; \"\n",
    "    else:\n",
    "        curr_string += row[\"FullText\"] + \"; \"\n",
    "    \n",
    "    \n",
    "    tokens.add(prefixed_phrase + row[\"FullText\"].lower().replace(\" ,\", \"\").replace(\", age\", \"age\"))\n",
    "    prefixed_phrase = \"\"\n",
    "    \n",
    "    if curr_string[-5:] == \"ECG; \" or curr_string[-23:] == \"ventricular pacemaker; \":\n",
    "        done = True\n",
    "    \n",
    "diagnosis_df = pd.DataFrame(diagnoses, columns = ['exam_id', 'diagnosis'])\n",
    "waveform_lead_rhythm_diag = pd.merge(left=waveform_lead_rhythm, right=diagnosis_df, left_on='exam_id', right_on='exam_id')\n",
    "\n",
    "\n",
    "\n",
    "# Define all the data here\n",
    "tokens = list(tokens)\n",
    "#full_x = torch.tensor(waveform_lead_rhythm_diag['decoded_waveform']).float().to(device)\n",
    "#full_y = list(waveform_lead_rhythm_diag['diagnosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataLoader():\n",
    "    def __init__(self, df, batch_size):\n",
    "        self.df = df.sample(frac=1)\n",
    "        self.decoded = list(self.df[\"decoded_waveform\"])\n",
    "        self.diagnoses = list(self.df['diagnosis'])\n",
    "        \n",
    "        self.starting_index = 0\n",
    "        self.cap = len(df)\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def generate(self):\n",
    "        # generates both x and y\n",
    "        if self.starting_index + self.batch_size > self.cap:\n",
    "            output1 = torch.tensor(self.decoded[self.starting_index:]).float()\n",
    "            output2 = self.diagnoses[self.starting_index:]\n",
    "            self.starting_index = 0\n",
    "            self.df = self.df.sample(frac=1)\n",
    "            self.decoded = list(self.df[\"decoded_waveform\"])\n",
    "            self.diagnoses = list(self.df['diagnosis'])\n",
    "            \n",
    "        else:\n",
    "            output1 = torch.tensor(self.decoded[self.starting_index:self.starting_index+self.batch_size]).float()\n",
    "            output2 = self.diagnoses[self.starting_index:self.starting_index+self.batch_size]\n",
    "            self.starting_index += self.batch_size\n",
    "        \n",
    "        \n",
    "        return output1, output2\n",
    "\n",
    "loader = dataLoader(waveform_lead_rhythm_diag, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  0, 148,  32, 169,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0, 121, 140,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0, 121, 140,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0, 121,  21,  76,  84,  25,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0, 148, 157,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0, 121,  71,  21, 146, 124,  28,  19,   0,   0,   0,   0,   0],\n",
       "         [  0,  30, 157,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0, 148, 157,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0, 136,  34,  72,  25,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0, 121, 140,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0, 121, 140,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0, 121,  32,   6,  26,  25,   0,   0,   0,   0,   0,   0,   0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(loader.generate()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'anterior infarct': 125,\n",
       " 'indeterminate axis': 104,\n",
       " 'or digitalis effect': 8,\n",
       " 'nonspecific t wave abnormality': 92,\n",
       " 'wide qrs tachycardia': 14,\n",
       " 'incomplete left bundle branch block': 165,\n",
       " 'ventricular pre-excitation, wpw pattern type b': 135,\n",
       " 'biventricular hypertrophy': 33,\n",
       " 'junctional st depression, probably abnormal': 66,\n",
       " 't wave abnormality, consider inferior ischemia': 57,\n",
       " 'normal sinus rhythm': 87,\n",
       " 'marked t wave abnormality, consider lateral ischemia': 146,\n",
       " 'atrial-paced complexes': 116,\n",
       " 'left bundle branch block': 36,\n",
       " 'lateral leads': 54,\n",
       " 'minimal voltage criteria for lvh, may be normal variant': 70,\n",
       " 'left ventricular hypertrophy': 80,\n",
       " 'with premature ventricular or aberrantly conducted complexes': 89,\n",
       " 'marked t wave abnormality, consider inferior ischemia': 16,\n",
       " 'deep q-wave in lead v6,': 88,\n",
       " ', new': 91,\n",
       " 'atrial fibrillation': 97,\n",
       " 'st depression, consider subendocardial injury': 19,\n",
       " 'otherwise normal ecg': 98,\n",
       " 't wave abnormality, consider inferolateral ischemia': 127,\n",
       " 'wide qrs rhythm': 163,\n",
       " 'st elevation consider anterior injury or acute infarct': 167,\n",
       " 'st & marked t wave abnormality, consider lateral ischemia': 171,\n",
       " 'acute pericarditis': 177,\n",
       " ', plus right ventricular hypertrophy': 51,\n",
       " 'with junctional escape complexes': 108,\n",
       " 'with slow ventricular response': 123,\n",
       " 'st & t wave abnormality, consider inferolateral ischemia': 137,\n",
       " 'with premature ventricular complexes': 152,\n",
       " 'av dual-paced complexes': 102,\n",
       " 'undetermined rhythm': 162,\n",
       " 'left atrial rhythm': 156,\n",
       " 'low right atrial bradycardia': 24,\n",
       " 'marked st abnormality, possible septal subendocardial injury': 13,\n",
       " ', possibly acute': 114,\n",
       " 'junctional rhythm': 115,\n",
       " 'inferior injury pattern': 153,\n",
       " 'with 4:1 a-v conduction': 170,\n",
       " \"rsr' or qr pattern in v1 suggests right ventricular conduction delay\": 179,\n",
       " 'with repolarization abnormality': 140,\n",
       " 'and': 4,\n",
       " 'with fusion complexes': 105,\n",
       " 'possible': 85,\n",
       " 'ventricular-paced complexes': 126,\n",
       " 'prolonged qt': 161,\n",
       " 'marked st abnormality, possible anterior subendocardial injury': 181,\n",
       " 'marked st abnormality, possible inferior subendocardial injury': 29,\n",
       " 'marked st abnormality, possible lateral subendocardial injury': 109,\n",
       " 'st & marked t wave abnormality, consider inferior ischemia': 130,\n",
       " 'with premature atrial complexes': 94,\n",
       " 'left anterior fascicular block': 141,\n",
       " 't-wave inversion in': 83,\n",
       " 'incomplete right bundle branch block': 93,\n",
       " 'with sinus arrhythmia': 106,\n",
       " 'sinus tachycardia': 78,\n",
       " 'premature atrial complexes': 157,\n",
       " 'st depression, consider subendocardial injury or digitalis effect': 37,\n",
       " ', may be secondary to qrs abnormality': 84,\n",
       " 'with 2:1 a-v conduction': 49,\n",
       " 'age undetermined': 35,\n",
       " 't wave abnormality, consider anterior ischemia': 96,\n",
       " 'cannot rule out': 23,\n",
       " 'with qrs widening and repolarization abnormality': 112,\n",
       " 'inferior leads': 145,\n",
       " 'st elevation consider lateral injury or acute infarct': 178,\n",
       " 'with qrs widening': 53,\n",
       " 'atrial-sensed ventricular-paced rhythm': 150,\n",
       " 'marked st abnormality, possible anterolateral subendocardial injury': 25,\n",
       " 'abnormal qrs-t angle, consider primary t wave abnormality': 122,\n",
       " 'right bundle branch block': 155,\n",
       " 'unusual p axis and short pr, probable junctional rhythm': 101,\n",
       " 'sinus rhythm': 69,\n",
       " 'with ventricular escape complexes': 129,\n",
       " 'electronic atrial pacemaker': 90,\n",
       " 'accelerated': 160,\n",
       " 'with a-v dissociation': 34,\n",
       " 'left axis deviation': 11,\n",
       " 'sinus bradycardia': 110,\n",
       " 'anterior injury pattern': 9,\n",
       " 'st & t wave abnormality, consider anterior ischemia': 28,\n",
       " 'supraventricular complexes': 21,\n",
       " 'marked st abnormality, possible inferolateral subendocardial injury': 124,\n",
       " 'unusual p axis and short pr, probable junctional tachycardia': 136,\n",
       " 'left posterior fascicular block': 138,\n",
       " 'unusual p axis, possible ectopic atrial bradycardia': 142,\n",
       " 'left atrial enlargement': 168,\n",
       " 'st elevation, consider early repolarization, pericarditis, or injury': 173,\n",
       " 'normal ecg': 134,\n",
       " 'voltage criteria for left ventricular hypertrophy': 75,\n",
       " 'with 2nd degree a-v block': 99,\n",
       " 'marked st abnormality, possible anteroseptal subendocardial injury': 120,\n",
       " 'low voltage qrs': 52,\n",
       " 'st elevation consider inferolateral injury or acute infarct': 103,\n",
       " 'borderline': 119,\n",
       " 'st elevation, consider early repolarization': 180,\n",
       " 'with premature supraventricular complexes': 15,\n",
       " 'right superior axis deviation': 42,\n",
       " 'unusual p axis, possible ectopic atrial rhythm': 44,\n",
       " 'rightward axis': 176,\n",
       " 'anterolateral injury pattern': 18,\n",
       " 'septal infarct': 30,\n",
       " 'st elevation consider anterolateral injury or acute infarct': 86,\n",
       " 'and consecutive': 62,\n",
       " 'right axis deviation': 58,\n",
       " 'junctional bradycardia': 45,\n",
       " 'ventricular-paced rhythm': 139,\n",
       " 'marked sinus bradycardia': 117,\n",
       " 'with 3:1 a-v conduction': 121,\n",
       " 'with aberrant conduction': 164,\n",
       " 'atrial flutter': 175,\n",
       " 'nonspecific st and t wave abnormality': 5,\n",
       " 'lateral injury pattern': 20,\n",
       " 'pulmonary disease pattern': 6,\n",
       " 'abnormal ecg': 67,\n",
       " 'premature supraventricular complexes': 76,\n",
       " 'marked t wave abnormality, consider anterior ischemia': 95,\n",
       " 'non-specific intra-ventricular conduction block': 148,\n",
       " 'with retrograde conduction': 48,\n",
       " 'atrial-paced rhythm': 31,\n",
       " 'with occasional': 131,\n",
       " 'in a pattern of bigeminy': 107,\n",
       " 'with prolonged av conduction': 118,\n",
       " 'fusion complexes': 72,\n",
       " 'wolff-parkinson-white': 166,\n",
       " 'current undetermined rhythm precludes rhythm comparison, needs review': 43,\n",
       " 'with short pr': 2,\n",
       " '[PAD]': 0,\n",
       " 'with complete heart block': 41,\n",
       " 'with sinus/atrial capture': 10,\n",
       " 'with 1st degree a-v block': 60,\n",
       " 'right bundle branch block -or- right ventricular hypertrophy': 111,\n",
       " 'st abnormality, possible digitalis effect': 47,\n",
       " 'st & t wave abnormality, consider inferior ischemia': 22,\n",
       " 'with possible': 26,\n",
       " 'with rapid ventricular response': 56,\n",
       " 'anteroseptal infarct': 68,\n",
       " 'with frequent': 55,\n",
       " 'with a competing junctional pacemaker': 64,\n",
       " 'nonspecific st abnormality': 82,\n",
       " 't wave abnormality, consider lateral ischemia': 100,\n",
       " 'lateral infarct': 81,\n",
       " 'early repolarization': 27,\n",
       " 'biatrial enlargement': 158,\n",
       " 'narrow qrs tachycardia': 182,\n",
       " 'idioventricular rhythm': 39,\n",
       " '[UNK]': 1,\n",
       " 'with undetermined rhythm irregularity': 113,\n",
       " 'marked t wave abnormality, consider anterolateral ischemia': 3,\n",
       " 'consider right ventricular involvement in acute inferior infarct': 77,\n",
       " 'moderate voltage criteria for lvh, may be normal variant': 133,\n",
       " 'with marked sinus arrhythmia': 79,\n",
       " 'inferior infarct': 128,\n",
       " 'st abnormality and': 38,\n",
       " 'borderline ecg': 74,\n",
       " 'junctional st depression, probably normal': 159,\n",
       " 'anterolateral infarct': 32,\n",
       " ', probably digitalis effect': 65,\n",
       " 'av dual-paced rhythm': 151,\n",
       " 'non-specific intra-ventricular conduction delay': 169,\n",
       " 'dextrocardia': 172,\n",
       " 't wave abnormality, consider anterolateral ischemia': 63,\n",
       " 'or': 61,\n",
       " 'st elevation consider inferior injury or acute infarct': 132,\n",
       " 'with blocked': 17,\n",
       " 'electronic ventricular pacemaker': 143,\n",
       " 'biventricular pacemaker detected': 71,\n",
       " 'inferior-posterior infarct': 147,\n",
       " 'with variable a-v block': 40,\n",
       " 'right atrial enlargement': 50,\n",
       " 'right ventricular hypertrophy': 154,\n",
       " 'unusual p axis, possible ectopic atrial tachycardia': 59,\n",
       " 'premature ventricular complexes': 149,\n",
       " 'prominent mid-precordial voltage,': 46,\n",
       " 'supraventricular tachycardia': 174,\n",
       " 'st & t wave abnormality, consider lateral ischemia': 12,\n",
       " 'st & marked t wave abnormality, consider anterolateral ischemia': 7,\n",
       " 'increased r/s ratio in v1, consider early transition or posterior infarct': 73,\n",
       " 'st & t wave abnormality, consider anterolateral ischemia': 144}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating and pretraining tokenizer for the LSTM Encoder-Decoder model\n",
    "\n",
    "class tokenizer(nn.Module):\n",
    "    def __init__(self, vocab, max_len=12):\n",
    "        super(tokenizer, self).__init__()\n",
    "        self.tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
    "        self.trainer = WordLevelTrainer(special_tokens=[\"[PAD]\", \"[UNK]\"])\n",
    "        self.tokenizer.train_from_iterator(np.array(tokens), self.trainer)\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # expects list of sentence fragments, within each sentence separated by ;\n",
    "        input_ids = []\n",
    "        attention_masks = []\n",
    "        for sentence in x:\n",
    "            tokenized = self.tokenizer.encode(sentence.split(\"; \"), is_pretokenized=True)\n",
    "            input_id = [0] + tokenized.ids + [0 for i in range(self.max_len - len(tokenized.ids))]\n",
    "            attention_mask = [1] + tokenized.attention_mask + [1] + [0 for i in range(self.max_len - len(tokenized.attention_mask) - 1)]\n",
    "            input_ids.append(input_id)\n",
    "            attention_masks.append(attention_mask)\n",
    "        return {\"input_ids\": torch.tensor(input_ids).detach(), \"attention_mask\": torch.tensor(attention_masks).detach()}\n",
    "    \n",
    "    def forward_lstm(self, x):\n",
    "        # expects list of sentence fragments, within each sentence separated by ; length is variable\n",
    "        x = copy.deepcopy(x)\n",
    "        for i, sentence in enumerate(x):\n",
    "            x[i] = sentence.split(\"; \")\n",
    "        \n",
    "        output = [self.tokenizer.encode(label, is_pretokenized=True).ids for label in x]\n",
    "        for i in output:\n",
    "            i.append(0)\n",
    "        return output\n",
    "    \n",
    "    \n",
    "    def decode(self, x):\n",
    "        # expects tensor of ids for a single label\n",
    "        return self.tokenizer.decode(list(x))\n",
    "\n",
    "    \n",
    "tokenizer = tokenizer(vocab=tokens) \n",
    "print(len(tokenizer.tokenizer.get_vocab()))\n",
    "tokenizer.tokenizer.get_vocab()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[50, 40, 0],\n",
       " [55, 53, 0],\n",
       " [55, 53, 0],\n",
       " [36, 41, 40, 0],\n",
       " [55, 47, 32, 60, 3, 5, 0],\n",
       " [55, 13, 17, 5, 0],\n",
       " [36, 41, 40, 0],\n",
       " [55, 56, 21, 8, 10, 0],\n",
       " [55, 53, 0],\n",
       " [4, 2, 12, 60, 3, 6, 5, 0],\n",
       " [24, 30, 37, 19, 23, 5, 0],\n",
       " [44, 19, 5, 0],\n",
       " [44, 56, 38, 49, 5, 0],\n",
       " [55, 53, 0],\n",
       " [29, 43, 12, 63, 27, 5, 0],\n",
       " [55, 53, 0],\n",
       " [24, 2, 12, 57, 3, 5, 0],\n",
       " [4, 54, 61, 34, 18, 19, 32, 60, 3, 45, 5, 0],\n",
       " [4, 54, 61, 19, 45, 5, 0],\n",
       " [20, 42, 0],\n",
       " [20, 0],\n",
       " [55, 53, 0],\n",
       " [55, 53, 0],\n",
       " [55, 53, 0],\n",
       " [55, 32, 7, 3, 5, 0],\n",
       " [55, 53, 0],\n",
       " [55, 56, 21, 25, 10, 0],\n",
       " [55, 53, 0],\n",
       " [55, 53, 0],\n",
       " [50, 0],\n",
       " [36, 41, 40, 0],\n",
       " [55, 31, 10, 0],\n",
       " [55, 53, 0],\n",
       " [50, 40, 0],\n",
       " [4, 32, 7, 3, 5, 0],\n",
       " [55, 53, 0],\n",
       " [55, 53, 0],\n",
       " [55, 53, 0],\n",
       " [55, 60, 3, 5, 0],\n",
       " [42, 0],\n",
       " [55, 60, 3, 5, 0],\n",
       " [55, 56, 7, 5, 0],\n",
       " [55, 53, 0],\n",
       " [55, 53, 0],\n",
       " [55, 60, 17, 5, 0],\n",
       " [55, 53, 0],\n",
       " [55, 53, 0],\n",
       " [55, 60, 17, 5, 0],\n",
       " [55, 33, 5, 0],\n",
       " [55, 53, 0],\n",
       " [42, 0],\n",
       " [36, 41, 40, 0]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making labels for the LSTM model\n",
    "token_y_lstm = tokenizer.forward_lstm(full_y)\n",
    "token_y_lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 0, 50, 40,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 55, 53,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 55, 53,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 36, 41, 40,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 55, 47, 32, 60,  3,  5,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 55, 13, 17,  5,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 36, 41, 40,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 55, 56, 21,  8, 10,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 55, 53,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  4,  2, 12, 60,  3,  6,  5,  0,  0,  0,  0,  0],\n",
       "         [ 0, 24, 30, 37, 19, 23,  5,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 44, 19,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 44, 56, 38, 49,  5,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 55, 53,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 29, 43, 12, 63, 27,  5,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 55, 53,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 24,  2, 12, 57,  3,  5,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  4, 54, 61, 34, 18, 19, 32, 60,  3, 45,  5,  0],\n",
       "         [ 0,  4, 54, 61, 19, 45,  5,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 20, 42,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 20,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 55, 53,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 55, 53,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 55, 53,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 55, 32,  7,  3,  5,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 55, 53,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 55, 56, 21, 25, 10,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 55, 53,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 55, 53,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 50,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 36, 41, 40,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 55, 31, 10,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 55, 53,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 50, 40,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  4, 32,  7,  3,  5,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 55, 53,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 55, 53,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 55, 53,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 55, 60,  3,  5,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 42,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 55, 60,  3,  5,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 55, 56,  7,  5,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 55, 53,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 55, 53,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 55, 60, 17,  5,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 55, 53,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 55, 53,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 55, 60, 17,  5,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 55, 33,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 55, 53,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 42,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 36, 41, 40,  0,  0,  0,  0,  0,  0,  0,  0,  0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making labels for the transformer model\n",
    "token_y_transformer = tokenizer(full_y)\n",
    "token_y_transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedder: Conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools to help with the creation of an Embedder\n",
    "\n",
    "# define global max pooling\n",
    "class global_max_pooling_1d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x, _ = torch.max(x, dim = 2)\n",
    "        return(x)\n",
    "\n",
    "# define resblock for neural nets\n",
    "class ResBlock1D(nn.Module):\n",
    "    def __init__(self, num_filters, kernel_size, padding, groups = 1, stride = 1):\n",
    "        super(ResBlock1D, self).__init__()\n",
    "        self.act = nn.ReLU()\n",
    "        self.conv1d_1 = nn.Conv1d(num_filters, num_filters, kernel_size = kernel_size, padding = padding, groups = groups, stride = stride)\n",
    "        self.conv1d_2 = nn.Conv1d(num_filters, num_filters, kernel_size = kernel_size, padding = padding, groups = groups, stride = stride)\n",
    "        self.batch_norm_1 = nn.BatchNorm1d(num_filters)\n",
    "        self.batch_norm_2 = nn.BatchNorm1d(num_filters)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        x = self.batch_norm_1(self.act(self.conv1d_1(x)))\n",
    "        x = self.batch_norm_2(self.act(self.conv1d_2(x)))\n",
    "        return x + res\n",
    "\n",
    "def init_weights(x):\n",
    "    if isinstance(x, nn.Conv1d):\n",
    "        nn.init.kaiming_uniform_(x.weight, mode='fan_in', nonlinearity='relu')\n",
    "        x.bias.data.fill_(0.01)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect an embedder and de-embedder for training (we will then isolate the Encoder portion of this autoencoder as our embedder)\n",
    "class ConvAutoEncoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(ConvAutoEncoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "    def make_encoder(self):\n",
    "        return self.encoder\n",
    "    \n",
    "    def make_decoder(self):\n",
    "        return self.decoder    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedder 1: Conv (AutoEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 2500])\n",
      "torch.Size([1, 64])\n",
      "torch.Size([1, 8, 2500])\n"
     ]
    }
   ],
   "source": [
    "# HYPERPARAMETERS\n",
    "J = 10 # max number of filters per class\n",
    "LR = 1e-3\n",
    "\n",
    "NUM_LAYERS = 5\n",
    "STRIDE = 1\n",
    "LR = 1e-3\n",
    "KER_SIZE = 249\n",
    "PADDING = 124\n",
    "EMBED_DIM = 256\n",
    "NUM_LEADS = 8\n",
    "\n",
    "\n",
    "# build resnet model and display the shape of feed through\n",
    "conv_model = nn.Sequential()\n",
    "init_channels = NUM_LEADS\n",
    "for i in range(NUM_LAYERS):\n",
    "    next_channels = 2 * init_channels\n",
    "    conv_model.add_module('conv_{num}'.format(num = i), nn.Conv1d(in_channels = init_channels, out_channels = next_channels, kernel_size = KER_SIZE, padding = PADDING, stride = STRIDE))\n",
    "    conv_model.add_module('act_{num}'.format(num = i), nn.ELU())\n",
    "    conv_model.add_module('batch_norm_{num}'.format(num = i), nn.BatchNorm1d(next_channels))\n",
    "    conv_model.add_module('res_{num}'.format(num = i), ResBlock1D(num_filters = next_channels, kernel_size = KER_SIZE, padding = PADDING))\n",
    "    conv_model.add_module('act_res_{num}'.format(num = i), nn.ELU())\n",
    "    init_channels = next_channels\n",
    "    \n",
    "conv_model.add_module('conv_fin', nn.Conv1d(in_channels = init_channels, out_channels = EMBED_DIM, kernel_size = KER_SIZE, padding = PADDING))\n",
    "conv_model.add_module('act_fin', nn.ELU())\n",
    "conv_model.add_module('batch_fin', nn.BatchNorm1d(EMBED_DIM))\n",
    "conv_model.apply(init_weights)\n",
    "\n",
    "\n",
    "# Make de-embedder\n",
    "deconv_model = nn.Sequential()\n",
    "init_channels = EMBED_DIM\n",
    "for i in range(NUM_LAYERS):\n",
    "    next_channels = init_channels // 2\n",
    "    deconv_model.add_module('conv_{num}'.format(num = i), nn.ConvTranspose1d(in_channels = init_channels, out_channels = next_channels, kernel_size = KER_SIZE, padding = PADDING, stride = STRIDE))\n",
    "    deconv_model.add_module('act_{num}'.format(num = i), nn.ELU())\n",
    "    deconv_model.add_module('batch_norm_{num}'.format(num = i), nn.BatchNorm1d(next_channels))\n",
    "    deconv_model.add_module('res_{num}'.format(num = i), ResBlock1D(num_filters = next_channels, kernel_size = KER_SIZE, padding = PADDING))\n",
    "    deconv_model.add_module('act_res_{num}'.format(num = i), nn.ELU())\n",
    "    init_channels = next_channels\n",
    "deconv_model.add_module('conv_fin', nn.ConvTranspose1d(in_channels = init_channels, out_channels = NUM_LEADS, kernel_size = KER_SIZE, padding = PADDING))\n",
    "deconv_model.add_module('act_fin', nn.ELU())\n",
    "deconv_model.add_module('batch_fin', nn.BatchNorm1d(NUM_LEADS))\n",
    "\n",
    "\n",
    "class Reshape(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = args\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(self.shape)\n",
    "\n",
    "class ConvModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvModel, self).__init__()\n",
    "        self.KER_SIZE = 9\n",
    "        self.PADDING = 4\n",
    "        self.STRIDE = 5\n",
    "        self.encoder = self.build_encoder()\n",
    "        self.decoder = self.build_decoder()\n",
    "    \n",
    "    \n",
    "    def build_encoder(self):\n",
    "        encoder = nn.Sequential()\n",
    "        init_channels = 8\n",
    "        KER_SIZE, PADDING, STRIDE = self.KER_SIZE, self.PADDING, self.STRIDE\n",
    "        for i in range(4):\n",
    "            next_channels = 3 * init_channels\n",
    "            encoder.add_module('conv_{num}'.format(num = i), nn.Conv1d(in_channels = init_channels, out_channels = next_channels, kernel_size = KER_SIZE, padding = PADDING, stride = STRIDE))\n",
    "            encoder.add_module('act_{num}'.format(num = i), nn.ELU())\n",
    "            encoder.add_module('batch_norm_{num}'.format(num = i), nn.BatchNorm1d(next_channels))\n",
    "            encoder.add_module('res_{num}'.format(num = i), ResBlock1D(num_filters = next_channels, kernel_size = KER_SIZE, padding = PADDING))\n",
    "            encoder.add_module('act_res_{num}'.format(num = i), nn.ELU())\n",
    "            init_channels = next_channels\n",
    "        \n",
    "        encoder.add_module('flattener', nn.Flatten())\n",
    "        encoder.add_module(\"linear\", nn.Linear(2592, 648)) \n",
    "        encoder.add_module('act_{num}'.format(num = i+1), nn.ELU())\n",
    "        #encoder.add_module('batch_norm_{num}'.format(num = i+1), nn.BatchNorm1d(num_features = 648))\n",
    "        encoder.add_module(\"linear2\", nn.Linear(648, 64)) \n",
    "        return encoder\n",
    "    \n",
    "    \n",
    "    \n",
    "    def build_decoder(self):\n",
    "        KER_SIZE, PADDING, STRIDE = self.STRIDE, 0, self.STRIDE\n",
    "        \n",
    "        decoder = nn.Sequential()\n",
    "        init_channels = 648\n",
    "        decoder.add_module(\"linear\", nn.Linear(64, 648))\n",
    "        decoder.add_module('act_-1', nn.ELU())\n",
    "        #decoder.add_module('batch_norm_-1', nn.BatchNorm1d(648))\n",
    "        decoder.add_module(\"linear2\", nn.Linear(648, 2592)) \n",
    "        decoder.add_module(\"reshape\", Reshape(-1, 648, 4))\n",
    "        decoder.add_module('act_-2', nn.ELU())\n",
    "        #decoder.add_module('batch_norm_-2', nn.BatchNorm1d(648))\n",
    "        \n",
    "        for i in range(4):\n",
    "            next_channels = init_channels // 3\n",
    "            decoder.add_module('conv_{num}'.format(num = i), nn.ConvTranspose1d(in_channels = init_channels, out_channels = next_channels, kernel_size = KER_SIZE, padding = PADDING, stride = STRIDE))\n",
    "            decoder.add_module('act_{num}'.format(num = i), nn.ELU())\n",
    "            decoder.add_module('batch_norm_{num}'.format(num = i), nn.BatchNorm1d(next_channels))\n",
    "            decoder.add_module('res_{num}'.format(num = i), ResBlock1D(num_filters = next_channels, kernel_size = self.KER_SIZE, padding = self.PADDING))\n",
    "            decoder.add_module('act_res_{num}'.format(num = i), nn.ELU())\n",
    "            init_channels = next_channels\n",
    "        #decoder.add_module('conv_fin', nn.ConvTranspose1d(in_channels = init_channels, out_channels = 8, kernel_size = KER_SIZE, padding = PADDING))\n",
    "        #decoder.add_module('act_fin', nn.ELU())\n",
    "        #decoder.add_module('batch_fin', nn.BatchNorm1d(NUM_LEADS))\n",
    "        #decoder.add_module(\"linear\", nn.Linear(2188, 2500))\n",
    "        \n",
    "        return decoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "    def make_encoder(self):\n",
    "        return self.encoder\n",
    "    \n",
    "    def make_decoder(self):\n",
    "        return self.decoder    \n",
    "\n",
    "    \n",
    "encoder = ConvModel().make_encoder()\n",
    "decoder = ConvModel().make_decoder()\n",
    "\n",
    "inp = loader.generate()[0][:1]\n",
    "\n",
    "print(inp.shape)\n",
    "x = encoder(inp)\n",
    "print(x.shape)\n",
    "x = decoder(x)\n",
    "print(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0265, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0295, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0266, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0274, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0271, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0266, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0262, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0259, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0258, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0256, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0255, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0252, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0251, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0249, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0247, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0245, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0244, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0243, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0242, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0240, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0239, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0238, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0237, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0235, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0234, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0233, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0232, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0231, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0230, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0228, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0227, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0226, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0225, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0224, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0223, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0222, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0221, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0220, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0219, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0218, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0217, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0216, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0215, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0215, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0214, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0213, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0212, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0211, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0210, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0209, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0208, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0208, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0207, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0206, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0205, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0204, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0203, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0203, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0202, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0201, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0200, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0199, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0199, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0198, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0197, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0196, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0195, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0195, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0194, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0193, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0192, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0192, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0191, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0190, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0189, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0189, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0188, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0187, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0186, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0186, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0185, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0184, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0183, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0183, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0182, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0181, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0181, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0180, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0179, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0178, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0178, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0177, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0176, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0176, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0175, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0174, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0173, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0173, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0172, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Optional AutoEncoder Pretraining of the Embedder\n",
    "\n",
    "# Training Params\n",
    "#auto_model = ConvModel().to(device)\n",
    "auto_optimizer = torch.optim.Adam(auto_model.parameters(), lr = 1e-4)\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "# Set this to a non-zero number for pretraining\n",
    "\n",
    "epochs = 100\n",
    "#full_x, output = loader.generate()\n",
    "for i in range(epochs):\n",
    "    auto_optimizer.zero_grad()\n",
    "    outputs = auto_model(full_x)\n",
    "    loss = loss_function(outputs, full_x)\n",
    "    loss.backward(retain_graph=True)\n",
    "    auto_optimizer.step()\n",
    "    print(loss)\n",
    "        \n",
    "# Saving/loading weights\n",
    "torch.save(auto_model.state_dict(), 'model/autoencoder.pt')\n",
    "auto_model.load_state_dict(torch.load('model/autoencoder.pt'))\n",
    "\n",
    "# Embedder for our other models\n",
    "conv_embedder = auto_model.make_encoder()\n",
    "\n",
    "# If powerful enough, then can freeze weights\n",
    "if epochs > 100:\n",
    "    for param in conv_embedder.params():\n",
    "        param.requires_grad = False\n",
    "\n",
    "torch.save(conv_embedder.state_dict(), \"model/embedder.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0878,  0.0878,  0.0878,  ..., -0.2754, -0.2665, -0.2665],\n",
      "         [ 0.1409,  0.1409,  0.1409,  ...,  0.3092,  0.3180,  0.3180],\n",
      "         [-0.0717, -0.0628, -0.0540,  ...,  0.0700,  0.0612,  0.0612],\n",
      "         ...,\n",
      "         [ 0.5306,  0.5306,  0.5306,  ...,  0.3269,  0.3446,  0.3446],\n",
      "         [ 0.1586,  0.1586,  0.1586,  ...,  0.2826,  0.2915,  0.2915],\n",
      "         [-0.0362, -0.0362, -0.0362,  ..., -0.1691, -0.1425, -0.1425]]])\n",
      "torch.Size([1, 8, 2500])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = full_x[:1]\n",
    "encoder = auto_model.make_encoder()\n",
    "print(x)\n",
    "print(auto_model(x).shape)\n",
    "\n",
    "y_vals = auto_model(x)[0][0].detach().numpy()\n",
    "fig, axs = plt.subplots(2)\n",
    "axs[0].plot(np.arange(2500), x[0][0])\n",
    "axs[1].plot(np.arange(2500), y_vals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedder 2: Window Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowEmbedder(nn.Module):\n",
    "    def __init__(self, slice_size=25, embed_dim=512, num_leads=8):\n",
    "        super(WindowEmbedder, self).__init__()\n",
    "        self.slice_size = slice_size # should divide 2500\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_leads = num_leads\n",
    "        self.linear = nn.Linear(slice_size * num_leads, embed_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # assumes the input is batch, then embed_dim, then seq_length\n",
    "        if len(x.shape) == 2: # when input is 1 by 1\n",
    "            x = x.unsqueeze(0)\n",
    "        flattened_slice_length = self.slice_size * self.num_leads\n",
    "        x = x.transpose(2, 1)\n",
    "        x = x.contiguous().view(-1, 2500 // self.slice_size, flattened_slice_length)\n",
    "        x = self.linear(x).transpose(1, 0)\n",
    "        return x\n",
    "    \n",
    "    def forward_no_lin(self, x):\n",
    "        if len(x.shape) == 2: # when input is 1 by 1\n",
    "            x = x.unsqueeze(0)\n",
    "        flattened_slice_length = self.slice_size * self.num_leads\n",
    "        x = x.transpose(2, 1)\n",
    "        x = x.contiguous().view(-1, 2500 // self.slice_size, flattened_slice_length)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Encoder-Decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters \n",
    "hidden_layers = 1024\n",
    "embedding_dim = EMBED_DIM\n",
    "word_list_length = 65\n",
    "start_token = end_token = 0\n",
    "seq_length = 13\n",
    "\n",
    "class Global_Dot_Attention(nn.Module):\n",
    "    def __init__(self, enc_h, dec_h):\n",
    "        super(Global_Dot_Attention, self).__init__()\n",
    "        self.h_dim = dec_h\n",
    "        self.linear_out = nn.Linear(enc_h + dec_h, dec_h)\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "    def score(self, enc_o, dec_o):\n",
    "        scores = torch.bmm(dec_o.transpose(1, 0), enc_o.permute(1, 2, 0))\n",
    "        return torch.div(scores, math.sqrt(self.h_dim))\n",
    "    \n",
    "    def forward(self, h_dec, h_enc):\n",
    "        align_scores = self.score(h_enc, h_dec)\n",
    "        batch_s, len_d, len_e = align_scores.size()\n",
    "            \n",
    "        align_vec = self.softmax(align_scores.view(batch_s * len_d, len_e))\n",
    "        align_vec = align_vec.view(batch_s, len_d, len_e)\n",
    "        \n",
    "        cont_vec = torch.bmm(align_vec, h_enc.transpose(1, 0))\n",
    "        \n",
    "        c_d_cat = torch.cat((cont_vec, h_dec.transpose(1, 0)), 2).view(batch_s * len_d, -1)\n",
    "        h_dec_attn = torch.tanh(self.linear_out(c_d_cat)).view(batch_s, len_d, -1)\n",
    "        \n",
    "        return h_dec_attn\n",
    "\n",
    "    \n",
    "class LSTM_Encoder(nn.Module):\n",
    "    def __init__(self, h_dim, e_dim):\n",
    "        super(LSTM_Encoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(e_dim, h_dim, num_layers = 8) # Change to LSTMCell\n",
    "        \n",
    "    def forward(self, x, hidden, cell_state):\n",
    "        \n",
    "        if hidden is None and cell_state is None:\n",
    "            final, comp = self.lstm(x)\n",
    "        else:\n",
    "            final, comp = self.lstm(x, (hidden, cell_state))\n",
    "        hid, cell = comp\n",
    "        return final, hid, cell\n",
    "    \n",
    "    \n",
    "    def initial_hidden_cell(self):\n",
    "        return torch.zeros(8, 52, 1024), torch.zeros(8, 52, 1024)\n",
    "\n",
    "\n",
    "class LSTM_Decoder(nn.Module):\n",
    "    def __init__(self, h_dim, e_dim, word_list_length, max_length = seq_length):\n",
    "        super(LSTM_Decoder, self).__init__()\n",
    "        self.emb = nn.Embedding(word_list_length, e_dim)\n",
    "        self.attention = Global_Dot_Attention(h_dim, h_dim)\n",
    "        self.lstm = nn.LSTM(e_dim, h_dim, num_layers = 8)\n",
    "        self.out = nn.Linear(h_dim, word_list_length)\n",
    "        \n",
    "        self.max_length = max_length\n",
    "        self.e_dim = e_dim\n",
    "        \n",
    "    def forward(self, x, hidden, cell_state, encoder_outputs):\n",
    "        if len(x.size()) == 1:\n",
    "            x = x.unsqueeze(0)\n",
    "        batch_s, len_seq = x.size()\n",
    "        seq_embedded = self.emb(x).view(len_seq, batch_s, -1)   \n",
    "        dec_h, dec_hidden  = self.lstm(seq_embedded, (hidden, cell_state)) # Put into an iterative for loop\n",
    "        \n",
    "        att_dec = self.attention(dec_h, encoder_outputs)\n",
    "        batch_s, len_d, _ = att_dec.size()\n",
    "        dec_h_out = self.out(att_dec.view(batch_s * len_d, -1))\n",
    "        dec_h_out = dec_h_out.view(batch_s, len_d, -1)\n",
    "        return dec_h_out, dec_hidden\n",
    "\n",
    "    def generate(self, x, hidden, cell_state):\n",
    "        soft_max = nn.Softmax()\n",
    "        hidden_dec, cell_dec = hidden, cell_state\n",
    "        batch = x.shape[1]\n",
    "        decoder_input = torch.zeros(batch, 1, dtype = torch.long)\n",
    "        results = decoder_input\n",
    "        \n",
    "        for j in range(self.max_length):\n",
    "            logit, dec_hidden = self.forward(decoder_input, hidden_dec, cell_dec, x)\n",
    "            hidden_dec, cell_dec = dec_hidden\n",
    "            logit = soft_max(logit.squeeze(1))\n",
    "            _, val = logit.topk(1, dim = 1)\n",
    "            decoder_input = val.detach()\n",
    "            print(decoder_input)\n",
    "            results = torch.cat((results, decoder_input))\n",
    "            if j != 0 and decoder_input[0] == 0:\n",
    "                break\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def generate_beam(self, x, hidden, cell_state, k=3):\n",
    "        # assumes x is a single encoder output\n",
    "        soft_max = nn.LogSoftmax()\n",
    "        hidden_dec, cell_dec = hidden, cell_state\n",
    "        batch = x.shape[1]\n",
    "        decoder_input = torch.zeros(batch, 1, dtype = torch.long)\n",
    "        # Each candidate is [seq indices, loglikelihood, hidden states]\n",
    "        candidates = [[None, 0.0, None]]\n",
    "        true_candidates = []\n",
    "        # populate candidates for the first iteration\n",
    "        logit, dec_hidden = self.forward(decoder_input, hidden_dec, cell_dec, x)\n",
    "        logit = soft_max(logit.squeeze(1))\n",
    "        val, idx = logit.topk(k, dim = 1)\n",
    "        \n",
    "        for i, candidate in enumerate(candidates):\n",
    "            candidate[0] = idx[0][0].unsqueeze(0).unsqueeze(0) # always 0\n",
    "             \n",
    "            candidate[2] = dec_hidden\n",
    "        \n",
    "        # now start populating the\n",
    "        for j in range(1, self.max_length):\n",
    "            if len(true_candidates) == k: break\n",
    "            \n",
    "            new_candidates = []\n",
    "            for candidate in candidates:\n",
    "                \n",
    "                hidden_dec, cell_dec = candidate[2]\n",
    "                decoder_input = candidate[0][-1]\n",
    "                \n",
    "                logit, dec_hidden = self.forward(decoder_input, hidden_dec, cell_dec, x)\n",
    "                logit = soft_max(logit.squeeze(1))\n",
    "                val, idx = logit.topk(k, dim = 1)\n",
    "                \n",
    "                for i in range(k):\n",
    "                    if idx[0][i] == 0:\n",
    "                        true_candidates.append( [torch.cat((candidate[0], idx[0][i].unsqueeze(0).unsqueeze(0))), candidate[1]+ val[0][i]] )\n",
    "                        continue\n",
    "                \n",
    "                    new_candidates.append( [torch.cat((candidate[0], idx[0][i].unsqueeze(0).unsqueeze(0))), candidate[1]+ val[0][i], dec_hidden] )\n",
    "            \n",
    "            new_candidates.sort(reverse=True, key = lambda vals: vals[1])\n",
    "            \n",
    "            candidates = new_candidates[:k-len(true_candidates)]\n",
    "        \n",
    "        \n",
    "        \n",
    "        true_candidates.sort(reverse=True, key = lambda vals: vals[1])\n",
    "        return true_candidates[0][0]\n",
    "        \n",
    "\n",
    "        \n",
    "def accuracy_score(pred, lab):\n",
    "    soft_max = nn.Softmax()\n",
    "    _, pred = soft_max(pred).topk(1)\n",
    "    match = pred.squeeze(1) == lab\n",
    "    accuracy = torch.mean(match.type(torch.float))\n",
    "    return accuracy\n",
    "\n",
    "def train(x, y, attn_mask, embedder, encoder, decoder, emb_optimizer, enc_optimizer, dec_optimizer):\n",
    "    hidden_enc, cell_enc = encoder.initial_hidden_cell()\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    emb_optimizer.zero_grad()\n",
    "    enc_optimizer.zero_grad()\n",
    "    dec_optimizer.zero_grad()\n",
    "    \n",
    "    x = embedder(x)\n",
    "    \n",
    "    enc_out, hidden_enc, cell_enc = encoder(x, hidden_enc, cell_enc)\n",
    "    \n",
    "    target_lab = y\n",
    "    \n",
    "    decoder_out, dec_hidden = decoder(target_lab, hidden_enc, cell_enc, enc_out)\n",
    "    batch_s, len_seq, o_size = decoder_out.size()\n",
    "    outputs_merged = decoder_out.view(batch_s * len_seq, o_size)\n",
    "\n",
    "    attn_mask_adj = attn_mask.unsqueeze(2).repeat([1, 1, o_size])\n",
    "    outputs_masked = torch.masked_select(decoder_out, attn_mask_adj).view(-1, o_size)\n",
    "        \n",
    "    target_lab = torch.masked_select(target_lab, attn_mask)\n",
    "    \n",
    "    loss = loss_fn(outputs_masked, target_lab)\n",
    "    loss.backward()\n",
    "        \n",
    "    emb_optimizer.step()\n",
    "    enc_optimizer.step()\n",
    "    dec_optimizer.step()\n",
    "    \n",
    "    return loss.item(), outputs_masked, target_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielbang/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/danielbang/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "token_y = torch.tensor(token_y_transformer['input_ids'], dtype = torch.long)\n",
    "mask = torch.tensor(token_y_transformer['attention_mask'], dtype = torch.bool)\n",
    "\n",
    "lstm_embedder = WindowEmbedder(embed_dim=embedding_dim)\n",
    "lstm_encoder = LSTM_Encoder(hidden_layers, embedding_dim)\n",
    "lstm_decoder = LSTM_Decoder(hidden_layers, embedding_dim, word_list_length)\n",
    "\n",
    "lstm_embedder.load_state_dict(torch.load('model/lstm_embedder.pt'))\n",
    "lstm_encoder.load_state_dict(torch.load('model/lstm_encoder.pt'))\n",
    "lstm_decoder.load_state_dict(torch.load('model/lstm_decoder.pt'))\n",
    "\n",
    "\n",
    "emb_optimizer = torch.optim.Adam(lstm_embedder.parameters(), lr = 1e-3)\n",
    "enc_optimizer = torch.optim.Adam(lstm_encoder.parameters(), lr = 1e-3)\n",
    "dec_optimizer = torch.optim.Adam(lstm_decoder.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielbang/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/Users/danielbang/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:151: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 \n",
      "loss:  0.13229618966579437 \n",
      "accuracy:  tensor(0.9890) \n",
      "\n",
      "epoch:  1 \n",
      "loss:  0.1712910234928131 \n",
      "accuracy:  tensor(0.9596) \n",
      "\n",
      "epoch:  2 \n",
      "loss:  0.13127711415290833 \n",
      "accuracy:  tensor(0.9890) \n",
      "\n",
      "epoch:  3 \n",
      "loss:  0.1357884407043457 \n",
      "accuracy:  tensor(0.9890) \n",
      "\n",
      "epoch:  4 \n",
      "loss:  0.147406667470932 \n",
      "accuracy:  tensor(0.9779) \n",
      "\n",
      "epoch:  5 \n",
      "loss:  0.14616766571998596 \n",
      "accuracy:  tensor(0.9816) \n",
      "\n",
      "epoch:  6 \n",
      "loss:  0.13975095748901367 \n",
      "accuracy:  tensor(0.9816) \n",
      "\n",
      "epoch:  7 \n",
      "loss:  0.13493835926055908 \n",
      "accuracy:  tensor(0.9853) \n",
      "\n",
      "epoch:  8 \n",
      "loss:  0.13152259588241577 \n",
      "accuracy:  tensor(0.9890) \n",
      "\n",
      "epoch:  9 \n",
      "loss:  0.12979936599731445 \n",
      "accuracy:  tensor(0.9890) \n",
      "\n",
      "epoch:  10 \n",
      "loss:  0.1297115534543991 \n",
      "accuracy:  tensor(0.9890) \n",
      "\n",
      "epoch:  11 \n",
      "loss:  0.13045640289783478 \n",
      "accuracy:  tensor(0.9890) \n",
      "\n",
      "epoch:  12 \n",
      "loss:  0.13094943761825562 \n",
      "accuracy:  tensor(0.9853) \n",
      "\n",
      "epoch:  13 \n",
      "loss:  0.13042865693569183 \n",
      "accuracy:  tensor(0.9853) \n",
      "\n",
      "epoch:  14 \n",
      "loss:  0.12886342406272888 \n",
      "accuracy:  tensor(0.9890) \n",
      "\n",
      "epoch:  15 \n",
      "loss:  0.1267756223678589 \n",
      "accuracy:  tensor(0.9890) \n",
      "\n",
      "epoch:  16 \n",
      "loss:  0.12474989891052246 \n",
      "accuracy:  tensor(0.9890) \n",
      "\n",
      "epoch:  17 \n",
      "loss:  0.12314623594284058 \n",
      "accuracy:  tensor(0.9890) \n",
      "\n",
      "epoch:  18 \n",
      "loss:  0.12205465883016586 \n",
      "accuracy:  tensor(0.9890) \n",
      "\n",
      "epoch:  19 \n",
      "loss:  0.12137174606323242 \n",
      "accuracy:  tensor(0.9890) \n",
      "\n",
      "epoch:  20 \n",
      "loss:  0.12090835720300674 \n",
      "accuracy:  tensor(0.9890) \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-dfcb87a28b49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlstm_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_histogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_histogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m'_enc'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/grad'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/utils/tensorboard/writer.py\u001b[0m in \u001b[0;36madd_histogram\u001b[0;34m(self, tag, values, global_step, bins, walltime, max_bins)\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_bins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         self._get_file_writer().add_summary(\n\u001b[0;32m--> 430\u001b[0;31m             histogram(tag, values, bins, max_bins=max_bins), global_step, walltime)\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     def add_histogram_raw(self, tag, min, max, num, sum, sum_squares,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/utils/tensorboard/summary.py\u001b[0m in \u001b[0;36mhistogram\u001b[0;34m(name, values, bins, max_bins)\u001b[0m\n\u001b[1;32m    298\u001b[0m     \"\"\"\n\u001b[1;32m    299\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m     \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_histogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_bins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mSummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhisto\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/utils/tensorboard/summary.py\u001b[0m in \u001b[0;36mmake_histogram\u001b[0;34m(values, bins, max_bins)\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0msum_sq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     return HistogramProto(min=values.min(),\n\u001b[0;32m--> 342\u001b[0;31m                           \u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m                           \u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                           \u001b[0msum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     37\u001b[0m def _amax(a, axis=None, out=None, keepdims=False,\n\u001b[1;32m     38\u001b[0m           initial=_NoValue, where=True):\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m def _amin(a, axis=None, out=None, keepdims=False,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('runs/lstm_encoder_decoder_final')\n",
    "\n",
    "\n",
    "\n",
    "emb_optimizer = torch.optim.Adam(lstm_embedder.parameters(), lr = 1e-5)\n",
    "enc_optimizer = torch.optim.Adam(lstm_encoder.parameters(), lr = 1e-5)\n",
    "dec_optimizer = torch.optim.Adam(lstm_decoder.parameters(), lr = 1e-5)\n",
    "\n",
    "for epoch in range(340):\n",
    "    loss, pred, lab = train(full_x, token_y, mask, lstm_embedder, lstm_encoder, lstm_decoder, emb_optimizer, enc_optimizer, dec_optimizer)\n",
    "    \n",
    "    accuracy = accuracy_score(pred, lab)\n",
    "    print(\"epoch: \", epoch, \"\\nloss: \", loss, \"\\naccuracy: \", accuracy, \"\\n\")\n",
    "        \n",
    "    if epoch == 50:\n",
    "        emb_optimizer = torch.optim.Adam(lstm_embedder.parameters(), lr = 1e-4)\n",
    "        enc_optimizer = torch.optim.Adam(lstm_encoder.parameters(), lr = 1e-4)\n",
    "        dec_optimizer = torch.optim.Adam(lstm_decoder.parameters(), lr = 1e-4)\n",
    "\n",
    "    if epoch == 110:\n",
    "        emb_optimizer = torch.optim.Adam(lstm_embedder.parameters(), lr = 1e-5)\n",
    "        enc_optimizer = torch.optim.Adam(lstm_encoder.parameters(), lr = 1e-5)\n",
    "        dec_optimizer = torch.optim.Adam(lstm_decoder.parameters(), lr = 1e-5)\n",
    "\n",
    "    if epoch == 260:\n",
    "        emb_optimizer = torch.optim.Adam(lstm_embedder.parameters(), lr = 1e-6)\n",
    "        enc_optimizer = torch.optim.Adam(lstm_encoder.parameters(), lr = 1e-6)\n",
    "        dec_optimizer = torch.optim.Adam(lstm_decoder.parameters(), lr = 1e-6)\n",
    "\n",
    "    if epoch == 300:\n",
    "        emb_optimizer = torch.optim.Adam(lstm_embedder.parameters(), lr = 1e-7)\n",
    "        enc_optimizer = torch.optim.Adam(lstm_encoder.parameters(), lr = 1e-7)\n",
    "        dec_optimizer = torch.optim.Adam(lstm_decoder.parameters(), lr = 1e-7)\n",
    "\n",
    "       \n",
    "    for tag, value in lstm_embedder.named_parameters():\n",
    "        tag = tag.replace('.', '/')\n",
    "        writer.add_histogram(tag, value.data.cpu().numpy(), epoch)\n",
    "        if value.grad is None:\n",
    "            writer.add_histogram(tag+ '_emb' + '/grad', 0, epoch)           \n",
    "        else:\n",
    "            writer.add_histogram(tag+ '_emb' + '/grad', value.grad.data.cpu().numpy(), epoch)           \n",
    "    \n",
    "    for tag, value in lstm_encoder.named_parameters():\n",
    "        tag = tag.replace('.', '/')\n",
    "        writer.add_histogram(tag, value.data.cpu().numpy(), epoch)\n",
    "        if value.grad is None:\n",
    "            writer.add_histogram(tag+ '_enc' + '/grad', 0, epoch)           \n",
    "        else:\n",
    "            writer.add_histogram(tag+ '_enc' + '/grad', value.grad.data.cpu().numpy(), epoch)\n",
    "    \n",
    "    \n",
    "    for tag, value in lstm_decoder.named_parameters():\n",
    "        tag = tag.replace('.', '/')\n",
    "        writer.add_histogram(tag, value.data.cpu().numpy(), epoch)\n",
    "        if value.grad is None:\n",
    "            writer.add_histogram(tag+'_dec' + '/grad', 0, epoch)           \n",
    "        else:\n",
    "            writer.add_histogram(tag+'_dec' + '/grad', value.grad.data.cpu().numpy(), epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lstm_embedder.state_dict(), 'model/lstm_embedder.pt')\n",
    "torch.save(lstm_encoder.state_dict(), 'model/lstm_encoder.pt')\n",
    "torch.save(lstm_decoder.state_dict(), 'model/lstm_decoder.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth:  sinus bradycardia otherwise normal ecg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielbang/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/Users/danielbang/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:108: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/Users/danielbang/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:127: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  sinus bradycardia otherwise normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "predicted:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "predicted:  sinus rhythm with marked sinus arrhythmia otherwise normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  sinus rhythm with marked sinus arrhythmia otherwise normal ecg\n",
      "predicted:  sinus rhythm with marked sinus arrhythmia\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm with sinus arrhythmia cannot rule out inferior infarct age undetermined abnormal ecg\n",
      "predicted:  normal sinus rhythm with sinus arrhythmia cannot rule out inferior infarct age undetermined\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm st & t wave abnormality, consider anterior ischemia prolonged qt abnormal ecg\n",
      "predicted:  normal sinus rhythm st & t wave abnormality, consider anterior ischemia\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  sinus rhythm with marked sinus arrhythmia otherwise normal ecg\n",
      "predicted:  sinus rhythm with marked sinus arrhythmia otherwise normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm possible left atrial enlargement incomplete left bundle branch block borderline ecg\n",
      "predicted:  normal sinus rhythm possible prolonged qt\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "predicted:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  sinus tachycardia left axis deviation pulmonary disease pattern inferior infarct age undetermined st & t wave abnormality, consider lateral ischemia abnormal ecg\n",
      "predicted:  sinus tachycardia left axis deviation pulmonary disease pattern inferior infarct age undetermined st & t wave abnormality, consider lateral ischemia\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  atrial fibrillation with rapid ventricular response with premature ventricular or aberrantly conducted complexes right bundle branch block left posterior fascicular block abnormal ecg\n",
      "predicted:  normal sinus rhythm with rapid ventricular response with premature ventricular or aberrantly conducted complexes right bundle branch block left posterior fascicular block\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  undetermined rhythm right bundle branch block abnormal ecg\n",
      "predicted:  av sequential or dual chamber electronic pacemaker\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  undetermined rhythm possible right ventricular hypertrophy nonspecific t wave abnormality abnormal ecg\n",
      "predicted:  undetermined rhythm possible right ventricular hypertrophy nonspecific t wave abnormality\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "predicted:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  electronic atrial pacemaker indeterminate axis pulmonary disease pattern st elevation consider anterolateral injury or acute infarct st elevation consider inferior injury or acute infarct abnormal ecg\n",
      "predicted:  electronic atrial pacemaker indeterminate axis pulmonary disease pattern st elevation consider anterolateral injury or acute infarct st elevation consider inferior injury or acute infarct abnormal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "predicted:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  atrial fibrillation left axis deviation pulmonary disease pattern septal infarct age undetermined abnormal ecg\n",
      "predicted:  atrial fibrillation left axis deviation pulmonary disease pattern septal infarct age undetermined abnormal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  sinus tachycardia with short pr with premature supraventricular complexes and fusion complexes right bundle branch block cannot rule out inferior infarct age undetermined t wave abnormality, consider lateral ischemia abnormal ecg\n",
      "predicted:  sinus tachycardia with short pr with premature supraventricular complexes and fusion complexes right bundle branch block cannot rule out inferior infarct age undetermined t wave abnormality, consider lateral ischemia\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  sinus tachycardia with short pr with premature supraventricular complexes right bundle branch block t wave abnormality, consider lateral ischemia abnormal ecg\n",
      "predicted:  sinus tachycardia with short pr with premature supraventricular complexes right bundle branch block t wave abnormality, consider lateral ischemia\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  av sequential or dual chamber electronic pacemaker electronic ventricular pacemaker\n",
      "predicted:  av sequential or dual chamber electronic pacemaker electronic ventricular pacemaker\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  av sequential or dual chamber electronic pacemaker\n",
      "predicted:  av sequential or dual chamber electronic pacemaker\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "predicted:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "predicted:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "predicted:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm cannot rule out anterior infarct age undetermined abnormal ecg\n",
      "predicted:  normal sinus rhythm cannot rule out anterior infarct age undetermined\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "predicted:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm possible left atrial enlargement incomplete right bundle branch block borderline ecg\n",
      "predicted:  normal sinus rhythm possible prolonged qt abnormal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "predicted:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "predicted:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  sinus bradycardia\n",
      "predicted:  electronic ventricular pacemaker\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  sinus rhythm with marked sinus arrhythmia otherwise normal ecg\n",
      "predicted:  sinus rhythm with marked sinus arrhythmia otherwise normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm minimal voltage criteria for lvh, may be normal variant borderline ecg\n",
      "predicted:  normal sinus rhythm minimal voltage criteria for lvh, may be normal variant\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "predicted:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  sinus bradycardia otherwise normal ecg\n",
      "predicted:  sinus bradycardia otherwise normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  sinus tachycardia cannot rule out anterior infarct age undetermined abnormal ecg\n",
      "predicted:  sinus tachycardia cannot rule out anterior infarct age undetermined\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "predicted:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "predicted:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "predicted:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm inferior infarct age undetermined abnormal ecg\n",
      "predicted:  normal sinus rhythm inferior infarct age undetermined\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  electronic ventricular pacemaker\n",
      "predicted:  electronic ventricular pacemaker\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm inferior infarct age undetermined abnormal ecg\n",
      "predicted:  normal sinus rhythm inferior infarct age undetermined\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm possible anterior infarct abnormal ecg\n",
      "predicted:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "predicted:  sinus bradycardia minimal voltage criteria for lvh, may be normal variant\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "predicted:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm inferior infarct prolonged qt abnormal ecg\n",
      "predicted:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "predicted:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "predicted:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm inferior infarct prolonged qt abnormal ecg\n",
      "predicted:  normal sinus rhythm inferior infarct prolonged qt\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm st abnormality, possible digitalis effect abnormal ecg\n",
      "predicted:  normal sinus rhythm st abnormality, possible digitalis effect\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "predicted:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  electronic ventricular pacemaker\n",
      "predicted:  electronic ventricular pacemaker\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  sinus rhythm with marked sinus arrhythmia otherwise normal ecg\n",
      "predicted:  sinus rhythm with marked sinus arrhythmia otherwise normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking the predictions\n",
    "\n",
    "for x, y in zip(full_x, token_y):\n",
    "    #print(x)\n",
    "    print(\"ground truth: \", tokenizer.decode(y))\n",
    "    \n",
    "    val_x = lstm_embedder(x)\n",
    "    \n",
    "    hidden_enc, cell_enc = torch.zeros(8, 1, 1024), torch.zeros(8, 1, 1024)\n",
    "    \n",
    "    enc_out, hidden_enc, cell_enc = lstm_encoder(val_x, hidden_enc, cell_enc)\n",
    "    \n",
    "    decoder_out = lstm_decoder.generate_beam(enc_out, hidden_enc, cell_enc)  \n",
    "    print(\"predicted: \", tokenizer.decode(decoder_out))\n",
    "    \n",
    "    print(\"\\n\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder 3 - Multi-Head Attention Transformer Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work in progress, will clean later\n",
    "\n",
    "\n",
    "class ECGTransformerEncoder(nn.Module):\n",
    "    # Takes the ECG discrete signals sequence and maps into a probability distribution of diagnosis\n",
    "    # For working/verification purposes\n",
    "    def __init__(self, vector_size, embed_dim, n_heads, hidden_linear_dim, n_layers, dropout):\n",
    "        super(ECGTransformerEncoder, self).__init__()\n",
    "        self.model_type = \"Transformer\"\n",
    "        self.positional_encoder = PositionalEncoder(embed_dim, dropout)\n",
    "    \n",
    "        #Since our data is already discrete numbers, might need some tweaking for this\n",
    "        self.embedder = conv_embedder\n",
    "                        #64 31              #39        64\n",
    "        \n",
    "        \n",
    "        self.encoder = TransformerEncoder(\n",
    "            TransformerEncoderLayer(embed_dim, n_heads, hidden_linear_dim, dropout),\n",
    "            n_layers)\n",
    "        \n",
    "        self.n_inputs = embed_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        # Simple linear decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "                        nn.Linear(768, 17),\n",
    "                        Transpose(17, 2500),\n",
    "                        nn.Linear(2500, 30),\n",
    "                        nn.LogSoftmax()\n",
    "                        )\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        #self.embedder.weight.data.uniform_(-.1, .1)\n",
    "        #self.decoder.bias.data.zero_()\n",
    "        #self.decoder.weight.data.uniform_(-.1, .1)\n",
    "        pass\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x = self.embedder(x) # * math.sqrt(self.n_inputs)\n",
    "        x = x.squeeze(0)\n",
    "        #x = x.view(2500, 8)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.positional_encoder(x)\n",
    "        x = self.encoder(x)\n",
    "        x = x.squeeze(1) \n",
    "        #x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder 4 - FNET Transformer Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNet(nn.Module):\n",
    "    def __init__(self, features, expansion, dropout):\n",
    "        super(FeedForwardNet, self).__init__()\n",
    "        self.linear_1 = nn.Linear(features, features * expansion)\n",
    "        self.linear_2 = nn.Linear(features * expansion, features)\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        #self.dropout_2 = nn.Dropout(dropout)\n",
    "        self.norm_1 = nn.LayerNorm(features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        x = F.relu(self.linear_1(x))\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.linear_2(x)\n",
    "        x = self.norm_1(x + res)\n",
    "        return x\n",
    "\n",
    "    \n",
    "class FNETLayer(nn.Module):\n",
    "    def __init__(self, features, expansion, dropout):\n",
    "        super(FNETLayer, self).__init__()\n",
    "        self.feed_forward = FeedForwardNet(features, expansion, dropout)\n",
    "        self.norm_1 = nn.LayerNorm(features)\n",
    "        \n",
    "        # additions to add\n",
    "        #self.attention_layer = nn.TransformerEncoderLayer(256, 16, 512, 0.1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        x = fft.fftn(x, dim = (-2, -1)).real\n",
    "        x = self.norm_1(x + res)\n",
    "        x = self.feed_forward(x)\n",
    "        #x = self.attention_layer(x)\n",
    "        return x\n",
    "    \n",
    "class FNETEncoder(nn.TransformerEncoder):\n",
    "    def __init__(self, features, expansion=2, dropout=0.5, num_layers=6):\n",
    "        encoder_layer = FNETLayer(features, expansion, dropout)\n",
    "        super().__init__(encoder_layer=encoder_layer, num_layers=num_layers)\n",
    "        self.attention_layers = nn.Sequential(\n",
    "            nn.TransformerEncoderLayer(EMBED_DIM, 16, 512, 0.1),\n",
    "            nn.TransformerEncoderLayer(EMBED_DIM, 16, 512, 0.1),\n",
    "            nn.TransformerEncoderLayer(EMBED_DIM, 16, 512, 0.1)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        for layer in self.attention_layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc Encoder Helper Functions/Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder(nn.Module):\n",
    "    # Necessary to store positional data about the input data\n",
    "    def __init__(self, embed_dim, dropout=0.1, max_len=2500):\n",
    "        super(PositionalEncoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        pos_encoding = torch.zeros(max_len, 1, embed_dim)\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        \n",
    "        divisor = torch.exp(torch.arange(0, embed_dim, 2).float() * (- math.log(10000.0) / embed_dim))\n",
    "        \n",
    "        pos_encoding[:, 0, 0::2] = torch.sin(position * divisor)\n",
    "        pos_encoding[:, 0, 1::2] = torch.cos(position * divisor)\n",
    "        self.register_buffer(\"pos_encoding\", pos_encoding)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        pos_encoding = self.pos_encoding.repeat(1, x.shape[1], 1)\n",
    "        x = x + pos_encoding[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "   \n",
    "\n",
    "class Transpose(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super(Transpose, self).__init__()\n",
    "        self.shape = args\n",
    "\n",
    "    def forward(self, x):\n",
    "        # If the number of the last batch sample in the data set is smaller than the defined batch_batch size, mismatch problems will occur. You can modify it yourself, for example, just pass in the shape behind, and then enter it through x.szie(0).\n",
    "        return x.view(self.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder 1 - Huggingface GPT2 Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with child class of GPT2LMHeadModel\n",
    "\n",
    "class GPT2LMHeadModel(GPT2PreTrainedModel):\n",
    "    _keys_to_ignore_on_load_missing = [r\"attn.masked_bias\", r\"attn.bias\", r\"lm_head.weight\"]\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.transformer = GPT2Model(config)\n",
    "        #self.transformer.forward = forward2.__get__(self.transformer, GPT2Model)\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "        # Model parallel\n",
    "        self.model_parallel = False\n",
    "        self.device_map = None\n",
    "        \n",
    "    def parallelize(self, device_map=None):\n",
    "        self.device_map = (\n",
    "            get_device_map(len(self.transformer.h), range(torch.cuda.device_count()))\n",
    "            if device_map is None\n",
    "            else device_map\n",
    "        )\n",
    "        assert_device_map(self.device_map, len(self.transformer.h))\n",
    "        self.transformer.parallelize(self.device_map)\n",
    "        self.lm_head = self.lm_head.to(self.transformer.first_device)\n",
    "        self.model_parallel = True\n",
    "        \n",
    "    def deparallelize(self):\n",
    "        self.transformer.deparallelize()\n",
    "        self.transformer = self.transformer.to(\"cpu\")\n",
    "        self.lm_head = self.lm_head.to(\"cpu\")\n",
    "        self.model_parallel = False\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    def get_output_embeddings(self):\n",
    "        return self.lm_head\n",
    "\n",
    "    def set_output_embeddings(self, new_embeddings):\n",
    "        self.lm_head = new_embeddings\n",
    "\n",
    "    def prepare_inputs_for_generation(self, input_ids, past=None, **kwargs):\n",
    "        token_type_ids = kwargs.get(\"token_type_ids\", None)\n",
    "        # only last token for inputs_ids if past is defined in kwargs\n",
    "        if past:\n",
    "            input_ids = input_ids[:, -1].unsqueeze(-1)\n",
    "            if token_type_ids is not None:\n",
    "                token_type_ids = token_type_ids[:, -1].unsqueeze(-1)\n",
    "\n",
    "        attention_mask = kwargs.get(\"attention_mask\", None)\n",
    "        position_ids = kwargs.get(\"position_ids\", None)\n",
    "\n",
    "        if attention_mask is not None and position_ids is None:\n",
    "            # create position_ids on the fly for batch generation\n",
    "            position_ids = attention_mask.long().cumsum(-1) - 1\n",
    "            position_ids.masked_fill_(attention_mask == 0, 1)\n",
    "            if past:\n",
    "                position_ids = position_ids[:, -1].unsqueeze(-1)\n",
    "        else:\n",
    "            position_ids = None\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"past_key_values\": past,\n",
    "            \"use_cache\": kwargs.get(\"use_cache\"),\n",
    "            \"encoder_hidden_states\": kwargs.get(\"encoder_hidden_states\", None), # The one line changed hehe\n",
    "            \"position_ids\": position_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"token_type_ids\": token_type_ids,\n",
    "        }\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        past_key_values=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        encoder_hidden_states=None,\n",
    "        encoder_attention_mask=None,\n",
    "        labels=None,\n",
    "        use_cache=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n",
    "            Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\n",
    "            ``labels = input_ids`` Indices are selected in ``[-100, 0, ..., config.vocab_size]`` All labels set to\n",
    "            ``-100`` are ignored (masked), the loss is only computed for labels in ``[0, ..., config.vocab_size]``\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        transformer_outputs = self.transformer(\n",
    "            input_ids,\n",
    "            past_key_values=past_key_values,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            encoder_hidden_states=encoder_hidden_states,\n",
    "            encoder_attention_mask=encoder_attention_mask,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        hidden_states = transformer_outputs[0]\n",
    "\n",
    "        # Set device for model parallelism\n",
    "        if self.model_parallel:\n",
    "            torch.cuda.set_device(self.transformer.first_device)\n",
    "            hidden_states = hidden_states.to(self.lm_head.weight.device)\n",
    "\n",
    "        lm_logits = self.lm_head(hidden_states)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            # Shift so that tokens < n predict n\n",
    "            shift_logits = lm_logits[..., :-1, :].contiguous()\n",
    "            shift_labels = labels[..., 1:].contiguous()\n",
    "            # Flatten the tokens\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (lm_logits,) + transformer_outputs[1:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return CausalLMOutputWithCrossAttentions(\n",
    "            loss=loss,\n",
    "            logits=lm_logits,\n",
    "            past_key_values=transformer_outputs.past_key_values,\n",
    "            hidden_states=transformer_outputs.hidden_states,\n",
    "            attentions=transformer_outputs.attentions,\n",
    "            cross_attentions=transformer_outputs.cross_attentions,\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def _reorder_cache(past: Tuple[Tuple[torch.Tensor]], beam_idx: torch.Tensor) -> Tuple[Tuple[torch.Tensor]]:\n",
    "        \"\"\"\n",
    "        This function is used to re-order the :obj:`past_key_values` cache if\n",
    "        :meth:`~transformers.PreTrainedModel.beam_search` or :meth:`~transformers.PreTrainedModel.beam_sample` is\n",
    "        called. This is required to match :obj:`past_key_values` with the correct beam_idx at every generation step.\n",
    "        \"\"\"\n",
    "        return tuple(\n",
    "            tuple(past_state.index_select(0, beam_idx.to(past_state.device)) for past_state in layer_past)\n",
    "            for layer_past in past\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder 2 - RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobertaLMHead(nn.Module):\n",
    "    \"\"\"Roberta Head for masked language modeling.\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(RobertaLMHead, self).__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.layer_norm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "\n",
    "        self.decoder = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n",
    "        self.bias = nn.Parameter(torch.zeros(config.vocab_size))\n",
    "\n",
    "    def forward(self, features, **kwargs):\n",
    "        x = self.dense(features)\n",
    "        x = x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))\n",
    "        x = self.layer_norm(x)\n",
    "\n",
    "        # project back to size of vocabulary with bias\n",
    "        x = self.decoder(x) + self.bias\n",
    "\n",
    "        return x\n",
    "\n",
    "class RobertaForCausalLM(RobertaPreTrainedModel):\n",
    "    _keys_to_ignore_on_save = [r\"lm_head.decoder.weight\", r\"lm_head.decoder.bias\"]\n",
    "    _keys_to_ignore_on_load_missing = [r\"position_ids\", r\"lm_head.decoder.weight\", r\"lm_head.decoder.bias\"]\n",
    "    _keys_to_ignore_on_load_unexpected = [r\"pooler\"]\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "        if not config.is_decoder:\n",
    "            logger.warning(\"If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`\")\n",
    "\n",
    "        self.roberta = RobertaModel(config, add_pooling_layer=False)\n",
    "        self.lm_head = RobertaLMHead(config)\n",
    "\n",
    "        # The LM head weights require special treatment only when they are tied with the word embeddings\n",
    "        self.update_keys_to_ignore(config, [\"lm_head.decoder.weight\"])\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def get_output_embeddings(self):\n",
    "        return self.lm_head.decoder\n",
    "\n",
    "    def set_output_embeddings(self, new_embeddings):\n",
    "        self.lm_head.decoder = new_embeddings\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        encoder_hidden_states=None,\n",
    "        encoder_attention_mask=None,\n",
    "        labels=None,\n",
    "        past_key_values=None,\n",
    "        use_cache=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        encoder_hidden_states  (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length, hidden_size)`, `optional`):\n",
    "            Sequence of hidden-states at the output of the last layer of the encoder. Used in the cross-attention if\n",
    "            the model is configured as a decoder.\n",
    "        encoder_attention_mask (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n",
    "            Mask to avoid performing attention on the padding token indices of the encoder input. This mask is used in\n",
    "            the cross-attention if the model is configured as a decoder. Mask values selected in ``[0, 1]``:\n",
    "\n",
    "            - 1 for tokens that are **not masked**,\n",
    "            - 0 for tokens that are **masked**.\n",
    "\n",
    "        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n",
    "            Labels for computing the left-to-right language modeling loss (next word prediction). Indices should be in\n",
    "            ``[-100, 0, ..., config.vocab_size]`` (see ``input_ids`` docstring) Tokens with indices set to ``-100`` are\n",
    "            ignored (masked), the loss is only computed for the tokens with labels in ``[0, ..., config.vocab_size]``\n",
    "        past_key_values (:obj:`tuple(tuple(torch.FloatTensor))` of length :obj:`config.n_layers` with each tuple having 4 tensors of shape :obj:`(batch_size, num_heads, sequence_length - 1, embed_size_per_head)`):\n",
    "            Contains precomputed key and value hidden states of the attention blocks. Can be used to speed up decoding.\n",
    "\n",
    "            If :obj:`past_key_values` are used, the user can optionally input only the last :obj:`decoder_input_ids`\n",
    "            (those that don't have their past key value states given to this model) of shape :obj:`(batch_size, 1)`\n",
    "            instead of all :obj:`decoder_input_ids` of shape :obj:`(batch_size, sequence_length)`.\n",
    "        use_cache (:obj:`bool`, `optional`):\n",
    "            If set to :obj:`True`, :obj:`past_key_values` key value states are returned and can be used to speed up\n",
    "            decoding (see :obj:`past_key_values`).\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        Example::\n",
    "\n",
    "            >>> from transformers import RobertaTokenizer, RobertaForCausalLM, RobertaConfig\n",
    "            >>> import torch\n",
    "\n",
    "            >>> tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "            >>> config = RobertaConfig.from_pretrained(\"roberta-base\")\n",
    "            >>> config.is_decoder = True\n",
    "            >>> model = RobertaForCausalLM.from_pretrained('roberta-base', config=config)\n",
    "\n",
    "            >>> inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "            >>> outputs = model(**inputs)\n",
    "\n",
    "            >>> prediction_logits = outputs.logits\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        if labels is not None:\n",
    "            use_cache = False\n",
    "\n",
    "        outputs = self.roberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            encoder_hidden_states=encoder_hidden_states,\n",
    "            encoder_attention_mask=encoder_attention_mask,\n",
    "            past_key_values=past_key_values,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        sequence_output = outputs[0]\n",
    "        prediction_scores = self.lm_head(sequence_output)\n",
    "\n",
    "        lm_loss = None\n",
    "        if labels is not None:\n",
    "            # we are doing next-token prediction; shift prediction scores and input ids by one\n",
    "            shifted_prediction_scores = prediction_scores[:, :-1, :].contiguous()\n",
    "            labels = labels[:, 1:].contiguous()\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            lm_loss = loss_fct(shifted_prediction_scores.view(-1, self.config.vocab_size), labels.view(-1))\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (prediction_scores,) + outputs[2:]\n",
    "            return ((lm_loss,) + output) if lm_loss is not None else output\n",
    "\n",
    "        return CausalLMOutputWithCrossAttentions(\n",
    "            loss=lm_loss,\n",
    "            logits=prediction_scores,\n",
    "            past_key_values=outputs.past_key_values,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "            cross_attentions=outputs.cross_attentions,\n",
    "        )\n",
    "\n",
    "\n",
    "    def prepare_inputs_for_generation(self, input_ids, encoder_hidden_states, past=None, attention_mask=None, **model_kwargs):\n",
    "        input_shape = input_ids.shape\n",
    "        # if model is used as a decoder in encoder-decoder model, the decoder attention mask is created on the fly\n",
    "        if attention_mask is None:\n",
    "            attention_mask = input_ids.new_ones(input_shape)\n",
    "\n",
    "        # cut decoder_input_ids if past is used\n",
    "        if past is not None:\n",
    "            input_ids = input_ids[:, -1:]\n",
    "\n",
    "        return {\"input_ids\": input_ids, \"encoder_hidden_states\": encoder_hidden_states, \"attention_mask\": attention_mask, \"past_key_values\": past}\n",
    "\n",
    "    def _reorder_cache(self, past, beam_idx):\n",
    "        reordered_past = ()\n",
    "        for layer_past in past:\n",
    "            reordered_past += (tuple(past_state.index_select(0, beam_idx) for past_state in layer_past),)\n",
    "        return reordered_past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaConfig {\n",
      "  \"add_cross_attention\": true,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": true,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 7,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 183\n",
      "}\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'full_y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f70e92655aba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#defining our input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'full_y' is not defined"
     ]
    }
   ],
   "source": [
    "# don't use this one, use the one at the bottom\n",
    "EMBED_DIM = 512\n",
    "word_list_length = 183\n",
    "LR = 1e-3\n",
    "\n",
    "# define and pretrain Decoder\n",
    "config = RobertaConfig(vocab_size = word_list_length, hidden_size=EMBED_DIM, num_attention_heads = 16, num_hidden_layers = 7, add_cross_attention = True, is_decoder = True, bos_token_id=0, eos_token_id= 0)\n",
    "print(config)\n",
    "transformer_decoder = RobertaForCausalLM(config=config)\n",
    "# optional pretrain decoder\n",
    "optimizer = torch.optim.Adam(transformer_decoder.parameters(), lr = LR)\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "\n",
    "#defining our input data\n",
    "inputs = tokenizer(full_y)\n",
    "\n",
    "\n",
    "epochs = 0\n",
    "for i in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = transformer_decoder(**inputs, labels = inputs[\"input_ids\"])\n",
    "    loss = outputs.loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(loss)\n",
    "    \n",
    "\n",
    "torch.save(transformer_decoder.state_dict(), 'model/roberta_decoder.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create encoder decoder model with Roberta\n",
    "class CustEncoderDecoder(nn.Module):\n",
    "    def __init__(self, embedder, encoder, decoder, tokenizer):\n",
    "        super(CustEncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.pos_enb = PositionalEncoder(embed_dim = EMBED_DIM)\n",
    "        self.embedder = embedder\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ecgs, labels = x\n",
    "        x = self.embedder(ecgs) # no permute with window embedder\n",
    "        x = self.pos_enb(x).permute(1, 0, 2)\n",
    "        x = self.encoder(x)\n",
    "        out = self.decoder(**labels, labels = labels[\"input_ids\"], encoder_hidden_states = x.contiguous())\n",
    "        return out\n",
    "    \n",
    "    # Should only take 1 input at a time\n",
    "    def predict_single(self, x):\n",
    "        ecgs = x\n",
    "        x = self.embedder(ecgs)#.permute(2, 0, 1)\n",
    "        print(x.shape)\n",
    "        x = self.pos_enb(x).permute(1, 0, 2)\n",
    "        print(x.shape)\n",
    "        x = self.encoder(x)\n",
    "        print(x.shape)\n",
    "        return self.tokenizer.decode(self.decoder.generate(encoder_hidden_states = x.contiguous())[0])\n",
    "\n",
    "    \n",
    "    # Takes in multiple inputs\n",
    "    def predict_batch(self, x):\n",
    "        ecgs = x\n",
    "        x = self.embedder(ecgs)#.permute(2, 0, 1)\n",
    "        x = self.pos_enb(x).permute(1, 0, 2)\n",
    "        x = self.encoder(x)\n",
    "        output = []\n",
    "        for ecg in x:\n",
    "            output.append(self.tokenizer.decode(self.decoder.generate(encoder_hidden_states = ecg.unsqueeze(0).contiguous())[0]))\n",
    "        return output\n",
    "    \n",
    "    def return_enc(self):\n",
    "        return self.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_encoder = FNETEncoder(EMBED_DIM, expansion = 2, dropout=0.1, num_layers = 6)\n",
    "transformer_embedder = WindowEmbedder(embed_dim = EMBED_DIM)\n",
    "enc_dec_model_roberta = CustEncoderDecoder(transformer_embedder, transformer_encoder, transformer_decoder, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 52, 256])\n",
      "tensor(4.6579, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(2.5247, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(2.0497, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.7803, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.7094, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.6555, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.6083, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.5708, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.5419, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.5104, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(2.6963, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.5398, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.5040, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.5034, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.5022, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.4938, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.4821, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.4713, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.4680, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.4676, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.4721, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.4682, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.4613, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.4586, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.4545, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.4521, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.4532, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.4547, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.4528, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.4503, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.4489, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.4483, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.4466, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.4461, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.4460, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.4455, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.4457, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.4455, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.4422, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.4428, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.4425, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.4417, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.4434, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.4433, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.4423, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.4431, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.4407, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.4410, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.4408, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.4400, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.4417, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n",
      "tensor(1.4398, grad_fn=<NllLossBackward>)\n",
      "torch.Size([100, 52, 256])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-152-86fe6f54df5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_dec_model_roberta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-146-2795018ea6d3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_enb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-122-3a818dcdc096>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         )\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    852\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    855\u001b[0m         )\n\u001b[1;32m    856\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    527\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m                 )\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m                 \u001b[0mcross_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m             )\n\u001b[1;32m    442\u001b[0m             \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m         )\n\u001b[1;32m    346\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_cross_attention\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             \u001b[0mkey_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m             \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/traceback.py\u001b[0m in \u001b[0;36mformat_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mformat_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0;34m\"\"\"Shorthand for 'format_list(extract_stack(f, limit))'.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#writer = SummaryWriter('runs/transformer_encoder_decoder')\n",
    "\n",
    "# train encoder decoder model!\n",
    "optimizer = torch.optim.Adam(enc_dec_model_roberta.parameters(), lr = LR)\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "\n",
    "# set number of epochs\n",
    "epochs = 230\n",
    "optimizer = torch.optim.Adam(enc_dec_model_roberta.parameters(), lr = 1e-3)\n",
    "inputs = tokenizer(full_y)\n",
    "\n",
    "for i in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = enc_dec_model_roberta((full_x, inputs))\n",
    "    loss = outputs.loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i == 70:\n",
    "        optimizer = torch.optim.Adam(enc_dec_model_roberta.parameters(), lr = 1e-4)\n",
    "    if i == 100:\n",
    "        optimizer = torch.optim.Adam(enc_dec_model_roberta.parameters(), lr = 1e-5)\n",
    "    if i == 180:\n",
    "        optimizer = torch.optim.Adam(enc_dec_model_roberta.parameters(), lr = 1e-6)\n",
    "    if i == 210:\n",
    "        optimizer = torch.optim.Adam(enc_dec_model_roberta.parameters(), lr = 1e-7)\n",
    "    print(loss)\n",
    "       \n",
    "\n",
    "            \n",
    "torch.save(enc_dec_model_roberta.state_dict(), 'model/roberta_enc_dec.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth:  sinus bradycardia otherwise normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  sinus rhythm with marked sinus arrhythmia otherwise normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm with sinus arrhythmia cannot rule out inferior infarct age undetermined abnormal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm st & t wave abnormality, consider anterior ischemia prolonged qt abnormal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  sinus rhythm with marked sinus arrhythmia otherwise normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm possible left atrial enlargement incomplete left bundle branch block borderline ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  sinus tachycardia left axis deviation pulmonary disease pattern inferior infarct age undetermined st & t wave abnormality, consider lateral ischemia abnormal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  atrial fibrillation with rapid ventricular response with premature ventricular or aberrantly conducted complexes right bundle branch block left posterior fascicular block abnormal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  undetermined rhythm right bundle branch block abnormal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  undetermined rhythm possible right ventricular hypertrophy nonspecific t wave abnormality abnormal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  electronic atrial pacemaker indeterminate axis pulmonary disease pattern st elevation consider anterolateral injury or acute infarct st elevation consider inferior injury or acute infarct abnormal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  atrial fibrillation left axis deviation pulmonary disease pattern septal infarct age undetermined abnormal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  sinus tachycardia with short pr with premature supraventricular complexes and fusion complexes right bundle branch block cannot rule out inferior infarct age undetermined t wave abnormality, consider lateral ischemia abnormal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  sinus tachycardia with short pr with premature supraventricular complexes right bundle branch block t wave abnormality, consider lateral ischemia abnormal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  av sequential or dual chamber electronic pacemaker electronic ventricular pacemaker\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  av sequential or dual chamber electronic pacemaker\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm cannot rule out anterior infarct age undetermined abnormal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm possible left atrial enlargement incomplete right bundle branch block borderline ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  sinus bradycardia\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  sinus rhythm with marked sinus arrhythmia otherwise normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm minimal voltage criteria for lvh, may be normal variant borderline ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  sinus bradycardia otherwise normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  sinus tachycardia cannot rule out anterior infarct age undetermined abnormal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm inferior infarct age undetermined abnormal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  electronic ventricular pacemaker\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm inferior infarct age undetermined abnormal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm possible anterior infarct abnormal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm inferior infarct prolonged qt abnormal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "torch.Size([100, 1, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm inferior infarct prolonged qt abnormal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm st abnormality, possible digitalis effect abnormal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  electronic ventricular pacemaker\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  sinus rhythm with marked sinus arrhythmia otherwise normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "enc_dec_model_roberta.load_state_dict(torch.load('model/roberta_enc_dec.pt'))\n",
    "for inp, out in zip(full_x, inputs[\"input_ids\"]):\n",
    "    print(\"ground truth: \", tokenizer.decode(out))\n",
    "    print(\"predicted label: \", enc_dec_model_roberta.predict_single(inp.unsqueeze(0)))\n",
    "    print(\"\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EncoderDecoder - FNET Encoder Huggingface Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FNETEncoder(\n",
       "  (layers): ModuleList(\n",
       "    (0): FNETLayer(\n",
       "      (feed_forward): FeedForwardNet(\n",
       "        (linear_1): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (linear_2): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "        (norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): FNETLayer(\n",
       "      (feed_forward): FeedForwardNet(\n",
       "        (linear_1): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (linear_2): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "        (norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (2): FNETLayer(\n",
       "      (feed_forward): FeedForwardNet(\n",
       "        (linear_1): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (linear_2): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "        (norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): FNETLayer(\n",
       "      (feed_forward): FeedForwardNet(\n",
       "        (linear_1): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (linear_2): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "        (norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (attention_layers): Sequential(\n",
       "    (0): TransformerEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define encoder\n",
    "transformer_encoder = FNETEncoder(EMBED_DIM, expansion = 2, dropout=0.1, num_layers = 4)\n",
    "transformer_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 256,\n",
      "  \"n_head\": 16,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 7,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.9.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 99\n",
      "}\n",
      "\n",
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(99, 256)\n",
      "    (wpe): Embedding(1024, 256)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0): GPT2Block(\n",
      "        (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (crossattention): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (q_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_cross_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): GPT2Block(\n",
      "        (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (crossattention): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (q_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_cross_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): GPT2Block(\n",
      "        (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (crossattention): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (q_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_cross_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): GPT2Block(\n",
      "        (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (crossattention): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (q_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_cross_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): GPT2Block(\n",
      "        (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (crossattention): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (q_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_cross_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): GPT2Block(\n",
      "        (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (crossattention): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (q_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_cross_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): GPT2Block(\n",
      "        (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (crossattention): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (q_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_cross_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=256, out_features=99, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define and pretrain Decoder\n",
    "config = GPT2Config(vocab_size = word_list_length, n_embd = EMBED_DIM, n_head = 16, n_layer = 7, add_cross_attention = True, is_encoder_decoder = False, bos_token_id=0, eos_token_id= 0)\n",
    "print(config)\n",
    "transformer_decoder = GPT2LMHeadModel(config = config)\n",
    "print(transformer_decoder)\n",
    "# optional pretrain decoder\n",
    "optimizer = torch.optim.Adam(transformer_decoder.parameters(), lr = LR)\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "\n",
    "#defining our input data\n",
    "#inputs = token_y_transformer\n",
    "\n",
    "\n",
    "\n",
    "epochs = 0\n",
    "for i in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = decoder(**inputs, labels = inputs[\"input_ids\"])\n",
    "    loss = outputs.loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(loss)\n",
    "    \n",
    "    for tag, value in decoder.named_parameters():\n",
    "        tag = tag.replace('.', '/')\n",
    "        writer.add_histogram(tag+ \"_gpt2\", value.data.cpu().numpy(), epoch)\n",
    "        if value.grad is None:\n",
    "            writer.add_histogram(tag+ '_gpt2' + '/grad', 0, epoch)           \n",
    "        else:\n",
    "            writer.add_histogram(tag+ '_gpt2' + '/grad', value.grad.data.cpu().numpy(), epoch)\n",
    "    \n",
    "    \n",
    "\n",
    "torch.save(transformer_decoder.state_dict(), 'model/gpt2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'are now are now indeterminate axis indeterminate axis st abnormality, possible digitalis effect st abnormality, possible digitalis effect st abnormality, possible digitalis effect st abnormality, possible digitalis effect with a competing junctional pacemaker with a competing junctional pacemaker with a competing junctional pacemaker nonspecific t wave abnormality has replaced inverted t waves in nonspecific t wave abnormality has replaced inverted t waves in minimal voltage criteria for lvh, may be normal variant minimal voltage criteria for lvh, may be normal variant minimal voltage criteria for lvh, may be normal variant with a competing junctional pacemaker nonspecific t wave abnormality no longer evident in nonspecific t wave abnormality no longer evident in'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define component models\n",
    "\n",
    "transformer_embedder = WindowEmbedder(embed_dim=EMBED_DIM)\n",
    "\n",
    "enc_dec_model = CustEncoderDecoder(transformer_embedder, transformer_encoder, transformer_decoder, tokenizer)\n",
    "\n",
    "enc_dec_model.predict_single(full_x[0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1501, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1511, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1468, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1471, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1500, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1445, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1475, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1467, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1511, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1481, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1475, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1449, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1476, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1478, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1476, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1450, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1497, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1466, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1509, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1508, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1484, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1484, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1469, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1469, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1484, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1466, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1483, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1510, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1478, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1477, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1490, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1448, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1443, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1464, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1464, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1505, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1441, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1488, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1468, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1480, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1483, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1461, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1434, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1465, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1457, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1471, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1531, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1448, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1520, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1440, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1430, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1516, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1460, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1477, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1441, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1471, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1491, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1481, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1473, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1475, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1464, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1476, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1461, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1466, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1473, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1475, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1470, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1473, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1495, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1471, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1466, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1466, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1471, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1462, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1444, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1476, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1503, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1521, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1476, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1462, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1474, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1459, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1451, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1437, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1492, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1432, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1463, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1453, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1466, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1460, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1462, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1473, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1480, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1509, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1465, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1422, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1462, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1468, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1448, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1480, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1431, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1429, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1494, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1451, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1456, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1545, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1465, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1474, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1491, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1466, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1484, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1500, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1446, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1448, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1498, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1467, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1461, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1450, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1481, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1436, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1462, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1454, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1474, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1478, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1457, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1499, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1464, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1473, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1473, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1451, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1445, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1518, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1486, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1484, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1476, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1460, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1493, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1444, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1463, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1472, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1467, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1452, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1502, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1474, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1449, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1455, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1449, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1455, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1477, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1465, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1470, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1461, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1423, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1420, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1472, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1490, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1485, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1448, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1489, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1457, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1448, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1524, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1465, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1454, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1451, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1453, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1450, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1494, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1452, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1424, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1459, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1473, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1455, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1477, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1489, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1470, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1440, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1437, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1470, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1467, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1467, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1485, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1469, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1465, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1453, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1446, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1453, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1448, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1471, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1468, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1499, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1432, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1452, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1443, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1430, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1434, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1487, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1463, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1493, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1478, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1457, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1439, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1457, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1427, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1458, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1470, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1451, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1458, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1468, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1426, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1461, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1503, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1448, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1457, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1445, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1472, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1446, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1445, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1432, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1476, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1458, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1466, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1491, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1465, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1458, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1461, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1454, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1472, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1466, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1464, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('runs/transformer_encoder_decoder_5')\n",
    "\n",
    "# train encoder decoder model!\n",
    "optimizer = torch.optim.Adam(enc_dec_model.parameters(), lr = LR)\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "\n",
    "# set number of epochs\n",
    "epochs = 230\n",
    "optimizer = torch.optim.Adam(enc_dec_model.parameters(), lr = 1e-5)\n",
    "inputs = tokenizer(full_y)\n",
    "for i in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = enc_dec_model((full_x, inputs))\n",
    "    loss = outputs.loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    #if i == 40:\n",
    "    #    optimizer = torch.optim.Adam(enc_dec_model.parameters(), lr = 1e-4)\n",
    "    #if i == 60:\n",
    "    #    optimizer = torch.optim.Adam(enc_dec_model.parameters(), lr = 1e-5)\n",
    "    if i == 180:\n",
    "        optimizer = torch.optim.Adam(enc_dec_model.parameters(), lr = 1e-6)\n",
    "    if i == 210:\n",
    "        optimizer = torch.optim.Adam(enc_dec_model.parameters(), lr = 1e-7)\n",
    "    print(loss)\n",
    "       \n",
    "\n",
    "    for tag, value in enc_dec_model.named_parameters():\n",
    "        tag = tag.replace('.', '/')\n",
    "        writer.add_histogram(tag+ \"_mixup2\", value.data.cpu().numpy(), i)\n",
    "        if value.grad is None:\n",
    "            writer.add_histogram(tag+ '_mixup2' + '/grad', 0, i)\n",
    "        else:\n",
    "            writer.add_histogram(tag+ '_mixup2' + '/grad', value.grad.data.cpu().numpy(), i)\n",
    "            \n",
    "torch.save(enc_dec_model.state_dict(), 'model/gpt2_enc_dec2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_dec_model.load_state_dict(torch.load('model/gpt2_enc_dec.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth:  sinus bradycardia otherwise normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100, 256])\n",
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  sinus rhythm with marked sinus arrhythmia otherwise normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm with sinus arrhythmia cannot rule out inferior infarct age undetermined abnormal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100, 256])\n",
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm st & t wave abnormality, consider anterior ischemia prolonged qt abnormal ecg t wave inversion now evident in anterior leads qt has lengthened\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  sinus rhythm with marked sinus arrhythmia otherwise normal ecg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm possible left atrial enlargement incomplete left bundle branch block borderline ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100, 256])\n",
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg incomplete left bundle branch block is no longer present\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  sinus tachycardia left axis deviation pulmonary disease pattern inferior infarct age undetermined st & t wave abnormality, consider lateral ischemia abnormal ecg sinus rhythm has replaced atrial fibrillation inverted t waves have replaced nonspecific t wave abnormality in lateral leads\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  atrial fibrillation with rapid ventricular response with premature ventricular or aberrantly conducted complexes right bundle branch block left posterior fascicular block abnormal ecg atrial fibrillation has replaced sinus rhythm qrs duration has increased\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100, 256])\n",
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  undetermined rhythm right bundle branch block abnormal ecg current undetermined rhythm precludes rhythm comparison, needs review qrs duration has increased qt has lengthened\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  undetermined rhythm possible right ventricular hypertrophy nonspecific t wave abnormality abnormal ecg current undetermined rhythm precludes rhythm comparison, needs review is no longer present\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100, 256])\n",
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  electronic atrial pacemaker indeterminate axis pulmonary disease pattern st elevation consider anterolateral injury or acute infarct st elevation consider inferior injury or acute infarct abnormal ecg electronic atrial pacemaker has replaced electronic ventricular pacemaker\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  atrial fibrillation left axis deviation pulmonary disease pattern septal infarct age undetermined abnormal ecg atrial fibrillation has replaced sinus rhythm nonspecific t wave abnormality has replaced inverted t waves in lateral leads\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100, 256])\n",
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  sinus tachycardia with short pr with premature supraventricular complexes and fusion complexes right bundle branch block cannot rule out inferior infarct age undetermined t wave abnormality, consider lateral ischemia abnormal ecg previous ecg has undetermined rhythm, needs review right bundle branch block is now present\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  sinus tachycardia with short pr with premature supraventricular complexes right bundle branch block t wave abnormality, consider lateral ischemia abnormal ecg premature supraventricular complexes are now present\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  av sequential or dual chamber electronic pacemaker electronic ventricular pacemaker has replaced sinus rhythm vent. rate has decreased\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100, 256])\n",
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  av sequential or dual chamber electronic pacemaker\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100, 256])\n",
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm cannot rule out anterior infarct age undetermined abnormal ecg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100, 256])\n",
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm possible left atrial enlargement incomplete right bundle branch block borderline ecg incomplete right bundle branch block is now present\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100, 256])\n",
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  sinus bradycardia\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  sinus rhythm with marked sinus arrhythmia otherwise normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm minimal voltage criteria for lvh, may be normal variant borderline ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100, 256])\n",
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  sinus bradycardia otherwise normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  sinus tachycardia cannot rule out anterior infarct age undetermined abnormal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100, 256])\n",
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100, 256])\n",
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm inferior infarct age undetermined abnormal ecg t wave amplitude has decreased in lateral leads\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  electronic ventricular pacemaker previous ecg has undetermined rhythm, needs review\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm inferior infarct age undetermined abnormal ecg inverted t waves have replaced nonspecific t wave abnormality in inferior leads\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100, 256])\n",
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm possible anterior infarct abnormal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100, 256])\n",
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm inferior infarct prolonged qt abnormal ecg t wave inversion no longer evident in lateral leads\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg criteria for septal infarct are no longer present\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100, 256])\n",
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm inferior infarct prolonged qt abnormal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm st abnormality, possible digitalis effect abnormal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  normal sinus rhythm normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100, 256])\n",
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  electronic ventricular pacemaker vent. rate has decreased\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ground truth:  sinus rhythm with marked sinus arrhythmia otherwise normal ecg\n",
      "torch.Size([100, 1, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "torch.Size([1, 100, 256])\n",
      "predicted label:  normal sinus rhythm normal ecg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking predicted output of Transformer model\n",
    "\n",
    "for inp, out in zip(full_x, inputs[\"input_ids\"]):\n",
    "    print(\"ground truth: \", tokenizer.decode(out))\n",
    "    print(\"predicted label: \", enc_dec_model.predict_single(inp.unsqueeze(0)))\n",
    "    print(\"\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roberta EncoderDecoder Model Start here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaModel(\n",
      "  (embeddings): RobertaEmbeddings(\n",
      "    (word_embeddings): Embedding(183, 512, padding_idx=1)\n",
      "    (position_embeddings): Embedding(512, 512, padding_idx=1)\n",
      "    (token_type_embeddings): Embedding(2, 512)\n",
      "    (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): RobertaEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=512, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=512, bias=True)\n",
      "          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=512, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=512, bias=True)\n",
      "          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=512, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=512, bias=True)\n",
      "          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=512, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=512, bias=True)\n",
      "          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=512, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=512, bias=True)\n",
      "          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): RobertaPooler(\n",
      "    (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# making the training loop\n",
    "word_list_length = 183\n",
    "EMBED_DIM=512\n",
    "# define tokenizer \n",
    "tokenizer = tokenizer\n",
    "\n",
    "# modify decoder configuration file\n",
    "encoder_config = RobertaConfig(vocab_size = word_list_length, hidden_size=EMBED_DIM, num_attention_heads = 16, num_hidden_layers = 5, bos_token_id=0, eos_token_id= 0)\n",
    "decoder_config = RobertaConfig(vocab_size = word_list_length, hidden_size=EMBED_DIM, num_attention_heads = 16, num_hidden_layers = 5, add_cross_attention = True, is_decoder = True, bos_token_id=0, eos_token_id= 0)\n",
    "\n",
    "# instantiate encoder decoder model\n",
    "encoder = RobertaModel(config=encoder_config).to(device)\n",
    "decoder = RobertaForCausalLM(config = decoder_config).to(device)\n",
    "\n",
    "encoder.load_state_dict(torch.load('model/roberta_encoder.pt'))\n",
    "# define embedder\n",
    "embedder = WindowEmbedder(embed_dim = EMBED_DIM).to(device)\n",
    "\n",
    "loader = dataLoader(waveform_lead_rhythm_diag, 15)\n",
    "# get inputs\n",
    "#decoder_inputs = tokenizer(full_y)\n",
    "#labels = decoder_inputs['input_ids'].to(device)\n",
    "#mask = decoder_inputs['attention_mask'].to(device)\n",
    "\n",
    "print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrain Encoder\n",
    "\n",
    "LR = 1e-3\n",
    "\n",
    "# pretrain Encoder\n",
    "\n",
    "LR = 1e-3\n",
    "\n",
    "# define and pretrain Decoder\n",
    "\n",
    "# optional pretrain decoder\n",
    "\n",
    "\n",
    "class EncoderWithLin(nn.Module):\n",
    "    def __init__(self, embedder, encoder):\n",
    "        super(EncoderWithLin, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.linear = nn.Linear(EMBED_DIM, 200)\n",
    "        self.pos_enb = PositionalEncoder(embed_dim = EMBED_DIM)\n",
    "        self.embedder = embedder\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedder(x)\n",
    "        x = self.pos_enb(x).permute(1, 0, 2)\n",
    "        x = self.encoder(inputs_embeds = x).last_hidden_state\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "    \n",
    "    def return_enc(self):\n",
    "        return self.encoder\n",
    "    \n",
    "    def return_emb(self):\n",
    "        return self.embedder\n",
    "\n",
    "\n",
    "wrapper_model = EncoderWithLin(embedder, encoder)\n",
    "optimizer = torch.optim.Adam(wrapper_model.parameters(), lr = LR)\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "\n",
    "\n",
    "#defining our input data\n",
    "loss_function = nn.MSELoss()\n",
    "epochs = 0\n",
    "for i in range(1, epochs):\n",
    "    if i % 40 == 0:\n",
    "        LR /= 5\n",
    "        optimizer = torch.optim.Adam(wrapper_model.parameters(), lr = LR)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    print(\"epoch no: \", i)\n",
    "    for j in range(4100//15):\n",
    "        x, y = loader.generate()\n",
    "        outputs = wrapper_model(x)\n",
    "        x = embedder.forward_no_lin(x)\n",
    "        \n",
    "        loss = loss_function(outputs, x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(loss)\n",
    "    \n",
    "\n",
    "    \n",
    "encoder = wrapper_model.return_enc()\n",
    "embedder = wrapper_model.return_emb()\n",
    "torch.save(encoder.state_dict(), 'model/roberta_encoder.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err\n",
      "(300, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "data, labels = loader.generate()\n",
    "data = wrapper_model.embedder(data)\n",
    "data = wrapper_model.pos_enb(data).permute(1,0,2)\n",
    "for_tsne = wrapper_model.encoder(inputs_embeds = data).last_hidden_state\n",
    "for_tsne = torch.flatten(for_tsne, start_dim=1)\n",
    "\n",
    "for i in range(19):\n",
    "    data, new_labels = loader.generate()\n",
    "    data = wrapper_model.embedder(data)\n",
    "    data = wrapper_model.pos_enb(data).permute(1,0,2)\n",
    "    adding_data = wrapper_model.encoder(inputs_embeds = data).last_hidden_state\n",
    "    adding_data = torch.flatten(adding_data, start_dim=1)\n",
    "    for_tsne = torch.cat((for_tsne, adding_data), 0)\n",
    "\n",
    "    for new_label in new_labels:\n",
    "        labels.append(new_label)\n",
    "        \n",
    "pca = PCA(n_components = 50, svd_solver = \"full\")\n",
    "codebooks = pca.fit_transform(for_tsne.detach())\n",
    "print(\"err\")\n",
    "codebooks = TSNE(2, perplexity = 10, n_iter = 1000, learning_rate = 50, init = \"pca\").fit_transform(codebooks)\n",
    "print(codebooks.shape)\n",
    "colors = ['r', 'b']\n",
    "#colors = ['r', 'b']\n",
    "plt.title(\"Codebook latent dimension (TSNE projected)\")\n",
    "for i in range(300):\n",
    "    if labels[i] == 'normal sinus rhythm; normal ecg':\n",
    "        plt.scatter(codebooks[i,0], codebooks[i,1], c=\"b\")\n",
    "    else:\n",
    "        plt.scatter(codebooks[i,0], codebooks[i,1], c=\"r\")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.1484, grad_fn=<NllLossBackward>)\n",
      "tensor(2.0997, grad_fn=<NllLossBackward>)\n",
      "tensor(1.6969, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5104, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4406, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3128, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3836, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3576, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3643, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3027, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2690, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2295, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1668, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1084, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0823, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0506, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0428, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0318, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0076, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9918, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9692, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9561, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9261, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9124, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8940, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8767, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8521, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8313, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8226, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8072, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7900, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7712, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7518, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7382, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7168, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7048, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6879, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6754, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6604, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6503, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6403, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6269, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6270, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6196, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6137, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6124, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5999, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5988, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5844, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5833, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5775, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5751, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5667, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5552, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5579, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5486, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5511, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5341, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5243, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5146, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5096, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5009, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4951, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4841, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4850, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4813, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4684, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4659, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4594, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4520, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4446, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4338, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4329, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4301, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4230, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4243, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4140, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4141, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4083, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4043, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3934, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3951, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3904, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3848, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3864, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3750, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3696, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3709, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3659, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3623, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3606, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3553, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3543, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3512, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3448, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3497, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3458, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3410, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3361, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3318, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3329, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3269, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3233, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3154, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3158, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3134, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3139, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3031, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3105, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3085, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3041, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3003, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3019, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3016, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2952, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2997, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2875, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2919, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2858, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2891, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2876, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2838, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2828, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2835, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2775, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2787, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2744, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2736, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2787, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2686, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2736, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2698, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2652, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2678, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2656, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2643, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2632, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2652, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2564, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2578, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2549, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2586, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2594, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2553, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2584, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2542, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2572, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2566, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2532, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2501, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2569, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2530, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2464, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2509, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2483, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2473, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2508, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2455, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2471, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2425, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2435, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2411, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2460, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2402, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2449, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2416, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2439, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2385, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2377, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2353, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2384, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2392, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2357, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2366, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2414, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2308, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2352, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2333, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2370, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2347, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2315, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2311, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2293, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2314, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2405, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2309, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2310, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2295, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2298, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2246, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2282, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2298, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2316, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2305, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2312, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2301, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2296, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2275, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2274, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2226, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "epochs = 200\n",
    "optimizer = torch.optim.Adam(decoder.parameters(), lr = 1e-3)\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# pretrain decoder\n",
    "for i in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = decoder(input_ids = labels, attention_mask = mask, labels = labels)\n",
    "    loss = outputs.loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3178, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3409, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3193, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3222, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3329, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3292, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3192, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3215, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3214, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3172, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3272, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3248, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3253, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3277, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3339, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3359, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3179, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3191, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3282, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3247, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3319, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3261, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3246, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3262, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3320, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3218, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3319, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3267, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3278, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3166, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3272, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3186, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3177, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3316, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3281, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3235, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3370, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3205, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3300, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3326, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3246, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3264, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3214, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3285, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3284, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3294, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3144, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3242, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3234, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3281, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3202, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3263, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3162, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3228, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3213, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3230, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3169, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3292, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3273, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3283, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3232, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3144, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3245, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3265, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3228, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3232, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3195, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3222, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3241, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3209, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3237, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3227, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3300, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3272, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3290, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3194, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3268, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3222, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3152, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3299, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3198, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3375, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3293, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3231, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3240, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3334, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3144, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3205, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3201, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3187, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3212, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3183, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3162, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3266, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3204, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3218, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3247, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3308, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3259, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3229, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3252, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3264, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3238, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3212, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3233, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3122, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3235, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3222, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3211, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3223, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3280, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3225, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3240, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3176, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3289, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3271, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3220, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3223, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3246, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3239, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3288, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3207, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3281, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3218, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3196, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3210, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3257, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3193, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3198, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3214, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3234, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3159, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3226, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3294, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3216, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3226, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3273, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3104, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3229, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3203, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3242, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3198, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3212, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3347, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3250, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3230, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3239, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3229, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3203, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3259, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3252, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3402, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3214, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3268, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3213, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3311, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3185, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3275, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3257, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3236, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3323, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3343, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3302, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3205, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3194, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3197, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3251, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3196, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3156, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3276, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3216, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3249, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3257, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3230, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3289, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3253, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3241, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3238, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3214, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3269, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3293, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3260, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3260, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3174, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3208, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3297, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3221, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3207, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3212, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3245, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3192, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3295, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3240, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3263, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3202, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3158, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3171, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3275, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3126, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3226, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3264, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3286, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3195, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3213, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3261, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3224, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3213, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3228, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3317, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3174, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3226, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3258, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3261, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3241, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3249, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3181, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3293, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3186, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3261, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3150, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3235, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3209, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3242, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3172, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3281, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3316, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3295, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3216, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3269, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3233, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3272, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3158, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3195, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3181, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3217, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3129, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3180, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3135, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3261, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3326, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3142, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3202, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3280, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3215, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3145, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3310, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3200, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3288, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3290, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3304, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3175, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3165, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3164, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3176, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3250, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3123, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3212, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3223, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3335, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3241, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3171, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3229, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3291, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3166, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3225, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3267, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3293, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3250, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3257, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3295, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3233, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3162, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3245, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3275, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3269, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3347, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3247, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3142, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3173, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3132, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3236, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3170, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3164, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3288, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3180, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3184, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3226, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3162, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3221, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3184, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3239, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3218, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3237, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3242, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3194, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3262, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3284, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3225, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3322, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3216, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Full Model\n",
    "# hyperparameters\n",
    "epochs = 300\n",
    "torch.cuda.empty_cache()\n",
    "model = EncoderDecoderModel(encoder = encoder, decoder = decoder).to(device)\n",
    "\n",
    "# define optimizers\n",
    "#emb_opt = torch.optim.Adam(embedder.parameters(), lr = 1e-3)\n",
    "enc_dec_opt = torch.optim.Adam(model.parameters(), lr = 1e-6)\n",
    "\n",
    "# define encoder decoder\n",
    "\n",
    "# train enc to end\n",
    "for i in range(epochs):\n",
    "    # zero out gradients for new iteration\n",
    "    #emb_opt.zero_grad()\n",
    "    enc_dec_opt.zero_grad()\n",
    "    \n",
    "    # get outputs and loss\n",
    "    inp_emb = embedder(full_x).transpose(1, 0)\n",
    "    outputs = model(inputs_embeds = inp_emb, decoder_input_ids = labels, decoder_attention_mask = mask, labels = labels)\n",
    "    loss = outputs.loss\n",
    "    \n",
    "    #if i == 40:\n",
    "    #    enc_dec_opt = torch.optim.Adam(model.parameters(), lr = 1e-4)\n",
    "    #if i == 60:\n",
    "    #    enc_dec_opt = torch.optim.Adam(model.parameters(), lr = 1e-5)\n",
    "    #if i == 180:\n",
    "    #    enc_dec_opt = torch.optim.Adam(model.parameters(), lr = 1e-6)\n",
    "    #if i == 210:\n",
    "    #    enc_dec_opt = torch.optim.Adam(model.parameters(), lr = 1e-7)\n",
    "    \n",
    "    # perform gradient descent\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    #emb_opt.step()\n",
    "    enc_dec_opt.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([52, 100, 256])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'new_ones'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-8dc370c52a3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minp_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;31m# init `attention_mask` depending on `pad_token_id`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m             model_kwargs[\"attention_mask\"] = self._prepare_attention_mask_for_generation(\n\u001b[0;32m--> 909\u001b[0;31m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_token_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meos_token_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m             )\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36m_prepare_attention_mask_for_generation\u001b[0;34m(self, input_ids, pad_token_id, eos_token_id)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_pad_token_in_inputs_ids\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_pad_token_not_equal_to_eos_token_id\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_token_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_ones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     def _prepare_encoder_decoder_kwargs_for_generation(\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'new_ones'"
     ]
    }
   ],
   "source": [
    "inp_emb = embedder(full_x).transpose(1, 0)\n",
    "print(inp_emb.shape)\n",
    "model.generate(inputs_embeds = inp_emb)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
