{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all packages needed\n",
    "import string, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "from base64 import b64decode as decode\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2Config\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing / Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_data_id</th>\n",
       "      <th>waveform_id</th>\n",
       "      <th>WavfmType</th>\n",
       "      <th>lead_id</th>\n",
       "      <th>lead_byte_count_total</th>\n",
       "      <th>lead_time_offset</th>\n",
       "      <th>waveform_data</th>\n",
       "      <th>lead_sample_count_total</th>\n",
       "      <th>lead_amplitude</th>\n",
       "      <th>lead_units</th>\n",
       "      <th>...</th>\n",
       "      <th>exam_id</th>\n",
       "      <th>waveform_type</th>\n",
       "      <th>number_of_leads</th>\n",
       "      <th>Waveform_Start_Time</th>\n",
       "      <th>Sample_Type</th>\n",
       "      <th>Sample_Base</th>\n",
       "      <th>Sample_Exponent</th>\n",
       "      <th>High_Pass_Filter</th>\n",
       "      <th>Low_Pass_Filter</th>\n",
       "      <th>AC_Filter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>9078054</td>\n",
       "      <td>1095618</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>+P/4//j/+P/4//j/+P/5//r/+//8//z//P/7//r/+f/4/...</td>\n",
       "      <td>2500</td>\n",
       "      <td>4.88</td>\n",
       "      <td>MICROVOLTS</td>\n",
       "      <td>...</td>\n",
       "      <td>549871</td>\n",
       "      <td>Rhythm</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>CONTINUOUS_SAMPLES</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>9081703</td>\n",
       "      <td>1095618</td>\n",
       "      <td>NaN</td>\n",
       "      <td>II</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>9v/2//b/8//w//D/8P/x//L/8//0//T/9P/z//L/8f/w/...</td>\n",
       "      <td>2500</td>\n",
       "      <td>4.88</td>\n",
       "      <td>MICROVOLTS</td>\n",
       "      <td>...</td>\n",
       "      <td>549871</td>\n",
       "      <td>Rhythm</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>CONTINUOUS_SAMPLES</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9074278</td>\n",
       "      <td>1095618</td>\n",
       "      <td>NaN</td>\n",
       "      <td>V1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>/v/+//7//v/+////AAAAAAAAAQACAAIAAgACAAIAAgACA...</td>\n",
       "      <td>2500</td>\n",
       "      <td>4.88</td>\n",
       "      <td>MICROVOLTS</td>\n",
       "      <td>...</td>\n",
       "      <td>549871</td>\n",
       "      <td>Rhythm</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>CONTINUOUS_SAMPLES</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>9066887</td>\n",
       "      <td>1095618</td>\n",
       "      <td>NaN</td>\n",
       "      <td>V2</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>9v/1//T/9P/0//T/9P/0//T/9f/2//b/9v/2//b/9v/2/...</td>\n",
       "      <td>2500</td>\n",
       "      <td>4.88</td>\n",
       "      <td>MICROVOLTS</td>\n",
       "      <td>...</td>\n",
       "      <td>549871</td>\n",
       "      <td>Rhythm</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>CONTINUOUS_SAMPLES</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>9082771</td>\n",
       "      <td>1095618</td>\n",
       "      <td>NaN</td>\n",
       "      <td>V3</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>7v/u/+7/7f/s/+z/7P/t/+7/7v/u/+7/7v/u/+7/7v/u/...</td>\n",
       "      <td>2500</td>\n",
       "      <td>4.88</td>\n",
       "      <td>MICROVOLTS</td>\n",
       "      <td>...</td>\n",
       "      <td>549871</td>\n",
       "      <td>Rhythm</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>CONTINUOUS_SAMPLES</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>9187141</td>\n",
       "      <td>1109067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>V4</td>\n",
       "      <td>1200</td>\n",
       "      <td>0</td>\n",
       "      <td>KAApACoAKwAsACwALQAtAC4ALgAuAC4ALgAuAC4ALgAvA...</td>\n",
       "      <td>600</td>\n",
       "      <td>4.88</td>\n",
       "      <td>MICROVOLTS</td>\n",
       "      <td>...</td>\n",
       "      <td>554080</td>\n",
       "      <td>Rhythm</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>CONTINUOUS_SAMPLES</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>150</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>9190675</td>\n",
       "      <td>1109067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>V5</td>\n",
       "      <td>1200</td>\n",
       "      <td>0</td>\n",
       "      <td>FgAXABkAGQAbABsAGwAbABsAGwAbABwAHQAeAB4AHgAfA...</td>\n",
       "      <td>600</td>\n",
       "      <td>4.88</td>\n",
       "      <td>MICROVOLTS</td>\n",
       "      <td>...</td>\n",
       "      <td>554080</td>\n",
       "      <td>Rhythm</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>CONTINUOUS_SAMPLES</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>150</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>9177603</td>\n",
       "      <td>1109067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>V5</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>+v/6//r/+v/7//z//f/+//z//P/8//z//v/+//7//v/+/...</td>\n",
       "      <td>5000</td>\n",
       "      <td>4.88</td>\n",
       "      <td>MICROVOLTS</td>\n",
       "      <td>...</td>\n",
       "      <td>554080</td>\n",
       "      <td>Rhythm</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>CONTINUOUS_SAMPLES</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>150</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>9172851</td>\n",
       "      <td>1109067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>V6</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>7v/u/+7/7v/x//L/8//0//T/9P/0//T/9P/0//T/9P/0/...</td>\n",
       "      <td>5000</td>\n",
       "      <td>4.88</td>\n",
       "      <td>MICROVOLTS</td>\n",
       "      <td>...</td>\n",
       "      <td>554080</td>\n",
       "      <td>Rhythm</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>CONTINUOUS_SAMPLES</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>150</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>9173608</td>\n",
       "      <td>1109067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>V6</td>\n",
       "      <td>1200</td>\n",
       "      <td>0</td>\n",
       "      <td>CgAKAAoACwAMAAwADAAMAAwADQAOAA8AEAASABIAEgASA...</td>\n",
       "      <td>600</td>\n",
       "      <td>4.88</td>\n",
       "      <td>MICROVOLTS</td>\n",
       "      <td>...</td>\n",
       "      <td>554080</td>\n",
       "      <td>Rhythm</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>CONTINUOUS_SAMPLES</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>150</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     lead_data_id  waveform_id  WavfmType lead_id  lead_byte_count_total  \\\n",
       "10        9078054      1095618        NaN       I                   5000   \n",
       "15        9081703      1095618        NaN      II                   5000   \n",
       "8         9074278      1095618        NaN      V1                   5000   \n",
       "1         9066887      1095618        NaN      V2                   5000   \n",
       "18        9082771      1095618        NaN      V3                   5000   \n",
       "..            ...          ...        ...     ...                    ...   \n",
       "150       9187141      1109067        NaN      V4                   1200   \n",
       "152       9190675      1109067        NaN      V5                   1200   \n",
       "155       9177603      1109067        NaN      V5                  10000   \n",
       "140       9172851      1109067        NaN      V6                  10000   \n",
       "141       9173608      1109067        NaN      V6                   1200   \n",
       "\n",
       "     lead_time_offset                                      waveform_data  \\\n",
       "10                  0   +P/4//j/+P/4//j/+P/5//r/+//8//z//P/7//r/+f/4/...   \n",
       "15                  0   9v/2//b/8//w//D/8P/x//L/8//0//T/9P/z//L/8f/w/...   \n",
       "8                   0   /v/+//7//v/+////AAAAAAAAAQACAAIAAgACAAIAAgACA...   \n",
       "1                   0   9v/1//T/9P/0//T/9P/0//T/9f/2//b/9v/2//b/9v/2/...   \n",
       "18                  0   7v/u/+7/7f/s/+z/7P/t/+7/7v/u/+7/7v/u/+7/7v/u/...   \n",
       "..                ...                                                ...   \n",
       "150                 0   KAApACoAKwAsACwALQAtAC4ALgAuAC4ALgAuAC4ALgAvA...   \n",
       "152                 0   FgAXABkAGQAbABsAGwAbABsAGwAbABwAHQAeAB4AHgAfA...   \n",
       "155                 0   +v/6//r/+v/7//z//f/+//z//P/8//z//v/+//7//v/+/...   \n",
       "140                 0   7v/u/+7/7v/x//L/8//0//T/9P/0//T/9P/0//T/9P/0/...   \n",
       "141                 0   CgAKAAoACwAMAAwADAAMAAwADQAOAA8AEAASABIAEgASA...   \n",
       "\n",
       "     lead_sample_count_total  lead_amplitude  lead_units  ...  exam_id  \\\n",
       "10                      2500            4.88  MICROVOLTS  ...   549871   \n",
       "15                      2500            4.88  MICROVOLTS  ...   549871   \n",
       "8                       2500            4.88  MICROVOLTS  ...   549871   \n",
       "1                       2500            4.88  MICROVOLTS  ...   549871   \n",
       "18                      2500            4.88  MICROVOLTS  ...   549871   \n",
       "..                       ...             ...         ...  ...      ...   \n",
       "150                      600            4.88  MICROVOLTS  ...   554080   \n",
       "152                      600            4.88  MICROVOLTS  ...   554080   \n",
       "155                     5000            4.88  MICROVOLTS  ...   554080   \n",
       "140                     5000            4.88  MICROVOLTS  ...   554080   \n",
       "141                      600            4.88  MICROVOLTS  ...   554080   \n",
       "\n",
       "     waveform_type  number_of_leads  Waveform_Start_Time         Sample_Type  \\\n",
       "10          Rhythm                8                    0  CONTINUOUS_SAMPLES   \n",
       "15          Rhythm                8                    0  CONTINUOUS_SAMPLES   \n",
       "8           Rhythm                8                    0  CONTINUOUS_SAMPLES   \n",
       "1           Rhythm                8                    0  CONTINUOUS_SAMPLES   \n",
       "18          Rhythm                8                    0  CONTINUOUS_SAMPLES   \n",
       "..             ...              ...                  ...                 ...   \n",
       "150         Rhythm                8                    0  CONTINUOUS_SAMPLES   \n",
       "152         Rhythm                8                    0  CONTINUOUS_SAMPLES   \n",
       "155         Rhythm                8                    0  CONTINUOUS_SAMPLES   \n",
       "140         Rhythm                8                    0  CONTINUOUS_SAMPLES   \n",
       "141         Rhythm                8                    0  CONTINUOUS_SAMPLES   \n",
       "\n",
       "     Sample_Base  Sample_Exponent  High_Pass_Filter Low_Pass_Filter  AC_Filter  \n",
       "10           250                0                 5             150       NONE  \n",
       "15           250                0                 5             150       NONE  \n",
       "8            250                0                 5             150       NONE  \n",
       "1            250                0                 5             150       NONE  \n",
       "18           250                0                 5             150       NONE  \n",
       "..           ...              ...               ...             ...        ...  \n",
       "150          500                0                16             150       NONE  \n",
       "152          500                0                16             150       NONE  \n",
       "155          500                0                16             150       NONE  \n",
       "140          500                0                16             150       NONE  \n",
       "141          500                0                16             150       NONE  \n",
       "\n",
       "[160 rows x 29 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use class base64 to decode waveform data\n",
    "def to_array(wf):\n",
    "    barr = bytearray(decode(wf))\n",
    "    vals = np.array(barr)\n",
    "    return vals.view(np.int16).astype(np.float32)\n",
    "\n",
    "# read in data\n",
    "exam_data = pd.read_csv(\"data/d_exam.csv\").drop(columns = [\"site_num\", \"patient_id_edit\"])\n",
    "waveform_data = pd.read_csv(\"data/d_waveform.csv\")\n",
    "lead_data = pd.read_csv(\"data/d_lead_data.csv\").drop(columns = [\"exam_id\"])\n",
    "diagnosis_data = pd.read_csv(\"data/d_diagnosis.csv\").drop(columns = [\"user_input\"])\n",
    "\n",
    "# add decoded data as a column to lead data\n",
    "waveforms = list(lead_data['waveform_data'])\n",
    "lead_data['decoded_waveform'] = [to_array(i) for i in waveforms]\n",
    "\n",
    "# merge waveform data and lead data\n",
    "waveform_lead = lead_data.merge(waveform_data, how = \"left\", left_on = \"waveform_id\", right_on = \"waveform_id\", suffixes = (None, None))\n",
    "\n",
    "#  sort by exam id and lead id\n",
    "waveform_lead.sort_values(by = [\"waveform_id\", \"lead_id\"], inplace = True)\n",
    "\n",
    "waveform_lead.loc[:, ['exam_id', 'lead_id', 'decoded_waveform', 'waveform_type']]\n",
    "waveform_lead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.63183594\n",
      "0.3154297\n",
      "0.75097656\n",
      "0.31347656\n",
      "0.7832031\n",
      "0.08496094\n",
      "0.8984375\n",
      "0.29296875\n",
      "0.78222656\n",
      "0.31152344\n",
      "0.8417969\n",
      "0.19335938\n",
      "0.6904297\n",
      "0.33691406\n",
      "0.6972656\n",
      "0.40234375\n"
     ]
    }
   ],
   "source": [
    "# concatenate all leads into a single array\n",
    "waveform_lead_concat = waveform_lead.groupby([\"exam_id\", \"waveform_type\"])['decoded_waveform'].apply(lambda x: tuple(x)).reset_index()\n",
    "waveform_lead_concat\n",
    "# remove irregular observations, concat tuple into numpy array\n",
    "waveform_lead_concat = waveform_lead_concat.drop([12,17], axis = 0)\n",
    "waveform_lead_concat['decoded_waveform'] = waveform_lead_concat['decoded_waveform'].apply(lambda x: np.vstack(x))#.apply(lambda x: np.transpose(x))\n",
    "\n",
    "waveform_lead_rhythm = waveform_lead_concat[waveform_lead_concat['waveform_type'] == \"Rhythm\"]\n",
    "#waveform_lead_median = waveform_lead_concat[waveform_lead_concat['waveform_type'] == \"Median\"]\n",
    "\n",
    "for value in waveform_lead_rhythm[\"decoded_waveform\"]:\n",
    "    value /= 1024\n",
    "    value += .5\n",
    "    print(np.max(value))\n",
    "    print(np.min(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal sinus rhythm low voltage qrs borderline ecg\n",
      "sinus bradycardia otherwise normal ecg\n",
      "sinus tachycardia otherwise normal ecg\n",
      "normal sinus rhythm normal ecg\n",
      "normal sinus rhythm normal ecg\n",
      "normal sinus rhythm with sinus arrhythmia minimal voltage criteria for lvh may be normal variant borderline ecg\n",
      "atrial fibrillation abnormal ecg normal sinus rhythm with sinus arrhythmia normal ecg\n"
     ]
    }
   ],
   "source": [
    "# Adding the labels/sentences\n",
    "exams = diagnosis_data[\"exam_id\"].unique()\n",
    "\n",
    "# Let's look over this tomorrow\n",
    "diagnosis_data = diagnosis_data[diagnosis_data['Original_Diag'] == 1].dropna()\n",
    "searchfor = ['previous', 'unconfirmed', 'compared', 'interpretation', 'significant']\n",
    "diagnosis_data = diagnosis_data.loc[diagnosis_data['Full_text'].str.contains('|'.join(searchfor)) != 1]\n",
    "#\n",
    "\n",
    "diagnosis_data.sort_values(by=[\"exam_id\", \"statement_order\"], inplace=True)\n",
    "diagnoses = []\n",
    "curr_id = 0\n",
    "curr_string = \"\"\n",
    "for i, row in diagnosis_data.iterrows():\n",
    "    if row[\"statement_order\"] == 1 and curr_string != \"\":\n",
    "        curr_string = curr_string.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "        val = [curr_id, curr_string[1:]]\n",
    "        diagnoses.append(val)\n",
    "        curr_string = \"\"\n",
    "        curr_id = row[\"exam_id\"]\n",
    "\n",
    "    if curr_id == 0:\n",
    "        curr_id = row[\"exam_id\"]\n",
    "    \n",
    "    curr_string += \" \" + row[\"Full_text\"]\n",
    "\n",
    "diagnosis_df = pd.DataFrame(diagnoses, columns = ['exam_id', 'diagnosis'])\n",
    "waveform_lead_rhythm_diag = pd.merge(left=waveform_lead_rhythm, right=diagnosis_df, left_on='exam_id', right_on='exam_id')\n",
    "\n",
    "#waveform_lead_rhythm_diag\n",
    "for i in waveform_lead_rhythm_diag[\"diagnosis\"]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'variant', 'arrhythmia', 'qrs', 'rhythm', 'ecg', 't', 'low', 'abnormality', 'sinus', 'for', 'tachycardia', 'be', 'inferior', 'otherwise', 'may', 'minimal', 'with', 'wave', 'fibrillation', 'bradycardia', 'ischemia', 'lvh', 'normal', 'voltage', 'atrial', 'borderline', 'consider', 'abnormal', 'criteria'}\n",
      "{'variant': 1, 'arrhythmia': 2, 'qrs': 3, 'rhythm': 4, 'ecg': 5, 't': 6, 'low': 7, 'abnormality': 8, 'sinus': 9, 'for': 10, 'tachycardia': 11, 'be': 12, 'inferior': 13, 'otherwise': 14, 'may': 15, 'minimal': 16, 'with': 17, 'wave': 18, 'fibrillation': 19, 'bradycardia': 20, 'ischemia': 21, 'lvh': 22, 'normal': 23, 'voltage': 24, 'atrial': 25, 'borderline': 26, 'consider': 27, 'abnormal': 28, 'criteria': 29, '': 0}\n"
     ]
    }
   ],
   "source": [
    "unique_words = set()\n",
    "for num, sentence in diagnoses:\n",
    "    for word in sentence.split():\n",
    "        unique_words.add(word)\n",
    "print(unique_words)\n",
    "unique_words = list(unique_words)\n",
    "word_map = dict()\n",
    "for i, word in enumerate(unique_words):\n",
    "    word_map[word] = i+1\n",
    "word_map[\"\"] = 0\n",
    "print(word_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 8, 2500])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split data into training and testing datasets\n",
    "# y not included for now\n",
    "def one_hot(x, dict_words):\n",
    "    x = x.split(\" \")\n",
    "    array = []\n",
    "    for i in x:\n",
    "        array.append([0] + [1 if y == i else 0 for y in dict_words] + [0,0])\n",
    "    for i in range(17-len(x)):\n",
    "        array.append([1 if i == 30 else 0 for i in range(32)])\n",
    "    return array\n",
    "\n",
    "dict_words = list(unique_words)\n",
    "#waveform_lead_rhythm_diag['diagnosis'] = waveform_lead_rhythm_diag['diagnosis'].apply(lambda x: one_hot(x, dict_words))\n",
    "\n",
    "len(waveform_lead_rhythm_diag[\"diagnosis\"][5])\n",
    "train_x, test_x, train_y, test_y = train_test_split(waveform_lead_rhythm_diag['decoded_waveform'], waveform_lead_rhythm_diag['diagnosis'], test_size = 0.1, random_state = 2021)\n",
    "train_x = torch.tensor(list(train_x)).float()\n",
    "train_x.shape\n",
    "train_x = torch.tensor(list(waveform_lead_rhythm_diag['decoded_waveform'])).float()\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 - Conv1D Encoder w/ LSTM Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 2500])\n",
      "torch.Size([1, 64, 31])\n"
     ]
    }
   ],
   "source": [
    "# HYPERPARAMETERS\n",
    "J = 8 # max number of filters per class\n",
    "LR = 1e-3\n",
    "\n",
    "# define global max pooling\n",
    "class global_max_pooling_1d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x, _ = torch.max(x, dim = 2)\n",
    "        return(x)\n",
    "\n",
    "# 1D grouped encoder model\n",
    "encoder_conv = nn.Sequential()\n",
    "encoder_conv.add_module('initial_norm', nn.BatchNorm1d(8))\n",
    "encoder_conv.add_module('conv_1', nn.Conv1d(in_channels = 8, out_channels = 8, groups = 8, kernel_size = 5, padding = 2))\n",
    "for i in range(2, (J+2), 2):\n",
    "    if (i-2) == 0: \n",
    "        prev = 8\n",
    "    else:\n",
    "        prev = (i-2)*8\n",
    "    encoder_conv.add_module('conv_{num}'.format(num = int(i / 2 + 1)), nn.Conv1d(in_channels = prev, out_channels = i*8, groups = 8, kernel_size = 5, padding = 2, stride = 3))\n",
    "    encoder_conv.add_module('activation_{num}'.format(num = int(i / 2 + 1)), nn.ELU())\n",
    "    encoder_conv.add_module('batch_norm_{num}'.format(num = int(i / 2 + 1)), nn.BatchNorm1d(i*8))\n",
    "    \n",
    "#encoder_conv.add_module('final_conv', nn.Conv1d(in_channels = J * 8, out_channels = 8, groups = 8, kernel_size = 5, padding = 2))\n",
    "#encoder_conv.add_module('max_pool', nn.MaxPool1d(kernel_size = 5, padding = 2, stride = 1))\n",
    "encoder_conv.add_module('reshape', nn.MaxPool1d(kernel_size = 5, padding = 2, stride = 1))\n",
    "\n",
    "\n",
    "# summarize model, verify output is of desired shape\n",
    "print(train_x[0].shape)\n",
    "print(encoder_conv(torch.unsqueeze(train_x[0], 0)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (conv_0): Conv1d(8, 16, kernel_size=(11,), stride=(1,), padding=(5,))\n",
      "  (act_0): ReLU()\n",
      "  (batch_norm_0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (res_0): ResBlock1D(\n",
      "    (act): ReLU()\n",
      "    (conv1d_1): Conv1d(16, 16, kernel_size=(11,), stride=(1,), padding=(5,))\n",
      "    (conv1d_2): Conv1d(16, 16, kernel_size=(11,), stride=(1,), padding=(5,))\n",
      "    (batch_norm_1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (batch_norm_2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (act_res_0): ReLU()\n",
      "  (conv_1): Conv1d(16, 32, kernel_size=(11,), stride=(1,), padding=(5,))\n",
      "  (act_1): ReLU()\n",
      "  (batch_norm_1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (res_1): ResBlock1D(\n",
      "    (act): ReLU()\n",
      "    (conv1d_1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))\n",
      "    (conv1d_2): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))\n",
      "    (batch_norm_1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (batch_norm_2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (act_res_1): ReLU()\n",
      "  (conv_2): Conv1d(32, 64, kernel_size=(11,), stride=(1,), padding=(5,))\n",
      "  (act_2): ReLU()\n",
      "  (batch_norm_2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (res_2): ResBlock1D(\n",
      "    (act): ReLU()\n",
      "    (conv1d_1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))\n",
      "    (conv1d_2): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))\n",
      "    (batch_norm_1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (batch_norm_2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (act_res_2): ReLU()\n",
      "  (conv_3): Conv1d(64, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
      "  (act_3): ReLU()\n",
      "  (batch_norm_3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (res_3): ResBlock1D(\n",
      "    (act): ReLU()\n",
      "    (conv1d_1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
      "    (conv1d_2): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
      "    (batch_norm_1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (batch_norm_2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (act_res_3): ReLU()\n",
      "  (conv_4): Conv1d(128, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
      "  (act_4): ReLU()\n",
      "  (batch_norm_4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (res_4): ResBlock1D(\n",
      "    (act): ReLU()\n",
      "    (conv1d_1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
      "    (conv1d_2): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
      "    (batch_norm_1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (batch_norm_2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (act_res_4): ReLU()\n",
      "  (conv_fin): Conv1d(256, 768, kernel_size=(11,), stride=(1,), padding=(5,))\n",
      "  (act_fin): ReLU()\n",
      "  (batch_fin): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# ResConv\n",
    "\n",
    "# HYPERPARAMETERS\n",
    "J = 10 # max number of filters per class\n",
    "LR = 1e-3\n",
    "KER_SIZE = 11\n",
    "PADDING = 5\n",
    "# define global max pooling\n",
    "class global_max_pooling_1d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x, _ = torch.max(x, dim = 2)\n",
    "        return(x)\n",
    "\n",
    "# define resblock for neural nets\n",
    "class ResBlock1D(nn.Module):\n",
    "    def __init__(self, num_filters, kernel_size, padding, groups = 1, stride = 1):\n",
    "        super(ResBlock1D, self).__init__()\n",
    "        self.act = nn.ReLU()\n",
    "        self.conv1d_1 = nn.Conv1d(num_filters, num_filters, kernel_size = kernel_size, padding = padding, groups = groups, stride = 1)\n",
    "        self.conv1d_2 = nn.Conv1d(num_filters, num_filters, kernel_size = kernel_size, padding = padding, groups = groups, stride = 1)\n",
    "        self.batch_norm_1 = nn.BatchNorm1d(num_filters)\n",
    "        self.batch_norm_2 = nn.BatchNorm1d(num_filters)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        x = self.batch_norm_1(self.act(self.conv1d_1(x)))\n",
    "        x = self.batch_norm_2(self.act(self.conv1d_2(x)))\n",
    "        return x + res\n",
    "\n",
    "conv_model = nn.Sequential()\n",
    "init_channels = 8\n",
    "for i in range(5):\n",
    "    next_channels = 2 * init_channels\n",
    "    conv_model.add_module('conv_{num}'.format(num = i), nn.Conv1d(in_channels = init_channels, out_channels = next_channels, kernel_size = KER_SIZE, padding = PADDING, stride = 1))\n",
    "    conv_model.add_module('act_{num}'.format(num = i), nn.ReLU())\n",
    "    conv_model.add_module('batch_norm_{num}'.format(num = i), nn.BatchNorm1d(next_channels))\n",
    "    conv_model.add_module('res_{num}'.format(num = i), ResBlock1D(num_filters = next_channels, kernel_size = KER_SIZE, padding = PADDING))\n",
    "    conv_model.add_module('act_res_{num}'.format(num = i), nn.ReLU())\n",
    "    init_channels = next_channels\n",
    "conv_model.add_module('conv_fin', nn.Conv1d(in_channels = init_channels, out_channels = 768, kernel_size = KER_SIZE, padding = PADDING))\n",
    "conv_model.add_module('act_fin', nn.ReLU())\n",
    "conv_model.add_module('batch_fin', nn.BatchNorm1d(768))\n",
    "print(conv_model)\n",
    "#print(conv_model(train_x).shape)\n",
    "conv_embedder = conv_model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 8, 2500])\n",
      "torch.Size([7, 2500, 8])\n",
      "torch.Size([7, 768, 2500])\n",
      "torch.Size([7, 8, 2500])\n"
     ]
    }
   ],
   "source": [
    "deconv_model = nn.Sequential()\n",
    "init_channels = 768\n",
    "for i in range(5):\n",
    "    next_channels = init_channels // 2\n",
    "    deconv_model.add_module('conv_{num}'.format(num = i), nn.Conv1d(in_channels = init_channels, out_channels = next_channels, kernel_size = KER_SIZE, padding = PADDING, stride = 1))\n",
    "    deconv_model.add_module('act_{num}'.format(num = i), nn.ReLU())\n",
    "    deconv_model.add_module('batch_norm_{num}'.format(num = i), nn.BatchNorm1d(next_channels))\n",
    "    deconv_model.add_module('res_{num}'.format(num = i), ResBlock1D(num_filters = next_channels, kernel_size = KER_SIZE, padding = PADDING))\n",
    "    deconv_model.add_module('act_res_{num}'.format(num = i), nn.ReLU())\n",
    "    init_channels = next_channels\n",
    "deconv_model.add_module('conv_fin', nn.Conv1d(in_channels = init_channels, out_channels = 8, kernel_size = KER_SIZE, padding = PADDING))\n",
    "deconv_model.add_module('act_fin', nn.ReLU())\n",
    "deconv_model.add_module('batch_fin', nn.BatchNorm1d(8))\n",
    "\n",
    "print(train_x.shape)\n",
    "print(data.shape)\n",
    "print(conv_model(train_x).shape)\n",
    "print(deconv_model(conv_model(train_x)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAutoEncoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(ConvAutoEncoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "    \n",
    "    def make_encoder(self):\n",
    "        return self.encoder\n",
    "    \n",
    "    def make_decoder(self):\n",
    "        return self.decoder\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Model to set to\n",
    "auto_model = ConvAutoEncoder(conv_model, deconv_model)\n",
    "auto_optimizer = torch.optim.Adam(auto_model.parameters(), lr = 1e-3)\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Training params\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "#print(train_x[0])\n",
    "for i in range(180):\n",
    "    #print(train_x.shape)\n",
    "    auto_optimizer.zero_grad()\n",
    "    outputs = auto_model(train_x)\n",
    "    #print(outputs.shape)\n",
    "    losses = loss_function(outputs, train_x)\n",
    "    losses.backward(retain_graph=True)\n",
    "    auto_optimizer.step()\n",
    "    print(losses)\n",
    "    if losses < .001:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(auto_model.state_dict(), 'model/autoencoder.pt')\n",
    "\n",
    "conv_embedder = auto_model.make_encoder()\n",
    "\n",
    "\n",
    "torch.save(conv_embedder.state_dict(), \"model/embedder.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 - LSTM Encoder w/ Huggingface Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unique_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2f894452ad6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mhidden_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m512\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0membedding_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mnum_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mECG_LSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'unique_words' is not defined"
     ]
    }
   ],
   "source": [
    "# define hyperparameters \n",
    "hidden_layers = 512\n",
    "embedding_dim = 8\n",
    "num_words = len(unique_words)\n",
    "\n",
    "class ECG_LSTM(nn.Module):\n",
    "    def __init__(self, encoder, h_dim, e_dim, word_list_length):\n",
    "        super(ECG_LSTM, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.lstm = nn.LSTM(e_dim, h_dim)\n",
    "        self.linear = nn.Linear(h_dim, word_list_length)\n",
    "        \n",
    "    def forward(self, seq):\n",
    "        seq_embedded = self.encoder(seq)\n",
    "        final_hidd, _ = self.lstm(seq_embedded)\n",
    "        dec_seq = self.linear(final_hidd)\n",
    "        return F.log_softmax(dec_seq)\n",
    "    \n",
    "lstm_dec = ECG_LSTM(encoder_conv, hidden_layers, embedding_dim, num_words)\n",
    "lstm_dec(train_x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 - Basic Transformer Architecture with Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 2500, 8])\n",
      "torch.Size([7, 768, 2500])\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "new_data = conv_embedder(train_x)\n",
    "print(new_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 2.0995, -0.5898, -0.4277,  ...,  3.1599, -0.5898,  7.7721],\n",
      "         [-0.5547,  0.6758, -0.5547,  ..., -0.5547, -0.5547,  3.1045],\n",
      "         [-0.5680, -0.5680,  2.9091,  ...,  0.8775, -0.5680,  1.5757],\n",
      "         ...,\n",
      "         [-0.5168,  1.1706,  0.0231,  ..., -0.5168, -0.5168,  3.2656],\n",
      "         [-0.4377,  2.8713,  0.2086,  ..., -0.4377,  2.6868,  0.6346],\n",
      "         [ 0.8298, -0.3843, -0.3843,  ..., -0.3843, -0.3843, -0.3843]],\n",
      "\n",
      "        [[-0.5898, -0.5898, -0.5898,  ..., 11.0307, -0.5898,  6.4339],\n",
      "         [-0.5547,  1.8430, -0.5547,  ..., -0.5547, -0.5547,  0.7982],\n",
      "         [-0.5680, -0.4991,  1.5885,  ..., -0.5680,  3.4990, -0.5680],\n",
      "         ...,\n",
      "         [-0.5168, -0.5168, -0.5168,  ..., 12.3154, -0.0480, -0.5168],\n",
      "         [-0.4377, -0.4377, -0.4377,  ..., -0.4377,  4.6131, -0.4377],\n",
      "         [ 1.8815, -0.3843, -0.3843,  ..., -0.3843, -0.3843, -0.3843]],\n",
      "\n",
      "        [[-0.5767, -0.5898, -0.5898,  ..., -0.5898, -0.5898,  2.2787],\n",
      "         [ 1.3027, -0.5547, -0.0715,  ..., -0.5547, -0.5547,  1.6808],\n",
      "         [-0.5680, -0.5680,  5.7637,  ..., -0.5680,  1.8905,  2.2515],\n",
      "         ...,\n",
      "         [ 0.3355, -0.5168,  1.6160,  ..., -0.5168, -0.5168, -0.3128],\n",
      "         [-0.4377,  0.3116, -0.4377,  ..., -0.4377,  8.5061, -0.4377],\n",
      "         [-0.3843, -0.3843, -0.3843,  ..., -0.3843, -0.3843, -0.3843]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.6090, -0.5898, -0.5898,  ...,  4.6626, -0.5898,  8.7354],\n",
      "         [-0.5547,  0.1743, -0.5547,  ..., -0.5547, -0.5547,  0.9166],\n",
      "         [-0.5680, -0.5680, -0.5680,  ...,  0.6356, -0.5680, -0.1458],\n",
      "         ...,\n",
      "         [ 1.3961,  0.1610, -0.5168,  ..., -0.5168, -0.4644,  4.8531],\n",
      "         [-0.4377, -0.4370,  2.3456,  ..., -0.4377,  3.8776,  2.4654],\n",
      "         [ 1.9787, -0.3843, -0.3843,  ..., -0.3843, -0.3843, -0.3843]],\n",
      "\n",
      "        [[ 2.8148, -0.5898, -0.5898,  ...,  5.8397, -0.5898,  8.4426],\n",
      "         [-0.5547,  1.8083, -0.5547,  ..., -0.5547, -0.5547,  3.1898],\n",
      "         [-0.5680, -0.5680,  1.4758,  ...,  0.4967, -0.5680,  1.4144],\n",
      "         ...,\n",
      "         [-0.2653,  2.1502, -0.5168,  ..., -0.5168,  3.2571,  1.5762],\n",
      "         [-0.4377, -0.4377, -0.4377,  ..., -0.4377,  3.4432,  4.0219],\n",
      "         [ 4.6946, -0.3843, -0.3843,  ..., -0.3843, -0.3843, -0.3837]],\n",
      "\n",
      "        [[-0.5898, -0.5898, -0.5898,  ...,  4.3355, -0.5898,  7.8368],\n",
      "         [-0.5547,  0.9471, -0.5547,  ..., -0.5547, -0.5547,  3.8864],\n",
      "         [-0.5680,  0.4552,  2.3579,  ..., -0.0696, -0.5680,  3.0510],\n",
      "         ...,\n",
      "         [-0.5168, -0.5168, -0.1033,  ..., -0.5168, -0.5168, -0.1218],\n",
      "         [-0.4377,  0.2357,  0.3837,  ..., -0.4377, -0.4377, -0.4377],\n",
      "         [ 1.7133, -0.3843, -0.3843,  ..., -0.3843, -0.3843, -0.3843]]])\n"
     ]
    }
   ],
   "source": [
    "new_data = new_data.detach()\n",
    "print(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "class ECGTransformerEncoder(nn.Module):\n",
    "    # Takes the ECG discrete signals sequence and maps into a probability distribution of diagnosis\n",
    "    # For working/verification purposes\n",
    "    def __init__(self, vector_size, embed_dim, n_heads, hidden_linear_dim, n_layers, dropout):\n",
    "        super(ECGTransformerEncoder, self).__init__()\n",
    "        self.model_type = \"Transformer\"\n",
    "        self.positional_encoder = PositionalEncoder(embed_dim, dropout)\n",
    "    \n",
    "        #Since our data is already discrete numbers, might need some tweaking for this\n",
    "        self.embedder = conv_embedder\n",
    "                        #64 31              #39        64\n",
    "        \n",
    "        \n",
    "        self.encoder = TransformerEncoder(\n",
    "            TransformerEncoderLayer(embed_dim, n_heads, hidden_linear_dim, dropout),\n",
    "            n_layers)\n",
    "        \n",
    "        self.n_inputs = embed_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        # Simple linear decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "                        nn.Linear(768, 17),\n",
    "                        Transpose(17, 2500),\n",
    "                        nn.Linear(2500, 30),\n",
    "                        nn.LogSoftmax()\n",
    "                        )\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        #self.embedder.weight.data.uniform_(-.1, .1)\n",
    "        #self.decoder.bias.data.zero_()\n",
    "        #self.decoder.weight.data.uniform_(-.1, .1)\n",
    "        pass\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x = self.embedder(x) # * math.sqrt(self.n_inputs)\n",
    "        x = x.squeeze(0)\n",
    "        #x = x.view(2500, 8)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.positional_encoder(x)\n",
    "        x = self.encoder(x)\n",
    "        x = x.squeeze(1) \n",
    "        #x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "class Transpose(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super(Transpose, self).__init__()\n",
    "        self.shape = args\n",
    "\n",
    "    def forward(self, x):\n",
    "        # If the number of the last batch sample in the data set is smaller than the defined batch_batch size, mismatch problems will occur. You can modify it yourself, for example, just pass in the shape behind, and then enter it through x.szie(0).\n",
    "        return x.view(self.shape)\n",
    "\n",
    "class SignalEmbedder(nn.Module):\n",
    "    # Necessary to convert the signal into \"word\" vectors for transformer processing.\n",
    "    # Currently a simple group and slice method, but will modify later for multi-channel inputs\n",
    "    \n",
    "    def __init__(self, num_slices, size_of_slice):\n",
    "        super(SignalEmbedder, self).__init__()\n",
    "        self.num_slices = num_slices\n",
    "        self.size_of_slice = size_of_slice\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x[: self.num_slices * self.size_of_slice]\n",
    "        x = x.reshape((self.num_slices, self.size_of_slice))\n",
    "        return x\n",
    "'''\n",
    "class OneHotConverter(nn.Module):\n",
    "    # Converts the sigmoid output into one-hots\n",
    "    \n",
    "    def __init__(self, size, sentence_length):\n",
    "        super(OneHotConverter, self).__init__()\n",
    "        self.arr_length = size\n",
    "        self.num_words = sentence_length\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = []\n",
    "        for num in x:\n",
    "            num = num.item()\n",
    "            num *= self.arr_length\n",
    "            val = np.zeros(self.arr_length)\n",
    "            val[int(round(num))] = 1\n",
    "        \n",
    "            output.append(val)\n",
    "        output = torch.as_tensor(output)\n",
    "        output.requires_grad_()\n",
    "        return output\n",
    "'''    \n",
    "\n",
    "class PositionalEncoder(nn.Module):\n",
    "    # Necessary to store positional data about the input data\n",
    "    def __init__(self, embed_dim, dropout=0.1, max_len=2500, batch_size = 1):\n",
    "        super(PositionalEncoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        pos_encoding = torch.zeros(max_len, 1, embed_dim)\n",
    "        position = torch.arange(max_len, dtype=torch.float).unsqueeze(1)\n",
    "        \n",
    "        divisor = torch.exp(torch.arange(0, embed_dim, 2).float() * (- math.log(10000.0) / embed_dim))\n",
    "        \n",
    "        pos_encoding[:, 0, 0::2] = torch.sin(position * divisor)\n",
    "        pos_encoding[:, 0, 1::2] = torch.cos(position * divisor)\n",
    "        pos_encoding = pos_encoding.repeat(1, batch_size, 1)\n",
    "        self.register_buffer(\"pos_encoding\", pos_encoding)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.pos_encoding[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9 20 14 23  5  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "tensor([[[0.5039, 0.5059, 0.4980,  ..., 0.5117, 0.5078, 0.5059],\n",
      "         [0.5029, 0.5049, 0.4980,  ..., 0.5088, 0.5049, 0.5039],\n",
      "         [0.5020, 0.5039, 0.4980,  ..., 0.5059, 0.5020, 0.5020],\n",
      "         ...,\n",
      "         [0.4932, 0.4941, 0.5020,  ..., 0.4814, 0.4824, 0.4844],\n",
      "         [0.4902, 0.4922, 0.5059,  ..., 0.4805, 0.4805, 0.4805],\n",
      "         [0.4902, 0.4922, 0.5059,  ..., 0.4805, 0.4805, 0.4805]],\n",
      "\n",
      "        [[0.4922, 0.4902, 0.4980,  ..., 0.4746, 0.4746, 0.4844],\n",
      "         [0.4922, 0.4902, 0.4980,  ..., 0.4756, 0.4756, 0.4854],\n",
      "         [0.4922, 0.4902, 0.4980,  ..., 0.4766, 0.4766, 0.4863],\n",
      "         ...,\n",
      "         [0.5098, 0.5088, 0.4980,  ..., 0.5088, 0.5107, 0.5068],\n",
      "         [0.5059, 0.5020, 0.5000,  ..., 0.4990, 0.5020, 0.5000],\n",
      "         [0.5059, 0.5020, 0.5000,  ..., 0.4990, 0.5020, 0.5000]],\n",
      "\n",
      "        [[0.4785, 0.4961, 0.5078,  ..., 0.5195, 0.5176, 0.5137],\n",
      "         [0.4805, 0.4961, 0.5088,  ..., 0.5215, 0.5195, 0.5146],\n",
      "         [0.4824, 0.4961, 0.5098,  ..., 0.5234, 0.5215, 0.5156],\n",
      "         ...,\n",
      "         [0.3877, 0.4775, 0.4717,  ..., 0.3057, 0.3516, 0.4209],\n",
      "         [0.3672, 0.4609, 0.4590,  ..., 0.2871, 0.3320, 0.3984],\n",
      "         [0.3672, 0.4609, 0.4590,  ..., 0.2871, 0.3320, 0.3984]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.4932, 0.4854, 0.5068,  ..., 0.4805, 0.4775, 0.4834],\n",
      "         [0.4961, 0.4873, 0.5107,  ..., 0.4795, 0.4795, 0.4824],\n",
      "         [0.4990, 0.4893, 0.5137,  ..., 0.4795, 0.4805, 0.4824],\n",
      "         ...,\n",
      "         [0.4844, 0.4883, 0.4941,  ..., 0.4824, 0.4795, 0.4854],\n",
      "         [0.4873, 0.4912, 0.4951,  ..., 0.4814, 0.4795, 0.4854],\n",
      "         [0.4873, 0.4912, 0.4951,  ..., 0.4814, 0.4795, 0.4854]],\n",
      "\n",
      "        [[0.4688, 0.4824, 0.5078,  ..., 0.4746, 0.4766, 0.4844],\n",
      "         [0.4688, 0.4814, 0.5088,  ..., 0.4746, 0.4766, 0.4834],\n",
      "         [0.4688, 0.4805, 0.5098,  ..., 0.4746, 0.4766, 0.4824],\n",
      "         ...,\n",
      "         [0.4893, 0.5020, 0.5176,  ..., 0.4814, 0.4766, 0.4814],\n",
      "         [0.4893, 0.5010, 0.5176,  ..., 0.4805, 0.4766, 0.4814],\n",
      "         [0.4893, 0.5010, 0.5176,  ..., 0.4805, 0.4766, 0.4814]],\n",
      "\n",
      "        [[0.4922, 0.4961, 0.5059,  ..., 0.4941, 0.4941, 0.4922],\n",
      "         [0.4951, 0.4961, 0.5068,  ..., 0.4932, 0.4932, 0.4922],\n",
      "         [0.4980, 0.4961, 0.5078,  ..., 0.4922, 0.4922, 0.4922],\n",
      "         ...,\n",
      "         [0.4941, 0.4824, 0.5088,  ..., 0.4834, 0.4814, 0.4795],\n",
      "         [0.4912, 0.4814, 0.5088,  ..., 0.4824, 0.4805, 0.4795],\n",
      "         [0.4912, 0.4814, 0.5088,  ..., 0.4824, 0.4805, 0.4795]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ECGTransformerEncoder(\n",
       "  (positional_encoder): PositionalEncoder(\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (embedder): Sequential(\n",
       "    (conv_0): Conv1d(8, 16, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "    (act_0): ReLU()\n",
       "    (batch_norm_0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (res_0): ResBlock1D(\n",
       "      (act): ReLU()\n",
       "      (conv1d_1): Conv1d(16, 16, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "      (conv1d_2): Conv1d(16, 16, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "      (batch_norm_1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (batch_norm_2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (act_res_0): ReLU()\n",
       "    (conv_1): Conv1d(16, 32, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "    (act_1): ReLU()\n",
       "    (batch_norm_1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (res_1): ResBlock1D(\n",
       "      (act): ReLU()\n",
       "      (conv1d_1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "      (conv1d_2): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "      (batch_norm_1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (batch_norm_2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (act_res_1): ReLU()\n",
       "    (conv_2): Conv1d(32, 64, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "    (act_2): ReLU()\n",
       "    (batch_norm_2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (res_2): ResBlock1D(\n",
       "      (act): ReLU()\n",
       "      (conv1d_1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "      (conv1d_2): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "      (batch_norm_1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (batch_norm_2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (act_res_2): ReLU()\n",
       "    (conv_3): Conv1d(64, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "    (act_3): ReLU()\n",
       "    (batch_norm_3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (res_3): ResBlock1D(\n",
       "      (act): ReLU()\n",
       "      (conv1d_1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "      (conv1d_2): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "      (batch_norm_1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (batch_norm_2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (act_res_3): ReLU()\n",
       "    (conv_4): Conv1d(128, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "    (act_4): ReLU()\n",
       "    (batch_norm_4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (res_4): ResBlock1D(\n",
       "      (act): ReLU()\n",
       "      (conv1d_1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "      (conv1d_2): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "      (batch_norm_1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (batch_norm_2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (act_res_4): ReLU()\n",
       "    (conv_fin): Conv1d(256, 768, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "    (act_fin): ReLU()\n",
       "    (batch_fin): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.3, inplace=False)\n",
       "        (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.3, inplace=False)\n",
       "        (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=17, bias=True)\n",
       "    (1): Transpose()\n",
       "    (2): Linear(in_features=2500, out_features=30, bias=True)\n",
       "    (3): LogSoftmax(dim=None)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training pipeline\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Model to set to\n",
    "model = ECGTransformerEncoder(vector_size=5, embed_dim=768, n_heads=16, hidden_linear_dim=2048, n_layers=2, dropout=0.3).to(device)\n",
    "\n",
    "# Training params\n",
    "loss_function = nn.L1Loss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "data = []\n",
    "for arr in waveform_lead_rhythm_diag[\"decoded_waveform\"]:\n",
    "    #print(arr)\n",
    "    arr = arr.transpose()\n",
    "    data.append(arr)\n",
    "\n",
    "labels = []\n",
    "for sentence in waveform_lead_rhythm_diag[\"diagnosis\"]:\n",
    "    #label = one_hot(sentence, dict_words)\n",
    "    label = []\n",
    "    for word in sentence.split():\n",
    "        label.append(word_map[word])\n",
    "    \n",
    "    while len(label) < 17:\n",
    "        label.append(0)\n",
    "    labels.append(np.array(label))\n",
    "data = torch.from_numpy(np.array(data, dtype=np.float64)).type(torch.FloatTensor)\n",
    "print(labels[1])\n",
    "labels = torch.from_numpy(np.array(labels))\n",
    "print(data)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7370614409446716\n",
      "loss: 0.6791639924049377\n",
      "loss: 0.3094591200351715\n",
      "loss: 0.5278668403625488\n",
      "loss: 0.34741342067718506\n",
      "loss: 0.21746216714382172\n",
      "loss: 0.4615210294723511\n",
      "epoch loss:  3.2799482345581055\n",
      "loss: 0.734946072101593\n",
      "loss: 0.6778768301010132\n",
      "loss: 0.3100247383117676\n",
      "loss: 0.5258252024650574\n",
      "loss: 0.34639695286750793\n",
      "loss: 0.2173265665769577\n",
      "loss: 0.4615813195705414\n",
      "epoch loss:  3.273977756500244\n",
      "loss: 0.7365527153015137\n",
      "loss: 0.6790151000022888\n",
      "loss: 0.310395210981369\n",
      "loss: 0.5262953639030457\n",
      "loss: 0.3462901711463928\n",
      "loss: 0.21628332138061523\n",
      "loss: 0.46113672852516174\n",
      "epoch loss:  3.2759687900543213\n",
      "loss: 0.7375586032867432\n",
      "loss: 0.6762019395828247\n",
      "loss: 0.3095795214176178\n",
      "loss: 0.5260034799575806\n",
      "loss: 0.3452601432800293\n",
      "loss: 0.2161376029253006\n",
      "loss: 0.4588436782360077\n",
      "epoch loss:  3.269584894180298\n",
      "loss: 0.7332217693328857\n",
      "loss: 0.6752980351448059\n",
      "loss: 0.3084912896156311\n",
      "loss: 0.5254095792770386\n",
      "loss: 0.34439337253570557\n",
      "loss: 0.21576423943042755\n",
      "loss: 0.458468496799469\n",
      "epoch loss:  3.2610466480255127\n",
      "loss: 0.7343229055404663\n",
      "loss: 0.6764134168624878\n",
      "loss: 0.3068646490573883\n",
      "loss: 0.5247707366943359\n",
      "loss: 0.34426477551460266\n",
      "loss: 0.21458059549331665\n",
      "loss: 0.45638176798820496\n",
      "epoch loss:  3.257598638534546\n",
      "loss: 0.7363019585609436\n",
      "loss: 0.6746543049812317\n",
      "loss: 0.3091001808643341\n",
      "loss: 0.5246335864067078\n",
      "loss: 0.3430143892765045\n",
      "loss: 0.21445059776306152\n",
      "loss: 0.45759329199790955\n",
      "epoch loss:  3.2597482204437256\n",
      "loss: 0.7290533781051636\n",
      "loss: 0.6741364002227783\n",
      "loss: 0.305162250995636\n",
      "loss: 0.5231873989105225\n",
      "loss: 0.34186112880706787\n",
      "loss: 0.21375927329063416\n",
      "loss: 0.45524972677230835\n",
      "epoch loss:  3.2424094676971436\n",
      "loss: 0.7324037551879883\n",
      "loss: 0.6769000887870789\n",
      "loss: 0.30595695972442627\n",
      "loss: 0.5226468443870544\n",
      "loss: 0.3405299782752991\n",
      "loss: 0.213170126080513\n",
      "loss: 0.45593076944351196\n",
      "epoch loss:  3.2475383281707764\n",
      "loss: 0.7300575375556946\n",
      "loss: 0.6759232878684998\n",
      "loss: 0.304387629032135\n",
      "loss: 0.5199978947639465\n",
      "loss: 0.3399910032749176\n",
      "loss: 0.21214085817337036\n",
      "loss: 0.45470955967903137\n",
      "epoch loss:  3.2372076511383057\n",
      "loss: 0.7332645654678345\n",
      "loss: 0.6702142357826233\n",
      "loss: 0.3028879463672638\n",
      "loss: 0.5206551551818848\n",
      "loss: 0.3386175036430359\n",
      "loss: 0.21229340136051178\n",
      "loss: 0.4535727798938751\n",
      "epoch loss:  3.2315056324005127\n",
      "loss: 0.7352818846702576\n",
      "loss: 0.6709439158439636\n",
      "loss: 0.3023867607116699\n",
      "loss: 0.519598126411438\n",
      "loss: 0.3393339514732361\n",
      "loss: 0.21062014997005463\n",
      "loss: 0.4519263803958893\n",
      "epoch loss:  3.2300913333892822\n",
      "loss: 0.7286512851715088\n",
      "loss: 0.6691531538963318\n",
      "loss: 0.30451709032058716\n",
      "loss: 0.5203612446784973\n",
      "loss: 0.3383707106113434\n",
      "loss: 0.21124595403671265\n",
      "loss: 0.45173969864845276\n",
      "epoch loss:  3.224039316177368\n",
      "loss: 0.7318467497825623\n",
      "loss: 0.6699748635292053\n",
      "loss: 0.30115246772766113\n",
      "loss: 0.5187214016914368\n",
      "loss: 0.3366648554801941\n",
      "loss: 0.21019022166728973\n",
      "loss: 0.4496109187602997\n",
      "epoch loss:  3.2181615829467773\n",
      "loss: 0.7297596335411072\n",
      "loss: 0.6688505411148071\n",
      "loss: 0.3012443780899048\n",
      "loss: 0.5166804790496826\n",
      "loss: 0.3354282081127167\n",
      "loss: 0.20947930216789246\n",
      "loss: 0.4487695097923279\n",
      "epoch loss:  3.210212230682373\n",
      "loss: 0.7252229452133179\n",
      "loss: 0.6660863161087036\n",
      "loss: 0.2995105981826782\n",
      "loss: 0.5159327983856201\n",
      "loss: 0.3349228799343109\n",
      "loss: 0.20935280621051788\n",
      "loss: 0.4486796259880066\n",
      "epoch loss:  3.1997079849243164\n",
      "loss: 0.7259606719017029\n",
      "loss: 0.6664937734603882\n",
      "loss: 0.29906341433525085\n",
      "loss: 0.5149297714233398\n",
      "loss: 0.33558470010757446\n",
      "loss: 0.20807774364948273\n",
      "loss: 0.44684869050979614\n",
      "epoch loss:  3.196958541870117\n",
      "loss: 0.7196106910705566\n",
      "loss: 0.6670355200767517\n",
      "loss: 0.29690513014793396\n",
      "loss: 0.5155101418495178\n",
      "loss: 0.33385300636291504\n",
      "loss: 0.2085486352443695\n",
      "loss: 0.44633832573890686\n",
      "epoch loss:  3.1878015995025635\n",
      "loss: 0.7240887880325317\n",
      "loss: 0.6678469777107239\n",
      "loss: 0.29827889800071716\n",
      "loss: 0.5146570801734924\n",
      "loss: 0.33397865295410156\n",
      "loss: 0.20743867754936218\n",
      "loss: 0.44697123765945435\n",
      "epoch loss:  3.193260431289673\n",
      "loss: 0.7205276489257812\n",
      "loss: 0.6660609245300293\n",
      "loss: 0.29719290137290955\n",
      "loss: 0.5127503275871277\n",
      "loss: 0.3328711688518524\n",
      "loss: 0.20713239908218384\n",
      "loss: 0.4453478157520294\n",
      "epoch loss:  3.1818830966949463\n",
      "loss: 0.7223877310752869\n",
      "loss: 0.6642135381698608\n",
      "loss: 0.2973742187023163\n",
      "loss: 0.5127325057983398\n",
      "loss: 0.33117252588272095\n",
      "loss: 0.2069014310836792\n",
      "loss: 0.4436645805835724\n",
      "epoch loss:  3.1784462928771973\n",
      "loss: 0.720256507396698\n",
      "loss: 0.662891149520874\n",
      "loss: 0.2965884804725647\n",
      "loss: 0.5108285546302795\n",
      "loss: 0.3305767774581909\n",
      "loss: 0.206152081489563\n",
      "loss: 0.44258853793144226\n",
      "epoch loss:  3.16988205909729\n",
      "loss: 0.7238136529922485\n",
      "loss: 0.6610416173934937\n",
      "loss: 0.29432693123817444\n",
      "loss: 0.5095882415771484\n",
      "loss: 0.3303261995315552\n",
      "loss: 0.2048010379076004\n",
      "loss: 0.4414668083190918\n",
      "epoch loss:  3.1653642654418945\n",
      "loss: 0.7192585468292236\n",
      "loss: 0.660904586315155\n",
      "loss: 0.29541271924972534\n",
      "loss: 0.5101654529571533\n",
      "loss: 0.3296101987361908\n",
      "loss: 0.20517317950725555\n",
      "loss: 0.4404323101043701\n",
      "epoch loss:  3.160957098007202\n",
      "loss: 0.7232639789581299\n",
      "loss: 0.6618738770484924\n",
      "loss: 0.29288825392723083\n",
      "loss: 0.5107265114784241\n",
      "loss: 0.32798337936401367\n",
      "loss: 0.203617125749588\n",
      "loss: 0.4408828020095825\n",
      "epoch loss:  3.161235809326172\n",
      "loss: 0.7199583053588867\n",
      "loss: 0.6626952290534973\n",
      "loss: 0.2934456765651703\n",
      "loss: 0.5083999633789062\n",
      "loss: 0.3282223343849182\n",
      "loss: 0.20381122827529907\n",
      "loss: 0.44190260767936707\n",
      "epoch loss:  3.158435344696045\n",
      "loss: 0.7185513377189636\n",
      "loss: 0.6597146987915039\n",
      "loss: 0.29388704895973206\n",
      "loss: 0.5083895325660706\n",
      "loss: 0.32799220085144043\n",
      "loss: 0.20310373604297638\n",
      "loss: 0.4384673237800598\n",
      "epoch loss:  3.1501059532165527\n",
      "loss: 0.7135388851165771\n",
      "loss: 0.6602230072021484\n",
      "loss: 0.28979194164276123\n",
      "loss: 0.5090793371200562\n",
      "loss: 0.3280395567417145\n",
      "loss: 0.202778160572052\n",
      "loss: 0.43950366973876953\n",
      "epoch loss:  3.1429545879364014\n",
      "loss: 0.7199883460998535\n",
      "loss: 0.6568041443824768\n",
      "loss: 0.2919944226741791\n",
      "loss: 0.5050951242446899\n",
      "loss: 0.32565242052078247\n",
      "loss: 0.20180311799049377\n",
      "loss: 0.43641379475593567\n",
      "epoch loss:  3.137751340866089\n",
      "loss: 0.7176096439361572\n",
      "loss: 0.6562695503234863\n",
      "loss: 0.291975200176239\n",
      "loss: 0.5047425031661987\n",
      "loss: 0.3250293433666229\n",
      "loss: 0.20145811140537262\n",
      "loss: 0.43601590394973755\n",
      "epoch loss:  3.1331005096435547\n",
      "loss: 0.714676558971405\n",
      "loss: 0.65602707862854\n",
      "loss: 0.28908056020736694\n",
      "loss: 0.5047193169593811\n",
      "loss: 0.32364192605018616\n",
      "loss: 0.20099087059497833\n",
      "loss: 0.4364735782146454\n",
      "epoch loss:  3.125610113143921\n",
      "loss: 0.7190191149711609\n",
      "loss: 0.6555417776107788\n",
      "loss: 0.2910707890987396\n",
      "loss: 0.5029853582382202\n",
      "loss: 0.32404789328575134\n",
      "loss: 0.20077070593833923\n",
      "loss: 0.43384283781051636\n",
      "epoch loss:  3.1272783279418945\n",
      "loss: 0.7123825550079346\n",
      "loss: 0.655923068523407\n",
      "loss: 0.2889774441719055\n",
      "loss: 0.5012333989143372\n",
      "loss: 0.3232998549938202\n",
      "loss: 0.2007477879524231\n",
      "loss: 0.43313971161842346\n",
      "epoch loss:  3.115703821182251\n",
      "loss: 0.7119136452674866\n",
      "loss: 0.6543267965316772\n",
      "loss: 0.285421222448349\n",
      "loss: 0.5001500844955444\n",
      "loss: 0.32187336683273315\n",
      "loss: 0.19948939979076385\n",
      "loss: 0.43157878518104553\n",
      "epoch loss:  3.1047534942626953\n",
      "loss: 0.7117005586624146\n",
      "loss: 0.6509595513343811\n",
      "loss: 0.28626173734664917\n",
      "loss: 0.5013661980628967\n",
      "loss: 0.32089054584503174\n",
      "loss: 0.1998349279165268\n",
      "loss: 0.4315066933631897\n",
      "epoch loss:  3.102519989013672\n",
      "loss: 0.7100884318351746\n",
      "loss: 0.6537734270095825\n",
      "loss: 0.2847955524921417\n",
      "loss: 0.5019723176956177\n",
      "loss: 0.3202698826789856\n",
      "loss: 0.19798411428928375\n",
      "loss: 0.430020809173584\n",
      "epoch loss:  3.0989043712615967\n",
      "loss: 0.7110143303871155\n",
      "loss: 0.6536873579025269\n",
      "loss: 0.28475311398506165\n",
      "loss: 0.49968403577804565\n",
      "loss: 0.319736123085022\n",
      "loss: 0.19714617729187012\n",
      "loss: 0.4272630512714386\n",
      "epoch loss:  3.0932841300964355\n",
      "loss: 0.7070707678794861\n",
      "loss: 0.6495000123977661\n",
      "loss: 0.2836548686027527\n",
      "loss: 0.49711525440216064\n",
      "loss: 0.3192799389362335\n",
      "loss: 0.19717426598072052\n",
      "loss: 0.4282328486442566\n",
      "epoch loss:  3.0820281505584717\n",
      "loss: 0.7061713337898254\n",
      "loss: 0.6505228877067566\n",
      "loss: 0.2838532030582428\n",
      "loss: 0.49801892042160034\n",
      "loss: 0.31827259063720703\n",
      "loss: 0.1971207559108734\n",
      "loss: 0.4285655617713928\n",
      "epoch loss:  3.0825250148773193\n",
      "loss: 0.7121654748916626\n",
      "loss: 0.6496369242668152\n",
      "loss: 0.2849787175655365\n",
      "loss: 0.4952460527420044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.3173438012599945\n",
      "loss: 0.19620873034000397\n",
      "loss: 0.42660072445869446\n",
      "epoch loss:  3.0821802616119385\n",
      "loss: 0.7072585821151733\n",
      "loss: 0.648779571056366\n",
      "loss: 0.28226491808891296\n",
      "loss: 0.49447309970855713\n",
      "loss: 0.31689944863319397\n",
      "loss: 0.19547352194786072\n",
      "loss: 0.42521652579307556\n",
      "epoch loss:  3.0703656673431396\n",
      "loss: 0.7105720043182373\n",
      "loss: 0.64705890417099\n",
      "loss: 0.2804194986820221\n",
      "loss: 0.495645672082901\n",
      "loss: 0.3166711926460266\n",
      "loss: 0.19561223685741425\n",
      "loss: 0.42468318343162537\n",
      "epoch loss:  3.070662498474121\n",
      "loss: 0.7088840007781982\n",
      "loss: 0.6469820141792297\n",
      "loss: 0.28018665313720703\n",
      "loss: 0.49448731541633606\n",
      "loss: 0.3157186210155487\n",
      "loss: 0.19518138468265533\n",
      "loss: 0.42388829588890076\n",
      "epoch loss:  3.0653281211853027\n",
      "loss: 0.7050816416740417\n",
      "loss: 0.645703136920929\n",
      "loss: 0.2805134654045105\n",
      "loss: 0.4920767545700073\n",
      "loss: 0.314157634973526\n",
      "loss: 0.19419549405574799\n",
      "loss: 0.4245525002479553\n",
      "epoch loss:  3.0562806129455566\n",
      "loss: 0.7109255194664001\n",
      "loss: 0.642879843711853\n",
      "loss: 0.27987632155418396\n",
      "loss: 0.491008460521698\n",
      "loss: 0.3141331672668457\n",
      "loss: 0.19317005574703217\n",
      "loss: 0.4221740663051605\n",
      "epoch loss:  3.0541672706604004\n",
      "loss: 0.7045941948890686\n",
      "loss: 0.6439101696014404\n",
      "loss: 0.2785288393497467\n",
      "loss: 0.49431461095809937\n",
      "loss: 0.31420713663101196\n",
      "loss: 0.1930367350578308\n",
      "loss: 0.4220696985721588\n",
      "epoch loss:  3.050661325454712\n",
      "loss: 0.702750027179718\n",
      "loss: 0.649451732635498\n",
      "loss: 0.27846166491508484\n",
      "loss: 0.4902298152446747\n",
      "loss: 0.3126995265483856\n",
      "loss: 0.19277414679527283\n",
      "loss: 0.42172637581825256\n",
      "epoch loss:  3.048093318939209\n",
      "loss: 0.7021411061286926\n",
      "loss: 0.642174482345581\n",
      "loss: 0.27896738052368164\n",
      "loss: 0.49117615818977356\n",
      "loss: 0.3120501637458801\n",
      "loss: 0.1928776204586029\n",
      "loss: 0.4197031557559967\n",
      "epoch loss:  3.0390899181365967\n",
      "loss: 0.7036980390548706\n",
      "loss: 0.6448575258255005\n",
      "loss: 0.2760779559612274\n",
      "loss: 0.49262893199920654\n",
      "loss: 0.3107856214046478\n",
      "loss: 0.19120687246322632\n",
      "loss: 0.4189162850379944\n",
      "epoch loss:  3.0381710529327393\n",
      "loss: 0.697780430316925\n",
      "loss: 0.6438248753547668\n",
      "loss: 0.2756502628326416\n",
      "loss: 0.48747310042381287\n",
      "loss: 0.3098471760749817\n",
      "loss: 0.19108043611049652\n",
      "loss: 0.41972899436950684\n",
      "epoch loss:  3.0253851413726807\n",
      "loss: 0.701735258102417\n",
      "loss: 0.6427721381187439\n",
      "loss: 0.27487751841545105\n",
      "loss: 0.4881647825241089\n",
      "loss: 0.30913957953453064\n",
      "loss: 0.19088581204414368\n",
      "loss: 0.41691145300865173\n",
      "epoch loss:  3.0244863033294678\n",
      "loss: 0.6950643658638\n",
      "loss: 0.6407859325408936\n",
      "loss: 0.27348679304122925\n",
      "loss: 0.4879932403564453\n",
      "loss: 0.3081912100315094\n",
      "loss: 0.19056276977062225\n",
      "loss: 0.41766420006752014\n",
      "epoch loss:  3.0137486457824707\n",
      "loss: 0.698852002620697\n",
      "loss: 0.6399165391921997\n",
      "loss: 0.2736850380897522\n",
      "loss: 0.48606982827186584\n",
      "loss: 0.30830058455467224\n",
      "loss: 0.1902768760919571\n",
      "loss: 0.41644641757011414\n",
      "epoch loss:  3.01354718208313\n",
      "loss: 0.7005685567855835\n",
      "loss: 0.639594316482544\n",
      "loss: 0.2731885015964508\n",
      "loss: 0.48537132143974304\n",
      "loss: 0.3084433376789093\n",
      "loss: 0.18932974338531494\n",
      "loss: 0.4149693548679352\n",
      "epoch loss:  3.011465072631836\n",
      "loss: 0.6994224190711975\n",
      "loss: 0.636997401714325\n",
      "loss: 0.27243751287460327\n",
      "loss: 0.4845120310783386\n",
      "loss: 0.30729010701179504\n",
      "loss: 0.18991976976394653\n",
      "loss: 0.41440120339393616\n",
      "epoch loss:  3.0049805641174316\n",
      "loss: 0.7004878520965576\n",
      "loss: 0.6386805772781372\n",
      "loss: 0.2724404036998749\n",
      "loss: 0.48480722308158875\n",
      "loss: 0.30716705322265625\n",
      "loss: 0.18889319896697998\n",
      "loss: 0.41374483704566956\n",
      "epoch loss:  3.006221294403076\n",
      "loss: 0.6962178349494934\n",
      "loss: 0.6371206641197205\n",
      "loss: 0.2737501263618469\n",
      "loss: 0.48356014490127563\n",
      "loss: 0.3054659366607666\n",
      "loss: 0.18828970193862915\n",
      "loss: 0.4119594097137451\n",
      "epoch loss:  2.996363639831543\n",
      "loss: 0.6998721361160278\n",
      "loss: 0.6387744545936584\n",
      "loss: 0.2699219882488251\n",
      "loss: 0.4825655519962311\n",
      "loss: 0.3052462637424469\n",
      "loss: 0.1874161660671234\n",
      "loss: 0.4121754467487335\n",
      "epoch loss:  2.995972156524658\n",
      "loss: 0.6972798705101013\n",
      "loss: 0.6336807012557983\n",
      "loss: 0.26977068185806274\n",
      "loss: 0.48119059205055237\n",
      "loss: 0.3039798438549042\n",
      "loss: 0.18678408861160278\n",
      "loss: 0.41076233983039856\n",
      "epoch loss:  2.983448028564453\n",
      "loss: 0.6945710182189941\n",
      "loss: 0.632456362247467\n",
      "loss: 0.2685343027114868\n",
      "loss: 0.4823751449584961\n",
      "loss: 0.3025302588939667\n",
      "loss: 0.18749114871025085\n",
      "loss: 0.4094104468822479\n",
      "epoch loss:  2.9773685932159424\n",
      "loss: 0.6943719983100891\n",
      "loss: 0.6335667967796326\n",
      "loss: 0.26734980940818787\n",
      "loss: 0.4811246395111084\n",
      "loss: 0.30263036489486694\n",
      "loss: 0.18607567250728607\n",
      "loss: 0.40884676575660706\n",
      "epoch loss:  2.973966121673584\n",
      "loss: 0.6925479769706726\n",
      "loss: 0.633230984210968\n",
      "loss: 0.26873376965522766\n",
      "loss: 0.47917860746383667\n",
      "loss: 0.30239567160606384\n",
      "loss: 0.18610341846942902\n",
      "loss: 0.4085513651371002\n",
      "epoch loss:  2.9707417488098145\n",
      "loss: 0.69615638256073\n",
      "loss: 0.6312586069107056\n",
      "loss: 0.26787540316581726\n",
      "loss: 0.4802534580230713\n",
      "loss: 0.30166536569595337\n",
      "loss: 0.18525345623493195\n",
      "loss: 0.407547265291214\n",
      "epoch loss:  2.9700098037719727\n",
      "loss: 0.693297803401947\n",
      "loss: 0.6319800019264221\n",
      "loss: 0.2676166594028473\n",
      "loss: 0.47990578413009644\n",
      "loss: 0.3006366789340973\n",
      "loss: 0.18542738258838654\n",
      "loss: 0.4076346457004547\n",
      "epoch loss:  2.966499090194702\n",
      "loss: 0.6930764317512512\n",
      "loss: 0.6315091252326965\n",
      "loss: 0.2656260132789612\n",
      "loss: 0.4779607951641083\n",
      "loss: 0.29953721165657043\n",
      "loss: 0.1843990683555603\n",
      "loss: 0.40633389353752136\n",
      "epoch loss:  2.9584426879882812\n",
      "loss: 0.6902473568916321\n",
      "loss: 0.6299349069595337\n",
      "loss: 0.2650892436504364\n",
      "loss: 0.4769425392150879\n",
      "loss: 0.29950422048568726\n",
      "loss: 0.18559202551841736\n",
      "loss: 0.40538573265075684\n",
      "epoch loss:  2.9526960849761963\n",
      "loss: 0.690875232219696\n",
      "loss: 0.6306169033050537\n",
      "loss: 0.2638168931007385\n",
      "loss: 0.47537776827812195\n",
      "loss: 0.2993171811103821\n",
      "loss: 0.1844393014907837\n",
      "loss: 0.40422680974006653\n",
      "epoch loss:  2.948669910430908\n",
      "loss: 0.6916627883911133\n",
      "loss: 0.629017174243927\n",
      "loss: 0.264268696308136\n",
      "loss: 0.4764389991760254\n",
      "loss: 0.2983434200286865\n",
      "loss: 0.18411272764205933\n",
      "loss: 0.402566134929657\n",
      "epoch loss:  2.9464099407196045\n",
      "loss: 0.6899597644805908\n",
      "loss: 0.6284675598144531\n",
      "loss: 0.2641282081604004\n",
      "loss: 0.4746295213699341\n",
      "loss: 0.29830312728881836\n",
      "loss: 0.18406562507152557\n",
      "loss: 0.4044625759124756\n",
      "epoch loss:  2.944016456604004\n",
      "loss: 0.6887322664260864\n",
      "loss: 0.6290950775146484\n",
      "loss: 0.2637147009372711\n",
      "loss: 0.4743364453315735\n",
      "loss: 0.2970351278781891\n",
      "loss: 0.18367688357830048\n",
      "loss: 0.4032003581523895\n",
      "epoch loss:  2.939790964126587\n",
      "loss: 0.6878573298454285\n",
      "loss: 0.6268030405044556\n",
      "loss: 0.26253020763397217\n",
      "loss: 0.47325992584228516\n",
      "loss: 0.2966057360172272\n",
      "loss: 0.1827584058046341\n",
      "loss: 0.4012998938560486\n",
      "epoch loss:  2.931114435195923\n",
      "loss: 0.6869586110115051\n",
      "loss: 0.6260663866996765\n",
      "loss: 0.26247912645339966\n",
      "loss: 0.47247132658958435\n",
      "loss: 0.29570096731185913\n",
      "loss: 0.18266421556472778\n",
      "loss: 0.40002569556236267\n",
      "epoch loss:  2.926366090774536\n",
      "loss: 0.6867135167121887\n",
      "loss: 0.6244003772735596\n",
      "loss: 0.26192957162857056\n",
      "loss: 0.4732971489429474\n",
      "loss: 0.29506823420524597\n",
      "loss: 0.18292182683944702\n",
      "loss: 0.3990127742290497\n",
      "epoch loss:  2.9233434200286865\n",
      "loss: 0.6860834360122681\n",
      "loss: 0.6236351132392883\n",
      "loss: 0.26084110140800476\n",
      "loss: 0.471213161945343\n",
      "loss: 0.2935173511505127\n",
      "loss: 0.1811593472957611\n",
      "loss: 0.39914101362228394\n",
      "epoch loss:  2.915590524673462\n",
      "loss: 0.6852668523788452\n",
      "loss: 0.6281670928001404\n",
      "loss: 0.2610415816307068\n",
      "loss: 0.47113656997680664\n",
      "loss: 0.2925034165382385\n",
      "loss: 0.18006867170333862\n",
      "loss: 0.39916637539863586\n",
      "epoch loss:  2.9173505306243896\n",
      "loss: 0.6869715452194214\n",
      "loss: 0.6238949298858643\n",
      "loss: 0.25915876030921936\n",
      "loss: 0.4685348570346832\n",
      "loss: 0.29364123940467834\n",
      "loss: 0.18007276952266693\n",
      "loss: 0.3967881202697754\n",
      "epoch loss:  2.909062385559082\n",
      "loss: 0.6844386458396912\n",
      "loss: 0.622169017791748\n",
      "loss: 0.2584584653377533\n",
      "loss: 0.46758797764778137\n",
      "loss: 0.2921272814273834\n",
      "loss: 0.17999863624572754\n",
      "loss: 0.3971293270587921\n",
      "epoch loss:  2.901909589767456\n",
      "loss: 0.6846647262573242\n",
      "loss: 0.6230036020278931\n",
      "loss: 0.25816959142684937\n",
      "loss: 0.4696504473686218\n",
      "loss: 0.2911898195743561\n",
      "loss: 0.17936721444129944\n",
      "loss: 0.3953809142112732\n",
      "epoch loss:  2.9014265537261963\n",
      "loss: 0.6828430891036987\n",
      "loss: 0.6228550672531128\n",
      "loss: 0.25818443298339844\n",
      "loss: 0.46890679001808167\n",
      "loss: 0.29130035638809204\n",
      "loss: 0.17932450771331787\n",
      "loss: 0.39509230852127075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss:  2.8985064029693604\n",
      "loss: 0.6829267144203186\n",
      "loss: 0.6212787628173828\n",
      "loss: 0.25892961025238037\n",
      "loss: 0.4668465256690979\n",
      "loss: 0.29011425375938416\n",
      "loss: 0.17959058284759521\n",
      "loss: 0.3936387896537781\n",
      "epoch loss:  2.893325090408325\n",
      "loss: 0.6824503540992737\n",
      "loss: 0.6210655570030212\n",
      "loss: 0.2562723755836487\n",
      "loss: 0.4659837484359741\n",
      "loss: 0.28984832763671875\n",
      "loss: 0.17923122644424438\n",
      "loss: 0.3936094343662262\n",
      "epoch loss:  2.888461112976074\n",
      "loss: 0.6848329305648804\n",
      "loss: 0.6227961182594299\n",
      "loss: 0.25555479526519775\n",
      "loss: 0.4659068286418915\n",
      "loss: 0.28926920890808105\n",
      "loss: 0.17833280563354492\n",
      "loss: 0.39109566807746887\n",
      "epoch loss:  2.8877882957458496\n",
      "loss: 0.6808115839958191\n",
      "loss: 0.6218788027763367\n",
      "loss: 0.25577518343925476\n",
      "loss: 0.4650154709815979\n",
      "loss: 0.2890644669532776\n",
      "loss: 0.17762236297130585\n",
      "loss: 0.3914775252342224\n",
      "epoch loss:  2.881645441055298\n",
      "loss: 0.680741012096405\n",
      "loss: 0.6193974018096924\n",
      "loss: 0.2545902132987976\n",
      "loss: 0.46395719051361084\n",
      "loss: 0.2876981198787689\n",
      "loss: 0.17768220603466034\n",
      "loss: 0.3916223347187042\n",
      "epoch loss:  2.875688314437866\n",
      "loss: 0.682023286819458\n",
      "loss: 0.6184938549995422\n",
      "loss: 0.2541061043739319\n",
      "loss: 0.4647664725780487\n",
      "loss: 0.2878877520561218\n",
      "loss: 0.1774137169122696\n",
      "loss: 0.3911488354206085\n",
      "epoch loss:  2.875839948654175\n",
      "loss: 0.6804110407829285\n",
      "loss: 0.6187493205070496\n",
      "loss: 0.25546425580978394\n",
      "loss: 0.46470198035240173\n",
      "loss: 0.28781524300575256\n",
      "loss: 0.17767265439033508\n",
      "loss: 0.39024701714515686\n",
      "epoch loss:  2.875061511993408\n",
      "loss: 0.6818207502365112\n",
      "loss: 0.61752849817276\n",
      "loss: 0.2568245232105255\n",
      "loss: 0.46345770359039307\n",
      "loss: 0.28812748193740845\n",
      "loss: 0.17779117822647095\n",
      "loss: 0.39064720273017883\n",
      "epoch loss:  2.876197099685669\n",
      "loss: 0.6803080439567566\n",
      "loss: 0.6178827881813049\n",
      "loss: 0.25518909096717834\n",
      "loss: 0.46428728103637695\n",
      "loss: 0.2869414687156677\n",
      "loss: 0.17653892934322357\n",
      "loss: 0.39065179228782654\n",
      "epoch loss:  2.8717994689941406\n",
      "loss: 0.6792222857475281\n",
      "loss: 0.6165773272514343\n",
      "loss: 0.25012511014938354\n",
      "loss: 0.46053647994995117\n",
      "loss: 0.2851071059703827\n",
      "loss: 0.17560036480426788\n",
      "loss: 0.3871125280857086\n",
      "epoch loss:  2.854281187057495\n",
      "loss: 0.6757437586784363\n",
      "loss: 0.6167004108428955\n",
      "loss: 0.2523571848869324\n",
      "loss: 0.4615235924720764\n",
      "loss: 0.2847101092338562\n",
      "loss: 0.17615871131420135\n",
      "loss: 0.38629525899887085\n",
      "epoch loss:  2.8534891605377197\n",
      "loss: 0.6785672903060913\n",
      "loss: 0.6174417734146118\n",
      "loss: 0.25192320346832275\n",
      "loss: 0.4607692360877991\n",
      "loss: 0.28559255599975586\n",
      "loss: 0.17662779986858368\n",
      "loss: 0.38720181584358215\n",
      "epoch loss:  2.858123779296875\n",
      "loss: 0.6769902110099792\n",
      "loss: 0.6131091117858887\n",
      "loss: 0.25117647647857666\n",
      "loss: 0.45986026525497437\n",
      "loss: 0.2841561436653137\n",
      "loss: 0.17544549703598022\n",
      "loss: 0.3863687217235565\n",
      "epoch loss:  2.847106456756592\n",
      "loss: 0.6749845147132874\n",
      "loss: 0.6114002466201782\n",
      "loss: 0.2500549852848053\n",
      "loss: 0.46025002002716064\n",
      "loss: 0.282053679227829\n",
      "loss: 0.1738637238740921\n",
      "loss: 0.3848336935043335\n",
      "epoch loss:  2.8374409675598145\n",
      "loss: 0.6773821711540222\n",
      "loss: 0.6138349771499634\n",
      "loss: 0.24986869096755981\n",
      "loss: 0.461148202419281\n",
      "loss: 0.28230544924736023\n",
      "loss: 0.17521630227565765\n",
      "loss: 0.38382408022880554\n",
      "epoch loss:  2.8435797691345215\n",
      "loss: 0.6765093207359314\n",
      "loss: 0.6115557551383972\n",
      "loss: 0.24795319139957428\n",
      "loss: 0.45650389790534973\n",
      "loss: 0.28187456727027893\n",
      "loss: 0.1732599288225174\n",
      "loss: 0.3832927644252777\n",
      "epoch loss:  2.830949306488037\n",
      "loss: 0.6745914220809937\n",
      "loss: 0.609498918056488\n",
      "loss: 0.247398242354393\n",
      "loss: 0.45563575625419617\n",
      "loss: 0.2802084982395172\n",
      "loss: 0.17329949140548706\n",
      "loss: 0.38211315870285034\n",
      "epoch loss:  2.8227455615997314\n",
      "loss: 0.6772919297218323\n",
      "loss: 0.6109067797660828\n",
      "loss: 0.24896353483200073\n",
      "loss: 0.4571267068386078\n",
      "loss: 0.2797889709472656\n",
      "loss: 0.17350994050502777\n",
      "loss: 0.38095971941947937\n",
      "epoch loss:  2.828547477722168\n",
      "loss: 0.6715285181999207\n",
      "loss: 0.6086931228637695\n",
      "loss: 0.24642321467399597\n",
      "loss: 0.45383337140083313\n",
      "loss: 0.27980270981788635\n",
      "loss: 0.17254072427749634\n",
      "loss: 0.3800401985645294\n",
      "epoch loss:  2.812861919403076\n",
      "loss: 0.6712518334388733\n",
      "loss: 0.6097231507301331\n",
      "loss: 0.24629619717597961\n",
      "loss: 0.4543806314468384\n",
      "loss: 0.27879929542541504\n",
      "loss: 0.17160020768642426\n",
      "loss: 0.37838059663772583\n",
      "epoch loss:  2.810431718826294\n",
      "loss: 0.6730209589004517\n",
      "loss: 0.6085141897201538\n",
      "loss: 0.24546276032924652\n",
      "loss: 0.4541569650173187\n",
      "loss: 0.27866557240486145\n",
      "loss: 0.17260736227035522\n",
      "loss: 0.3787367045879364\n",
      "epoch loss:  2.811164617538452\n",
      "loss: 0.6672057509422302\n",
      "loss: 0.6076497435569763\n",
      "loss: 0.24650563299655914\n",
      "loss: 0.4534279406070709\n",
      "loss: 0.27740973234176636\n",
      "loss: 0.17112329602241516\n",
      "loss: 0.3770701289176941\n",
      "epoch loss:  2.8003921508789062\n",
      "loss: 0.6689766645431519\n",
      "loss: 0.6071792840957642\n",
      "loss: 0.24426403641700745\n",
      "loss: 0.45137450098991394\n",
      "loss: 0.2766966223716736\n",
      "loss: 0.17089030146598816\n",
      "loss: 0.37773242592811584\n",
      "epoch loss:  2.7971138954162598\n",
      "loss: 0.6683411598205566\n",
      "loss: 0.6063660383224487\n",
      "loss: 0.24390728771686554\n",
      "loss: 0.45150598883628845\n",
      "loss: 0.2756279408931732\n",
      "loss: 0.1707516759634018\n",
      "loss: 0.37574928998947144\n",
      "epoch loss:  2.7922494411468506\n",
      "loss: 0.6703581809997559\n",
      "loss: 0.6067450642585754\n",
      "loss: 0.24283255636692047\n",
      "loss: 0.45078834891319275\n",
      "loss: 0.2760915160179138\n",
      "loss: 0.16946378350257874\n",
      "loss: 0.3746338188648224\n",
      "epoch loss:  2.7909133434295654\n",
      "loss: 0.6687130331993103\n",
      "loss: 0.6037201285362244\n",
      "loss: 0.24187205731868744\n",
      "loss: 0.4488322138786316\n",
      "loss: 0.2750726640224457\n",
      "loss: 0.1700289100408554\n",
      "loss: 0.37333545088768005\n",
      "epoch loss:  2.781574249267578\n",
      "loss: 0.6633375287055969\n",
      "loss: 0.6050840020179749\n",
      "loss: 0.24152669310569763\n",
      "loss: 0.4480170011520386\n",
      "loss: 0.2745576798915863\n",
      "loss: 0.16940997540950775\n",
      "loss: 0.37235787510871887\n",
      "epoch loss:  2.7742908000946045\n",
      "loss: 0.6661840081214905\n",
      "loss: 0.6060980558395386\n",
      "loss: 0.24107910692691803\n",
      "loss: 0.44706177711486816\n",
      "loss: 0.2738541066646576\n",
      "loss: 0.16951723396778107\n",
      "loss: 0.37337467074394226\n",
      "epoch loss:  2.7771689891815186\n",
      "loss: 0.665094256401062\n",
      "loss: 0.6035568714141846\n",
      "loss: 0.24038110673427582\n",
      "loss: 0.44859811663627625\n",
      "loss: 0.2734089493751526\n",
      "loss: 0.16893061995506287\n",
      "loss: 0.37208443880081177\n",
      "epoch loss:  2.7720541954040527\n",
      "loss: 0.6649877429008484\n",
      "loss: 0.6022439002990723\n",
      "loss: 0.24075046181678772\n",
      "loss: 0.4468567371368408\n",
      "loss: 0.2724766731262207\n",
      "loss: 0.16909511387348175\n",
      "loss: 0.3711127042770386\n",
      "epoch loss:  2.7675232887268066\n",
      "loss: 0.6628168225288391\n",
      "loss: 0.5995633006095886\n",
      "loss: 0.24037054181098938\n",
      "loss: 0.44570738077163696\n",
      "loss: 0.27187564969062805\n",
      "loss: 0.16805367171764374\n",
      "loss: 0.37015217542648315\n",
      "epoch loss:  2.7585394382476807\n",
      "loss: 0.6622715592384338\n",
      "loss: 0.5998585224151611\n",
      "loss: 0.23943226039409637\n",
      "loss: 0.44697582721710205\n",
      "loss: 0.27086740732192993\n",
      "loss: 0.16697655618190765\n",
      "loss: 0.36950570344924927\n",
      "epoch loss:  2.755887508392334\n",
      "loss: 0.6621372103691101\n",
      "loss: 0.6005375385284424\n",
      "loss: 0.23879271745681763\n",
      "loss: 0.445081502199173\n",
      "loss: 0.2703295946121216\n",
      "loss: 0.16760212182998657\n",
      "loss: 0.3684398829936981\n",
      "epoch loss:  2.752920389175415\n",
      "loss: 0.6609165072441101\n",
      "loss: 0.5995713472366333\n",
      "loss: 0.23695611953735352\n",
      "loss: 0.44435083866119385\n",
      "loss: 0.269733190536499\n",
      "loss: 0.1671234369277954\n",
      "loss: 0.36978453397750854\n",
      "epoch loss:  2.7484357357025146\n",
      "loss: 0.6627347469329834\n",
      "loss: 0.5992692708969116\n",
      "loss: 0.23784853518009186\n",
      "loss: 0.44264695048332214\n",
      "loss: 0.26908397674560547\n",
      "loss: 0.16678157448768616\n",
      "loss: 0.36861202120780945\n",
      "epoch loss:  2.7469773292541504\n",
      "loss: 0.6613524556159973\n",
      "loss: 0.5986872315406799\n",
      "loss: 0.23859469592571259\n",
      "loss: 0.44384056329727173\n",
      "loss: 0.268993079662323\n",
      "loss: 0.16592946648597717\n",
      "loss: 0.3684329390525818\n",
      "epoch loss:  2.745830535888672\n",
      "loss: 0.6629592180252075\n",
      "loss: 0.5988147258758545\n",
      "loss: 0.2369004487991333\n",
      "loss: 0.44557681679725647\n",
      "loss: 0.268794983625412\n",
      "loss: 0.16742005944252014\n",
      "loss: 0.3682979941368103\n",
      "epoch loss:  2.7487642765045166\n",
      "loss: 0.6651427149772644\n",
      "loss: 0.6006278395652771\n",
      "loss: 0.23902840912342072\n",
      "loss: 0.4457630217075348\n",
      "loss: 0.26953744888305664\n",
      "loss: 0.1678982675075531\n",
      "loss: 0.3689602017402649\n",
      "epoch loss:  2.756957769393921\n",
      "loss: 0.6620208621025085\n",
      "loss: 0.5965916514396667\n",
      "loss: 0.2375568300485611\n",
      "loss: 0.44244787096977234\n",
      "loss: 0.2699059247970581\n",
      "loss: 0.16852828860282898\n",
      "loss: 0.36825406551361084\n",
      "epoch loss:  2.7453055381774902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6602972745895386\n",
      "loss: 0.5981490612030029\n",
      "loss: 0.2358904480934143\n",
      "loss: 0.44127821922302246\n",
      "loss: 0.2670598030090332\n",
      "loss: 0.166484996676445\n",
      "loss: 0.3645620048046112\n",
      "epoch loss:  2.733721971511841\n",
      "loss: 0.6586454510688782\n",
      "loss: 0.5953205823898315\n",
      "loss: 0.2342836558818817\n",
      "loss: 0.4397212266921997\n",
      "loss: 0.26630598306655884\n",
      "loss: 0.16499045491218567\n",
      "loss: 0.36368805170059204\n",
      "epoch loss:  2.7229554653167725\n",
      "loss: 0.6592363119125366\n",
      "loss: 0.5958686470985413\n",
      "loss: 0.23520660400390625\n",
      "loss: 0.44125130772590637\n",
      "loss: 0.2672121226787567\n",
      "loss: 0.16569747030735016\n",
      "loss: 0.3643198311328888\n",
      "epoch loss:  2.728792428970337\n",
      "loss: 0.6595476269721985\n",
      "loss: 0.5957673192024231\n",
      "loss: 0.23404939472675323\n",
      "loss: 0.4399004280567169\n",
      "loss: 0.2661578357219696\n",
      "loss: 0.16504575312137604\n",
      "loss: 0.363160103559494\n",
      "epoch loss:  2.723628520965576\n",
      "loss: 0.6561885476112366\n",
      "loss: 0.5952978134155273\n",
      "loss: 0.23309111595153809\n",
      "loss: 0.4368353486061096\n",
      "loss: 0.26460567116737366\n",
      "loss: 0.16389529407024384\n",
      "loss: 0.36185938119888306\n",
      "epoch loss:  2.711773157119751\n",
      "loss: 0.6584410071372986\n",
      "loss: 0.5931779742240906\n",
      "loss: 0.23139099776744843\n",
      "loss: 0.43982288241386414\n",
      "loss: 0.26366302371025085\n",
      "loss: 0.1640733778476715\n",
      "loss: 0.3600350320339203\n",
      "epoch loss:  2.710604190826416\n",
      "loss: 0.6535409092903137\n",
      "loss: 0.5921710133552551\n",
      "loss: 0.23184950649738312\n",
      "loss: 0.43615472316741943\n",
      "loss: 0.2634482681751251\n",
      "loss: 0.1640467643737793\n",
      "loss: 0.3590983748435974\n",
      "epoch loss:  2.7003097534179688\n",
      "loss: 0.6545034050941467\n",
      "loss: 0.5920284390449524\n",
      "loss: 0.2303502857685089\n",
      "loss: 0.4356177747249603\n",
      "loss: 0.2620331346988678\n",
      "loss: 0.16340206563472748\n",
      "loss: 0.35900965332984924\n",
      "epoch loss:  2.6969449520111084\n",
      "loss: 0.6504281759262085\n",
      "loss: 0.5906763076782227\n",
      "loss: 0.22977367043495178\n",
      "loss: 0.43554043769836426\n",
      "loss: 0.2615875005722046\n",
      "loss: 0.16274775564670563\n",
      "loss: 0.3579091727733612\n",
      "epoch loss:  2.6886630058288574\n",
      "loss: 0.6535653471946716\n",
      "loss: 0.5902510285377502\n",
      "loss: 0.23029160499572754\n",
      "loss: 0.43680235743522644\n",
      "loss: 0.2614336311817169\n",
      "loss: 0.16225653886795044\n",
      "loss: 0.3566678464412689\n",
      "epoch loss:  2.6912682056427\n",
      "loss: 0.6527877449989319\n",
      "loss: 0.5884093642234802\n",
      "loss: 0.22873137891292572\n",
      "loss: 0.43423372507095337\n",
      "loss: 0.26099732518196106\n",
      "loss: 0.16331210732460022\n",
      "loss: 0.35595202445983887\n",
      "epoch loss:  2.6844236850738525\n",
      "loss: 0.6518834829330444\n",
      "loss: 0.5885096192359924\n",
      "loss: 0.22918303310871124\n",
      "loss: 0.43238621950149536\n",
      "loss: 0.2596656382083893\n",
      "loss: 0.16206850111484528\n",
      "loss: 0.35673174262046814\n",
      "epoch loss:  2.6804285049438477\n",
      "loss: 0.6542706489562988\n",
      "loss: 0.5872920751571655\n",
      "loss: 0.2281966507434845\n",
      "loss: 0.43187347054481506\n",
      "loss: 0.2595730125904083\n",
      "loss: 0.16149373352527618\n",
      "loss: 0.355467826128006\n",
      "epoch loss:  2.6781673431396484\n",
      "loss: 0.6507402062416077\n",
      "loss: 0.5872496366500854\n",
      "loss: 0.2271609604358673\n",
      "loss: 0.4321274757385254\n",
      "loss: 0.25917428731918335\n",
      "loss: 0.1607639342546463\n",
      "loss: 0.3543851673603058\n",
      "epoch loss:  2.6716017723083496\n",
      "loss: 0.6497518420219421\n",
      "loss: 0.5881385803222656\n",
      "loss: 0.22667734324932098\n",
      "loss: 0.43140095472335815\n",
      "loss: 0.2592644989490509\n",
      "loss: 0.16030406951904297\n",
      "loss: 0.3537434935569763\n",
      "epoch loss:  2.669280767440796\n",
      "loss: 0.6485216021537781\n",
      "loss: 0.5864498615264893\n",
      "loss: 0.2277769148349762\n",
      "loss: 0.4318051338195801\n",
      "loss: 0.2575536072254181\n",
      "loss: 0.16113817691802979\n",
      "loss: 0.35203641653060913\n",
      "epoch loss:  2.6652817726135254\n",
      "loss: 0.6533218026161194\n",
      "loss: 0.5868214964866638\n",
      "loss: 0.227548286318779\n",
      "loss: 0.43021145462989807\n",
      "loss: 0.2568749189376831\n",
      "loss: 0.16006547212600708\n",
      "loss: 0.3527727425098419\n",
      "epoch loss:  2.667616128921509\n",
      "loss: 0.6513999104499817\n",
      "loss: 0.5857369303703308\n",
      "loss: 0.22630374133586884\n",
      "loss: 0.42973464727401733\n",
      "loss: 0.2566896677017212\n",
      "loss: 0.1598999798297882\n",
      "loss: 0.35016801953315735\n",
      "epoch loss:  2.6599326133728027\n",
      "loss: 0.6462774872779846\n",
      "loss: 0.5837886929512024\n",
      "loss: 0.2251221090555191\n",
      "loss: 0.4266068935394287\n",
      "loss: 0.25577282905578613\n",
      "loss: 0.15923064947128296\n",
      "loss: 0.35001835227012634\n",
      "epoch loss:  2.6468169689178467\n",
      "loss: 0.6461169719696045\n",
      "loss: 0.5832522511482239\n",
      "loss: 0.22320114076137543\n",
      "loss: 0.4274390637874603\n",
      "loss: 0.2554965615272522\n",
      "loss: 0.15906216204166412\n",
      "loss: 0.3494470715522766\n",
      "epoch loss:  2.644015073776245\n",
      "loss: 0.6479163765907288\n",
      "loss: 0.5830955505371094\n",
      "loss: 0.22322499752044678\n",
      "loss: 0.42637020349502563\n",
      "loss: 0.254869282245636\n",
      "loss: 0.15911082923412323\n",
      "loss: 0.3476696312427521\n",
      "epoch loss:  2.642256736755371\n",
      "loss: 0.6505078077316284\n",
      "loss: 0.5837032198905945\n",
      "loss: 0.22396628558635712\n",
      "loss: 0.4271301031112671\n",
      "loss: 0.2537447214126587\n",
      "loss: 0.15893658995628357\n",
      "loss: 0.34764960408210754\n",
      "epoch loss:  2.6456379890441895\n",
      "loss: 0.6446568965911865\n",
      "loss: 0.5813341736793518\n",
      "loss: 0.2233458012342453\n",
      "loss: 0.42654767632484436\n",
      "loss: 0.2535208761692047\n",
      "loss: 0.15749026834964752\n",
      "loss: 0.3483753502368927\n",
      "epoch loss:  2.635270833969116\n",
      "loss: 0.6462493538856506\n",
      "loss: 0.5842129588127136\n",
      "loss: 0.22252468764781952\n",
      "loss: 0.4259538948535919\n",
      "loss: 0.25443220138549805\n",
      "loss: 0.15801310539245605\n",
      "loss: 0.34594857692718506\n",
      "epoch loss:  2.6373348236083984\n",
      "loss: 0.6456925868988037\n",
      "loss: 0.5796381235122681\n",
      "loss: 0.22187018394470215\n",
      "loss: 0.4235796332359314\n",
      "loss: 0.2520214915275574\n",
      "loss: 0.15767602622509003\n",
      "loss: 0.34688085317611694\n",
      "epoch loss:  2.627358913421631\n",
      "loss: 0.6439415812492371\n",
      "loss: 0.5797709822654724\n",
      "loss: 0.2207181304693222\n",
      "loss: 0.42327094078063965\n",
      "loss: 0.25114455819129944\n",
      "loss: 0.1574038565158844\n",
      "loss: 0.34392282366752625\n",
      "epoch loss:  2.6201729774475098\n",
      "loss: 0.6412824392318726\n",
      "loss: 0.5796725153923035\n",
      "loss: 0.2201729565858841\n",
      "loss: 0.42092448472976685\n",
      "loss: 0.2509896457195282\n",
      "loss: 0.15681886672973633\n",
      "loss: 0.3446807563304901\n",
      "epoch loss:  2.61454176902771\n",
      "loss: 0.6464175581932068\n",
      "loss: 0.579205334186554\n",
      "loss: 0.21928082406520844\n",
      "loss: 0.42291346192359924\n",
      "loss: 0.25038987398147583\n",
      "loss: 0.156210258603096\n",
      "loss: 0.34291988611221313\n",
      "epoch loss:  2.6173369884490967\n",
      "loss: 0.6449646353721619\n",
      "loss: 0.5774894952774048\n",
      "loss: 0.21858640015125275\n",
      "loss: 0.4222591817378998\n",
      "loss: 0.24989640712738037\n",
      "loss: 0.15668898820877075\n",
      "loss: 0.3417774438858032\n",
      "epoch loss:  2.6116623878479004\n",
      "loss: 0.6440576910972595\n",
      "loss: 0.5793416500091553\n",
      "loss: 0.21916359663009644\n",
      "loss: 0.4211966395378113\n",
      "loss: 0.24994075298309326\n",
      "loss: 0.1560571938753128\n",
      "loss: 0.342120885848999\n",
      "epoch loss:  2.6118783950805664\n",
      "loss: 0.6437925696372986\n",
      "loss: 0.5772839784622192\n",
      "loss: 0.21780146658420563\n",
      "loss: 0.4204762279987335\n",
      "loss: 0.24893897771835327\n",
      "loss: 0.1556098312139511\n",
      "loss: 0.34108448028564453\n",
      "epoch loss:  2.604987382888794\n",
      "loss: 0.6379845142364502\n",
      "loss: 0.5754634141921997\n",
      "loss: 0.21728692948818207\n",
      "loss: 0.4200296998023987\n",
      "loss: 0.24736455082893372\n",
      "loss: 0.1553051471710205\n",
      "loss: 0.33922067284584045\n",
      "epoch loss:  2.5926549434661865\n",
      "loss: 0.6384502649307251\n",
      "loss: 0.5756420493125916\n",
      "loss: 0.21643561124801636\n",
      "loss: 0.41817620396614075\n",
      "loss: 0.24681182205677032\n",
      "loss: 0.1548284888267517\n",
      "loss: 0.33917883038520813\n",
      "epoch loss:  2.5895233154296875\n",
      "loss: 0.6372720003128052\n",
      "loss: 0.5736278891563416\n",
      "loss: 0.21587449312210083\n",
      "loss: 0.4194817841053009\n",
      "loss: 0.24695947766304016\n",
      "loss: 0.15469953417778015\n",
      "loss: 0.33851298689842224\n",
      "epoch loss:  2.586427927017212\n",
      "loss: 0.6386107206344604\n",
      "loss: 0.5743541121482849\n",
      "loss: 0.21649818122386932\n",
      "loss: 0.4193636476993561\n",
      "loss: 0.24592795968055725\n",
      "loss: 0.15435564517974854\n",
      "loss: 0.3381543755531311\n",
      "epoch loss:  2.5872645378112793\n",
      "loss: 0.6366487145423889\n",
      "loss: 0.5730850100517273\n",
      "loss: 0.21401964128017426\n",
      "loss: 0.41723036766052246\n",
      "loss: 0.2454814612865448\n",
      "loss: 0.15396451950073242\n",
      "loss: 0.33792299032211304\n",
      "epoch loss:  2.578352689743042\n",
      "loss: 0.6404902338981628\n",
      "loss: 0.5723743438720703\n",
      "loss: 0.21373632550239563\n",
      "loss: 0.4175168573856354\n",
      "loss: 0.2450859546661377\n",
      "loss: 0.1544070839881897\n",
      "loss: 0.3370664417743683\n",
      "epoch loss:  2.5806772708892822\n",
      "loss: 0.633407473564148\n",
      "loss: 0.5743446350097656\n",
      "loss: 0.2134658396244049\n",
      "loss: 0.41538408398628235\n",
      "loss: 0.24432909488677979\n",
      "loss: 0.1537850946187973\n",
      "loss: 0.33637845516204834\n",
      "epoch loss:  2.571094512939453\n",
      "loss: 0.6351207494735718\n",
      "loss: 0.572732150554657\n",
      "loss: 0.21441298723220825\n",
      "loss: 0.41439563035964966\n",
      "loss: 0.24406719207763672\n",
      "loss: 0.15322183072566986\n",
      "loss: 0.3340038061141968\n",
      "epoch loss:  2.5679540634155273\n",
      "loss: 0.6335510015487671\n",
      "loss: 0.5708650350570679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.21380984783172607\n",
      "loss: 0.4138464629650116\n",
      "loss: 0.2440020740032196\n",
      "loss: 0.153212770819664\n",
      "loss: 0.33399754762649536\n",
      "epoch loss:  2.5632846355438232\n",
      "loss: 0.6343693733215332\n",
      "loss: 0.5705179572105408\n",
      "loss: 0.21248801052570343\n",
      "loss: 0.4147000312805176\n",
      "loss: 0.24355854094028473\n",
      "loss: 0.15354491770267487\n",
      "loss: 0.33218780159950256\n",
      "epoch loss:  2.5613667964935303\n",
      "loss: 0.6331907510757446\n",
      "loss: 0.5680468678474426\n",
      "loss: 0.21136678755283356\n",
      "loss: 0.41170457005500793\n",
      "loss: 0.2419542819261551\n",
      "loss: 0.153114452958107\n",
      "loss: 0.3318275213241577\n",
      "epoch loss:  2.5512051582336426\n",
      "loss: 0.632131040096283\n",
      "loss: 0.568535327911377\n",
      "loss: 0.21034877002239227\n",
      "loss: 0.41116365790367126\n",
      "loss: 0.24175767600536346\n",
      "loss: 0.15264101326465607\n",
      "loss: 0.3313818871974945\n",
      "epoch loss:  2.547959327697754\n",
      "loss: 0.6309769749641418\n",
      "loss: 0.5706782341003418\n",
      "loss: 0.2103147953748703\n",
      "loss: 0.41034746170043945\n",
      "loss: 0.24051469564437866\n",
      "loss: 0.1521732062101364\n",
      "loss: 0.32931405305862427\n",
      "epoch loss:  2.5443193912506104\n",
      "loss: 0.6309375166893005\n",
      "loss: 0.5688965916633606\n",
      "loss: 0.21023359894752502\n",
      "loss: 0.4099467694759369\n",
      "loss: 0.240939199924469\n",
      "loss: 0.1512586623430252\n",
      "loss: 0.33132314682006836\n",
      "epoch loss:  2.5435354709625244\n",
      "loss: 0.6328142285346985\n",
      "loss: 0.5671141743659973\n",
      "loss: 0.2092621624469757\n",
      "loss: 0.41080421209335327\n",
      "loss: 0.23927904665470123\n",
      "loss: 0.15118107199668884\n",
      "loss: 0.33042046427726746\n",
      "epoch loss:  2.540875196456909\n",
      "loss: 0.6295596957206726\n",
      "loss: 0.5662484765052795\n",
      "loss: 0.20938296616077423\n",
      "loss: 0.40833520889282227\n",
      "loss: 0.23878613114356995\n",
      "loss: 0.1507803052663803\n",
      "loss: 0.3289533257484436\n",
      "epoch loss:  2.53204607963562\n",
      "loss: 0.630540668964386\n",
      "loss: 0.5657851099967957\n",
      "loss: 0.20889534056186676\n",
      "loss: 0.40858402848243713\n",
      "loss: 0.23840488493442535\n",
      "loss: 0.15101851522922516\n",
      "loss: 0.3277275264263153\n",
      "epoch loss:  2.530956268310547\n",
      "loss: 0.6272532343864441\n",
      "loss: 0.565451443195343\n",
      "loss: 0.20690079033374786\n",
      "loss: 0.40904557704925537\n",
      "loss: 0.23751579225063324\n",
      "loss: 0.15115422010421753\n",
      "loss: 0.32651883363723755\n",
      "epoch loss:  2.5238399505615234\n",
      "loss: 0.6300361156463623\n",
      "loss: 0.5650548338890076\n",
      "loss: 0.20780208706855774\n",
      "loss: 0.4053783416748047\n",
      "loss: 0.2365138679742813\n",
      "loss: 0.15053647756576538\n",
      "loss: 0.3245655298233032\n",
      "epoch loss:  2.5198874473571777\n",
      "loss: 0.6269570589065552\n",
      "loss: 0.5646163821220398\n",
      "loss: 0.20539885759353638\n",
      "loss: 0.40641871094703674\n",
      "loss: 0.23611827194690704\n",
      "loss: 0.14991691708564758\n",
      "loss: 0.3241490125656128\n",
      "epoch loss:  2.5135750770568848\n",
      "loss: 0.6305660605430603\n",
      "loss: 0.5630828142166138\n",
      "loss: 0.2042531967163086\n",
      "loss: 0.4069482386112213\n",
      "loss: 0.2354719042778015\n",
      "loss: 0.1492222398519516\n",
      "loss: 0.3250313699245453\n",
      "epoch loss:  2.514575481414795\n",
      "loss: 0.6280590295791626\n",
      "loss: 0.5620383620262146\n",
      "loss: 0.20535947382450104\n",
      "loss: 0.4042917788028717\n",
      "loss: 0.23474901914596558\n",
      "loss: 0.14945060014724731\n",
      "loss: 0.32329460978507996\n",
      "epoch loss:  2.5072426795959473\n",
      "loss: 0.6269571781158447\n",
      "loss: 0.5623424053192139\n",
      "loss: 0.20557010173797607\n",
      "loss: 0.40516650676727295\n",
      "loss: 0.23455776274204254\n",
      "loss: 0.14900706708431244\n",
      "loss: 0.3244985342025757\n",
      "epoch loss:  2.5080995559692383\n",
      "loss: 0.6288580894470215\n",
      "loss: 0.5634049773216248\n",
      "loss: 0.20675142109394073\n",
      "loss: 0.40574875473976135\n",
      "loss: 0.23540981113910675\n",
      "loss: 0.14949451386928558\n",
      "loss: 0.3231034278869629\n",
      "epoch loss:  2.512770891189575\n",
      "loss: 0.6248362064361572\n",
      "loss: 0.5620363354682922\n",
      "loss: 0.20382288098335266\n",
      "loss: 0.403437077999115\n",
      "loss: 0.2343432903289795\n",
      "loss: 0.14863811433315277\n",
      "loss: 0.32254457473754883\n",
      "epoch loss:  2.4996583461761475\n",
      "loss: 0.6249505281448364\n",
      "loss: 0.559277355670929\n",
      "loss: 0.20272831618785858\n",
      "loss: 0.40084660053253174\n",
      "loss: 0.23297809064388275\n",
      "loss: 0.14857228100299835\n",
      "loss: 0.3202182352542877\n",
      "epoch loss:  2.4895713329315186\n",
      "loss: 0.6273403167724609\n",
      "loss: 0.5595138072967529\n",
      "loss: 0.20235830545425415\n",
      "loss: 0.4015442430973053\n",
      "loss: 0.23266161978244781\n",
      "loss: 0.14736828207969666\n",
      "loss: 0.32094064354896545\n",
      "epoch loss:  2.491727113723755\n",
      "loss: 0.6258832216262817\n",
      "loss: 0.5597409009933472\n",
      "loss: 0.20176318287849426\n",
      "loss: 0.4008166193962097\n",
      "loss: 0.23230823874473572\n",
      "loss: 0.14758290350437164\n",
      "loss: 0.3194533586502075\n",
      "epoch loss:  2.487548351287842\n",
      "loss: 0.6243067979812622\n",
      "loss: 0.5593776702880859\n",
      "loss: 0.20301873981952667\n",
      "loss: 0.4004538357257843\n",
      "loss: 0.23171254992485046\n",
      "loss: 0.14729496836662292\n",
      "loss: 0.3202935755252838\n",
      "epoch loss:  2.4864583015441895\n",
      "loss: 0.6236330270767212\n",
      "loss: 0.55794757604599\n",
      "loss: 0.20224981009960175\n",
      "loss: 0.4004436135292053\n",
      "loss: 0.2312646210193634\n",
      "loss: 0.14699161052703857\n",
      "loss: 0.31883788108825684\n",
      "epoch loss:  2.481367826461792\n",
      "loss: 0.6223039031028748\n",
      "loss: 0.5573329329490662\n",
      "loss: 0.19970494508743286\n",
      "loss: 0.39844387769699097\n",
      "loss: 0.23016561567783356\n",
      "loss: 0.14658840000629425\n",
      "loss: 0.31628480553627014\n",
      "epoch loss:  2.470824718475342\n",
      "loss: 0.6224159598350525\n",
      "loss: 0.5567966103553772\n",
      "loss: 0.2000599056482315\n",
      "loss: 0.39743736386299133\n",
      "loss: 0.22853001952171326\n",
      "loss: 0.14729192852973938\n",
      "loss: 0.3156585395336151\n",
      "epoch loss:  2.4681901931762695\n",
      "loss: 0.6179049611091614\n",
      "loss: 0.5570394396781921\n",
      "loss: 0.19895724952220917\n",
      "loss: 0.39794325828552246\n",
      "loss: 0.22901543974876404\n",
      "loss: 0.14596278965473175\n",
      "loss: 0.31477266550064087\n",
      "epoch loss:  2.4615955352783203\n",
      "loss: 0.6168755888938904\n",
      "loss: 0.5549813508987427\n",
      "loss: 0.19927294552326202\n",
      "loss: 0.39610597491264343\n",
      "loss: 0.22756816446781158\n",
      "loss: 0.14571528136730194\n",
      "loss: 0.3140317499637604\n",
      "epoch loss:  2.4545512199401855\n",
      "loss: 0.6174268126487732\n",
      "loss: 0.554704487323761\n",
      "loss: 0.19870813190937042\n",
      "loss: 0.39551016688346863\n",
      "loss: 0.2272578924894333\n",
      "loss: 0.14584662020206451\n",
      "loss: 0.3141033351421356\n",
      "epoch loss:  2.4535574913024902\n",
      "loss: 0.6169509291648865\n",
      "loss: 0.5518446564674377\n",
      "loss: 0.1974029242992401\n",
      "loss: 0.3935670852661133\n",
      "loss: 0.22725847363471985\n",
      "loss: 0.14539507031440735\n",
      "loss: 0.3123491406440735\n",
      "epoch loss:  2.444768190383911\n",
      "loss: 0.6161105632781982\n",
      "loss: 0.5539994835853577\n",
      "loss: 0.1974641978740692\n",
      "loss: 0.39401835203170776\n",
      "loss: 0.22634369134902954\n",
      "loss: 0.14521999657154083\n",
      "loss: 0.31141039729118347\n",
      "epoch loss:  2.4445667266845703\n",
      "loss: 0.6157614588737488\n",
      "loss: 0.5526548624038696\n",
      "loss: 0.19628936052322388\n",
      "loss: 0.39431264996528625\n",
      "loss: 0.22519437968730927\n",
      "loss: 0.14470012485980988\n",
      "loss: 0.3109222650527954\n",
      "epoch loss:  2.4398350715637207\n",
      "loss: 0.617177426815033\n",
      "loss: 0.5528228878974915\n",
      "loss: 0.19582268595695496\n",
      "loss: 0.39297211170196533\n",
      "loss: 0.22440451383590698\n",
      "loss: 0.14413835108280182\n",
      "loss: 0.31084197759628296\n",
      "epoch loss:  2.4381799697875977\n",
      "loss: 0.6151598691940308\n",
      "loss: 0.5512073040008545\n",
      "loss: 0.19484999775886536\n",
      "loss: 0.39175641536712646\n",
      "loss: 0.22425442934036255\n",
      "loss: 0.14412830770015717\n",
      "loss: 0.31009089946746826\n",
      "epoch loss:  2.4314470291137695\n",
      "loss: 0.6155346632003784\n",
      "loss: 0.5510886907577515\n",
      "loss: 0.19472157955169678\n",
      "loss: 0.39029547572135925\n",
      "loss: 0.2240074872970581\n",
      "loss: 0.14401033520698547\n",
      "loss: 0.30932921171188354\n",
      "epoch loss:  2.428987503051758\n",
      "loss: 0.6119489669799805\n",
      "loss: 0.5486617088317871\n",
      "loss: 0.1942218542098999\n",
      "loss: 0.39005914330482483\n",
      "loss: 0.2229069024324417\n",
      "loss: 0.14379402995109558\n",
      "loss: 0.3082650899887085\n",
      "epoch loss:  2.4198575019836426\n",
      "loss: 0.6122322678565979\n",
      "loss: 0.548405647277832\n",
      "loss: 0.19316110014915466\n",
      "loss: 0.3897925317287445\n",
      "loss: 0.2224535197019577\n",
      "loss: 0.14296850562095642\n",
      "loss: 0.3084433376789093\n",
      "epoch loss:  2.417456865310669\n",
      "loss: 0.6123965978622437\n",
      "loss: 0.5486177802085876\n",
      "loss: 0.19215387105941772\n",
      "loss: 0.3893287777900696\n",
      "loss: 0.22132070362567902\n",
      "loss: 0.14288747310638428\n",
      "loss: 0.3065575063228607\n",
      "epoch loss:  2.4132626056671143\n",
      "loss: 0.6132853031158447\n",
      "loss: 0.5475143194198608\n",
      "loss: 0.19232502579689026\n",
      "loss: 0.38685494661331177\n",
      "loss: 0.22121834754943848\n",
      "loss: 0.14268438518047333\n",
      "loss: 0.30496978759765625\n",
      "epoch loss:  2.4088521003723145\n",
      "loss: 0.6102293133735657\n",
      "loss: 0.5451254844665527\n",
      "loss: 0.19156797230243683\n",
      "loss: 0.38694632053375244\n",
      "loss: 0.22062434256076813\n",
      "loss: 0.1433541178703308\n",
      "loss: 0.3049265742301941\n",
      "epoch loss:  2.4027740955352783\n",
      "loss: 0.6107144355773926\n",
      "loss: 0.545789361000061\n",
      "loss: 0.19077779352664948\n",
      "loss: 0.3879146873950958\n",
      "loss: 0.21960924565792084\n",
      "loss: 0.14221732318401337\n",
      "loss: 0.3038557469844818\n",
      "epoch loss:  2.400878429412842\n",
      "loss: 0.6085677742958069\n",
      "loss: 0.5438977479934692\n",
      "loss: 0.19106724858283997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.38520756363868713\n",
      "loss: 0.21928168833255768\n",
      "loss: 0.14209173619747162\n",
      "loss: 0.30424371361732483\n",
      "epoch loss:  2.394357442855835\n",
      "loss: 0.6118438839912415\n",
      "loss: 0.5430666208267212\n",
      "loss: 0.18979372084140778\n",
      "loss: 0.3856427073478699\n",
      "loss: 0.21884067356586456\n",
      "loss: 0.1412000209093094\n",
      "loss: 0.30355140566825867\n",
      "epoch loss:  2.3939390182495117\n",
      "loss: 0.6102650165557861\n",
      "loss: 0.5445623993873596\n",
      "loss: 0.18943020701408386\n",
      "loss: 0.3857511579990387\n",
      "loss: 0.21842695772647858\n",
      "loss: 0.1407075822353363\n",
      "loss: 0.30232277512550354\n",
      "epoch loss:  2.3914661407470703\n",
      "loss: 0.6087973117828369\n",
      "loss: 0.5422974824905396\n",
      "loss: 0.18909095227718353\n",
      "loss: 0.3827359676361084\n",
      "loss: 0.21778571605682373\n",
      "loss: 0.14097535610198975\n",
      "loss: 0.30219119787216187\n",
      "epoch loss:  2.38387393951416\n",
      "loss: 0.6071667671203613\n",
      "loss: 0.5432260036468506\n",
      "loss: 0.18872994184494019\n",
      "loss: 0.3838512897491455\n",
      "loss: 0.21701332926750183\n",
      "loss: 0.14049983024597168\n",
      "loss: 0.30089065432548523\n",
      "epoch loss:  2.381377935409546\n",
      "loss: 0.610371470451355\n",
      "loss: 0.5416766405105591\n",
      "loss: 0.18854977190494537\n",
      "loss: 0.38278841972351074\n",
      "loss: 0.21641439199447632\n",
      "loss: 0.14084994792938232\n",
      "loss: 0.30075666308403015\n",
      "epoch loss:  2.3814074993133545\n",
      "loss: 0.6063178777694702\n",
      "loss: 0.5418075919151306\n",
      "loss: 0.1870506852865219\n",
      "loss: 0.3828744888305664\n",
      "loss: 0.21576155722141266\n",
      "loss: 0.13960811495780945\n",
      "loss: 0.2998333275318146\n",
      "epoch loss:  2.373253583908081\n",
      "loss: 0.6056239604949951\n",
      "loss: 0.5403794646263123\n",
      "loss: 0.1882123351097107\n",
      "loss: 0.3811798691749573\n",
      "loss: 0.21591602265834808\n",
      "loss: 0.13965201377868652\n",
      "loss: 0.2991480827331543\n",
      "epoch loss:  2.3701119422912598\n",
      "loss: 0.6101195216178894\n",
      "loss: 0.5413671731948853\n",
      "loss: 0.18868081271648407\n",
      "loss: 0.3821418583393097\n",
      "loss: 0.21570847928524017\n",
      "loss: 0.13976983726024628\n",
      "loss: 0.30013972520828247\n",
      "epoch loss:  2.377927303314209\n",
      "loss: 0.6102454662322998\n",
      "loss: 0.5409522652626038\n",
      "loss: 0.18656706809997559\n",
      "loss: 0.3814072608947754\n",
      "loss: 0.21490272879600525\n",
      "loss: 0.13988518714904785\n",
      "loss: 0.29887303709983826\n",
      "epoch loss:  2.372832775115967\n",
      "loss: 0.6061996221542358\n",
      "loss: 0.540888786315918\n",
      "loss: 0.18800319731235504\n",
      "loss: 0.3815493583679199\n",
      "loss: 0.21570280194282532\n",
      "loss: 0.13953489065170288\n",
      "loss: 0.29963573813438416\n",
      "epoch loss:  2.371514320373535\n",
      "loss: 0.6045063734054565\n",
      "loss: 0.5401243567466736\n",
      "loss: 0.186270609498024\n",
      "loss: 0.38129836320877075\n",
      "loss: 0.21496203541755676\n",
      "loss: 0.13858836889266968\n",
      "loss: 0.3001537621021271\n",
      "epoch loss:  2.365903854370117\n",
      "loss: 0.6077262163162231\n",
      "loss: 0.5395159125328064\n",
      "loss: 0.1877787709236145\n",
      "loss: 0.3798937201499939\n",
      "loss: 0.21499261260032654\n",
      "loss: 0.13870647549629211\n",
      "loss: 0.2986990809440613\n",
      "epoch loss:  2.3673129081726074\n",
      "loss: 0.6089602708816528\n",
      "loss: 0.5410910844802856\n",
      "loss: 0.18845726549625397\n",
      "loss: 0.38052934408187866\n",
      "loss: 0.2163112461566925\n",
      "loss: 0.1401737630367279\n",
      "loss: 0.2987290620803833\n",
      "epoch loss:  2.3742518424987793\n",
      "loss: 0.6029107570648193\n",
      "loss: 0.5391248464584351\n",
      "loss: 0.18610237538814545\n",
      "loss: 0.3804473578929901\n",
      "loss: 0.21432799100875854\n",
      "loss: 0.14031493663787842\n",
      "loss: 0.29683196544647217\n",
      "epoch loss:  2.360060214996338\n",
      "loss: 0.6065335869789124\n",
      "loss: 0.537304699420929\n",
      "loss: 0.18465200066566467\n",
      "loss: 0.3792489767074585\n",
      "loss: 0.21259231865406036\n",
      "loss: 0.13889627158641815\n",
      "loss: 0.2948912978172302\n",
      "epoch loss:  2.354119300842285\n",
      "loss: 0.5999467372894287\n",
      "loss: 0.537429690361023\n",
      "loss: 0.18350520730018616\n",
      "loss: 0.37690457701683044\n",
      "loss: 0.21190491318702698\n",
      "loss: 0.1375129073858261\n",
      "loss: 0.2943417429924011\n",
      "epoch loss:  2.341545820236206\n",
      "loss: 0.6018936038017273\n",
      "loss: 0.536651611328125\n",
      "loss: 0.18553981184959412\n",
      "loss: 0.3781472146511078\n",
      "loss: 0.21267500519752502\n",
      "loss: 0.1389368623495102\n",
      "loss: 0.2946593463420868\n",
      "epoch loss:  2.348503589630127\n",
      "loss: 0.602200448513031\n",
      "loss: 0.5344003438949585\n",
      "loss: 0.1829545646905899\n",
      "loss: 0.37539297342300415\n",
      "loss: 0.2114170342683792\n",
      "loss: 0.1374863088130951\n",
      "loss: 0.29223260283470154\n",
      "epoch loss:  2.3360841274261475\n",
      "loss: 0.5999268293380737\n",
      "loss: 0.5351934432983398\n",
      "loss: 0.1815778762102127\n",
      "loss: 0.3749825656414032\n",
      "loss: 0.21075046062469482\n",
      "loss: 0.1377096176147461\n",
      "loss: 0.29205402731895447\n",
      "epoch loss:  2.3321948051452637\n",
      "loss: 0.5991225242614746\n",
      "loss: 0.5353073477745056\n",
      "loss: 0.18263132870197296\n",
      "loss: 0.3739248812198639\n",
      "loss: 0.2112138420343399\n",
      "loss: 0.13691695034503937\n",
      "loss: 0.2925964295864105\n",
      "epoch loss:  2.3317131996154785\n",
      "loss: 0.6001936197280884\n",
      "loss: 0.5356061458587646\n",
      "loss: 0.18251089751720428\n",
      "loss: 0.37313321232795715\n",
      "loss: 0.20960503816604614\n",
      "loss: 0.13666290044784546\n",
      "loss: 0.2905503511428833\n",
      "epoch loss:  2.3282623291015625\n",
      "loss: 0.6021966338157654\n",
      "loss: 0.5336857438087463\n",
      "loss: 0.18060602247714996\n",
      "loss: 0.3733983635902405\n",
      "loss: 0.20991156995296478\n",
      "loss: 0.1364816278219223\n",
      "loss: 0.29066628217697144\n",
      "epoch loss:  2.326946258544922\n",
      "loss: 0.5978503823280334\n",
      "loss: 0.5337458252906799\n",
      "loss: 0.18036098778247833\n",
      "loss: 0.371588796377182\n",
      "loss: 0.208003431558609\n",
      "loss: 0.13633134961128235\n",
      "loss: 0.2890675365924835\n",
      "epoch loss:  2.316948413848877\n",
      "loss: 0.5961903929710388\n",
      "loss: 0.5326046943664551\n",
      "loss: 0.18047885596752167\n",
      "loss: 0.3706180155277252\n",
      "loss: 0.2077953964471817\n",
      "loss: 0.1358187347650528\n",
      "loss: 0.28880617022514343\n",
      "epoch loss:  2.312312364578247\n",
      "loss: 0.5989958047866821\n",
      "loss: 0.5311687588691711\n",
      "loss: 0.1793723851442337\n",
      "loss: 0.37149569392204285\n",
      "loss: 0.20715156197547913\n",
      "loss: 0.1361473649740219\n",
      "loss: 0.2887173891067505\n",
      "epoch loss:  2.313048839569092\n",
      "loss: 0.5999658703804016\n",
      "loss: 0.5309332609176636\n",
      "loss: 0.17979297041893005\n",
      "loss: 0.37150371074676514\n",
      "loss: 0.206851527094841\n",
      "loss: 0.1350329965353012\n",
      "loss: 0.28782597184181213\n",
      "epoch loss:  2.311906337738037\n",
      "loss: 0.5961770415306091\n",
      "loss: 0.5300779342651367\n",
      "loss: 0.1805119812488556\n",
      "loss: 0.3706677556037903\n",
      "loss: 0.2063458114862442\n",
      "loss: 0.1348479688167572\n",
      "loss: 0.287465363740921\n",
      "epoch loss:  2.306093692779541\n",
      "loss: 0.5925489068031311\n",
      "loss: 0.5309463143348694\n",
      "loss: 0.1775616854429245\n",
      "loss: 0.3691158592700958\n",
      "loss: 0.20540036261081696\n",
      "loss: 0.1352117359638214\n",
      "loss: 0.2862832546234131\n",
      "epoch loss:  2.2970681190490723\n",
      "loss: 0.593359112739563\n",
      "loss: 0.5319274663925171\n",
      "loss: 0.17750968039035797\n",
      "loss: 0.36920368671417236\n",
      "loss: 0.20559722185134888\n",
      "loss: 0.13389569520950317\n",
      "loss: 0.2868688702583313\n",
      "epoch loss:  2.2983615398406982\n",
      "loss: 0.5948007702827454\n",
      "loss: 0.529945969581604\n",
      "loss: 0.17741093039512634\n",
      "loss: 0.36897873878479004\n",
      "loss: 0.2049877941608429\n",
      "loss: 0.13428813219070435\n",
      "loss: 0.28631195425987244\n",
      "epoch loss:  2.296724319458008\n",
      "loss: 0.5931071639060974\n",
      "loss: 0.5295853018760681\n",
      "loss: 0.17708994448184967\n",
      "loss: 0.3681545853614807\n",
      "loss: 0.2045382857322693\n",
      "loss: 0.13430093228816986\n",
      "loss: 0.2853764593601227\n",
      "epoch loss:  2.2921528816223145\n",
      "loss: 0.595348060131073\n",
      "loss: 0.5289252400398254\n",
      "loss: 0.17757336795330048\n",
      "loss: 0.3685739040374756\n",
      "loss: 0.20456543564796448\n",
      "loss: 0.13358376920223236\n",
      "loss: 0.28528493642807007\n",
      "epoch loss:  2.2938547134399414\n",
      "loss: 0.5964178442955017\n",
      "loss: 0.5294910669326782\n",
      "loss: 0.1771530658006668\n",
      "loss: 0.370175838470459\n",
      "loss: 0.20473526418209076\n",
      "loss: 0.13371612131595612\n",
      "loss: 0.2869817018508911\n",
      "epoch loss:  2.298670768737793\n",
      "loss: 0.592786967754364\n",
      "loss: 0.5287392139434814\n",
      "loss: 0.17654916644096375\n",
      "loss: 0.36877861618995667\n",
      "loss: 0.20513415336608887\n",
      "loss: 0.13359679281711578\n",
      "loss: 0.28635817766189575\n",
      "epoch loss:  2.291943073272705\n",
      "loss: 0.5933231711387634\n",
      "loss: 0.5280460119247437\n",
      "loss: 0.17665137350559235\n",
      "loss: 0.3673402667045593\n",
      "loss: 0.20354358851909637\n",
      "loss: 0.13359610736370087\n",
      "loss: 0.28489720821380615\n",
      "epoch loss:  2.2873973846435547\n",
      "loss: 0.5932010412216187\n",
      "loss: 0.5265210270881653\n",
      "loss: 0.17671886086463928\n",
      "loss: 0.36480075120925903\n",
      "loss: 0.2027405947446823\n",
      "loss: 0.132690891623497\n",
      "loss: 0.28339821100234985\n",
      "epoch loss:  2.280071496963501\n",
      "loss: 0.5920081734657288\n",
      "loss: 0.5252330303192139\n",
      "loss: 0.1752512902021408\n",
      "loss: 0.36573323607444763\n",
      "loss: 0.20180705189704895\n",
      "loss: 0.13283759355545044\n",
      "loss: 0.2820364236831665\n",
      "epoch loss:  2.274906635284424\n",
      "loss: 0.5939481854438782\n",
      "loss: 0.5259631872177124\n",
      "loss: 0.17399083077907562\n",
      "loss: 0.36623796820640564\n",
      "loss: 0.20228207111358643\n",
      "loss: 0.13191582262516022\n",
      "loss: 0.28192487359046936\n",
      "epoch loss:  2.2762629985809326\n",
      "loss: 0.5922854542732239\n",
      "loss: 0.5242272019386292\n",
      "loss: 0.1751030832529068\n",
      "loss: 0.36382830142974854\n",
      "loss: 0.20167815685272217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.13227878510951996\n",
      "loss: 0.2811209261417389\n",
      "epoch loss:  2.270521879196167\n",
      "loss: 0.5893149971961975\n",
      "loss: 0.5253823399543762\n",
      "loss: 0.1741001158952713\n",
      "loss: 0.3630402684211731\n",
      "loss: 0.20086583495140076\n",
      "loss: 0.13211049139499664\n",
      "loss: 0.2801170349121094\n",
      "epoch loss:  2.2649312019348145\n",
      "loss: 0.5904955267906189\n",
      "loss: 0.522892951965332\n",
      "loss: 0.17399823665618896\n",
      "loss: 0.3619498610496521\n",
      "loss: 0.20038099586963654\n",
      "loss: 0.13189175724983215\n",
      "loss: 0.28027814626693726\n",
      "epoch loss:  2.261887550354004\n",
      "loss: 0.5896156430244446\n",
      "loss: 0.523681640625\n",
      "loss: 0.1725614368915558\n",
      "loss: 0.36161008477211\n",
      "loss: 0.199580118060112\n",
      "loss: 0.13152305781841278\n",
      "loss: 0.27874070405960083\n",
      "epoch loss:  2.257312536239624\n",
      "loss: 0.5932161211967468\n",
      "loss: 0.5233979821205139\n",
      "loss: 0.17201846837997437\n",
      "loss: 0.3612832725048065\n",
      "loss: 0.19943709671497345\n",
      "loss: 0.1309831738471985\n",
      "loss: 0.2790580093860626\n",
      "epoch loss:  2.2593941688537598\n",
      "loss: 0.5871614813804626\n",
      "loss: 0.522607684135437\n",
      "loss: 0.17236408591270447\n",
      "loss: 0.3607567846775055\n",
      "loss: 0.19909031689167023\n",
      "loss: 0.1312510371208191\n",
      "loss: 0.2777515947818756\n",
      "epoch loss:  2.2509829998016357\n",
      "loss: 0.5856381058692932\n",
      "loss: 0.5217194557189941\n",
      "loss: 0.17176532745361328\n",
      "loss: 0.3609139919281006\n",
      "loss: 0.19820266962051392\n",
      "loss: 0.13055524230003357\n",
      "loss: 0.2773025333881378\n",
      "epoch loss:  2.2460973262786865\n",
      "loss: 0.589369535446167\n",
      "loss: 0.5215016007423401\n",
      "loss: 0.17039352655410767\n",
      "loss: 0.35870492458343506\n",
      "loss: 0.19809147715568542\n",
      "loss: 0.13090236485004425\n",
      "loss: 0.2777760326862335\n",
      "epoch loss:  2.246739387512207\n",
      "loss: 0.5860732793807983\n",
      "loss: 0.5203804969787598\n",
      "loss: 0.17168617248535156\n",
      "loss: 0.35983189940452576\n",
      "loss: 0.1975734829902649\n",
      "loss: 0.13029107451438904\n",
      "loss: 0.2769288122653961\n",
      "epoch loss:  2.242765188217163\n",
      "loss: 0.5851877331733704\n",
      "loss: 0.5208167433738708\n",
      "loss: 0.17088499665260315\n",
      "loss: 0.35789385437965393\n",
      "loss: 0.1976022571325302\n",
      "loss: 0.13046790659427643\n",
      "loss: 0.27683505415916443\n",
      "epoch loss:  2.2396883964538574\n",
      "loss: 0.5841747522354126\n",
      "loss: 0.5197672247886658\n",
      "loss: 0.17155565321445465\n",
      "loss: 0.3566467761993408\n",
      "loss: 0.19755315780639648\n",
      "loss: 0.12983278930187225\n",
      "loss: 0.27647125720977783\n",
      "epoch loss:  2.236001491546631\n",
      "loss: 0.5841577053070068\n",
      "loss: 0.5192957520484924\n",
      "loss: 0.1703738570213318\n",
      "loss: 0.35759153962135315\n",
      "loss: 0.19678711891174316\n",
      "loss: 0.12931863963603973\n",
      "loss: 0.2748863101005554\n",
      "epoch loss:  2.2324109077453613\n",
      "loss: 0.5839657783508301\n",
      "loss: 0.5191967487335205\n",
      "loss: 0.1697220802307129\n",
      "loss: 0.3566955029964447\n",
      "loss: 0.19516772031784058\n",
      "loss: 0.12955723702907562\n",
      "loss: 0.27379563450813293\n",
      "epoch loss:  2.2281007766723633\n",
      "loss: 0.5818376541137695\n",
      "loss: 0.5185933113098145\n",
      "loss: 0.1680602729320526\n",
      "loss: 0.3567822575569153\n",
      "loss: 0.1960127055644989\n",
      "loss: 0.12932102382183075\n",
      "loss: 0.27330729365348816\n",
      "epoch loss:  2.223914384841919\n",
      "loss: 0.5848259329795837\n",
      "loss: 0.5170103311538696\n",
      "loss: 0.1676451861858368\n",
      "loss: 0.3559783101081848\n",
      "loss: 0.19516217708587646\n",
      "loss: 0.12914720177650452\n",
      "loss: 0.2735340893268585\n",
      "epoch loss:  2.2233030796051025\n",
      "loss: 0.5835605263710022\n",
      "loss: 0.5169510245323181\n",
      "loss: 0.16885721683502197\n",
      "loss: 0.3547919690608978\n",
      "loss: 0.1948259323835373\n",
      "loss: 0.12876467406749725\n",
      "loss: 0.27413251996040344\n",
      "epoch loss:  2.221883773803711\n",
      "loss: 0.58443284034729\n",
      "loss: 0.5156382322311401\n",
      "loss: 0.16818518936634064\n",
      "loss: 0.354072630405426\n",
      "loss: 0.19452576339244843\n",
      "loss: 0.12890836596488953\n",
      "loss: 0.27261173725128174\n",
      "epoch loss:  2.218374729156494\n",
      "loss: 0.5842514038085938\n",
      "loss: 0.5168143510818481\n",
      "loss: 0.16895297169685364\n",
      "loss: 0.3535706102848053\n",
      "loss: 0.19362324476242065\n",
      "loss: 0.12814456224441528\n",
      "loss: 0.27133387327194214\n",
      "epoch loss:  2.216691017150879\n",
      "loss: 0.5889769792556763\n",
      "loss: 0.5161614418029785\n",
      "loss: 0.1673710197210312\n",
      "loss: 0.3539988398551941\n",
      "loss: 0.19354413449764252\n",
      "loss: 0.1283431351184845\n",
      "loss: 0.2712366580963135\n",
      "epoch loss:  2.219632148742676\n",
      "loss: 0.5811414122581482\n",
      "loss: 0.5144844651222229\n",
      "loss: 0.1662633717060089\n",
      "loss: 0.3531455993652344\n",
      "loss: 0.1932346373796463\n",
      "loss: 0.12779664993286133\n",
      "loss: 0.2706989347934723\n",
      "epoch loss:  2.2067651748657227\n",
      "loss: 0.5812098979949951\n",
      "loss: 0.5159639120101929\n",
      "loss: 0.1666134148836136\n",
      "loss: 0.35201191902160645\n",
      "loss: 0.19260364770889282\n",
      "loss: 0.12800000607967377\n",
      "loss: 0.27086421847343445\n",
      "epoch loss:  2.2072670459747314\n",
      "loss: 0.5815044045448303\n",
      "loss: 0.5161505341529846\n",
      "loss: 0.16712678968906403\n",
      "loss: 0.35263922810554504\n",
      "loss: 0.19349753856658936\n",
      "loss: 0.127985879778862\n",
      "loss: 0.2717885375022888\n",
      "epoch loss:  2.210692882537842\n",
      "loss: 0.5823351740837097\n",
      "loss: 0.5158641338348389\n",
      "loss: 0.16775958240032196\n",
      "loss: 0.3528560400009155\n",
      "loss: 0.19356589019298553\n",
      "loss: 0.12741418182849884\n",
      "loss: 0.270718514919281\n",
      "epoch loss:  2.2105135917663574\n",
      "loss: 0.5828796625137329\n",
      "loss: 0.5156716704368591\n",
      "loss: 0.1671738177537918\n",
      "loss: 0.35228458046913147\n",
      "loss: 0.19308088719844818\n",
      "loss: 0.12839390337467194\n",
      "loss: 0.27162492275238037\n",
      "epoch loss:  2.2111093997955322\n",
      "loss: 0.5823168158531189\n",
      "loss: 0.516423225402832\n",
      "loss: 0.1679091900587082\n",
      "loss: 0.35272154211997986\n",
      "loss: 0.19367355108261108\n",
      "loss: 0.1280701756477356\n",
      "loss: 0.271223783493042\n",
      "epoch loss:  2.2123382091522217\n",
      "loss: 0.5812798142433167\n",
      "loss: 0.5139447450637817\n",
      "loss: 0.16739819943904877\n",
      "loss: 0.35303306579589844\n",
      "loss: 0.19259577989578247\n",
      "loss: 0.12712840735912323\n",
      "loss: 0.2701437771320343\n",
      "epoch loss:  2.205523729324341\n",
      "loss: 0.5813269019126892\n",
      "loss: 0.5130665898323059\n",
      "loss: 0.1653716266155243\n",
      "loss: 0.35011956095695496\n",
      "loss: 0.19156482815742493\n",
      "loss: 0.12660454213619232\n",
      "loss: 0.2690375745296478\n",
      "epoch loss:  2.197091579437256\n",
      "loss: 0.5785794258117676\n",
      "loss: 0.5132712721824646\n",
      "loss: 0.16536429524421692\n",
      "loss: 0.35034894943237305\n",
      "loss: 0.19048108160495758\n",
      "loss: 0.12649446725845337\n",
      "loss: 0.2687753140926361\n",
      "epoch loss:  2.193314790725708\n",
      "loss: 0.5782594680786133\n",
      "loss: 0.5119010210037231\n",
      "loss: 0.16522003710269928\n",
      "loss: 0.35008910298347473\n",
      "loss: 0.19069859385490417\n",
      "loss: 0.12671606242656708\n",
      "loss: 0.26735901832580566\n",
      "epoch loss:  2.1902432441711426\n",
      "loss: 0.5783048272132874\n",
      "loss: 0.513603687286377\n",
      "loss: 0.16432037949562073\n",
      "loss: 0.3482632339000702\n",
      "loss: 0.1901734173297882\n",
      "loss: 0.1257675141096115\n",
      "loss: 0.2668895125389099\n",
      "epoch loss:  2.1873223781585693\n",
      "loss: 0.577541172504425\n",
      "loss: 0.5125829577445984\n",
      "loss: 0.16466598212718964\n",
      "loss: 0.34864693880081177\n",
      "loss: 0.19046302139759064\n",
      "loss: 0.12669247388839722\n",
      "loss: 0.26653167605400085\n",
      "epoch loss:  2.187124252319336\n",
      "loss: 0.5774338245391846\n",
      "loss: 0.5121180415153503\n",
      "loss: 0.16338583827018738\n",
      "loss: 0.34838855266571045\n",
      "loss: 0.18979483842849731\n",
      "loss: 0.12579044699668884\n",
      "loss: 0.26659390330314636\n",
      "epoch loss:  2.1835055351257324\n",
      "loss: 0.5799773931503296\n",
      "loss: 0.5101615190505981\n",
      "loss: 0.16425441205501556\n",
      "loss: 0.34772607684135437\n",
      "loss: 0.18921354413032532\n",
      "loss: 0.12557274103164673\n",
      "loss: 0.2672715485095978\n",
      "epoch loss:  2.1841771602630615\n",
      "loss: 0.5769188404083252\n",
      "loss: 0.5095630884170532\n",
      "loss: 0.16430452466011047\n",
      "loss: 0.34679752588272095\n",
      "loss: 0.18868625164031982\n",
      "loss: 0.12516842782497406\n",
      "loss: 0.2650776207447052\n",
      "epoch loss:  2.17651629447937\n",
      "loss: 0.5745310187339783\n",
      "loss: 0.5089506506919861\n",
      "loss: 0.1636408567428589\n",
      "loss: 0.34521421790122986\n",
      "loss: 0.18887938559055328\n",
      "loss: 0.1253720372915268\n",
      "loss: 0.2653663754463196\n",
      "epoch loss:  2.17195463180542\n",
      "loss: 0.5762950778007507\n",
      "loss: 0.5104034543037415\n",
      "loss: 0.16312983632087708\n",
      "loss: 0.3461381494998932\n",
      "loss: 0.18775729835033417\n",
      "loss: 0.1256413608789444\n",
      "loss: 0.2643601596355438\n",
      "epoch loss:  2.173725128173828\n",
      "loss: 0.5743695497512817\n",
      "loss: 0.509104311466217\n",
      "loss: 0.16176222264766693\n",
      "loss: 0.34660130739212036\n",
      "loss: 0.1875939965248108\n",
      "loss: 0.1250537782907486\n",
      "loss: 0.26421087980270386\n",
      "epoch loss:  2.1686959266662598\n",
      "loss: 0.5766390562057495\n",
      "loss: 0.5100240111351013\n",
      "loss: 0.16397924721240997\n",
      "loss: 0.3461467921733856\n",
      "loss: 0.18795187771320343\n",
      "loss: 0.12474007159471512\n",
      "loss: 0.2633779048919678\n",
      "epoch loss:  2.1728591918945312\n",
      "loss: 0.573905348777771\n",
      "loss: 0.5079496502876282\n",
      "loss: 0.16227099299430847\n",
      "loss: 0.34487664699554443\n",
      "loss: 0.18732541799545288\n",
      "loss: 0.12511679530143738\n",
      "loss: 0.26375898718833923\n",
      "epoch loss:  2.165203809738159\n",
      "loss: 0.5759795308113098\n",
      "loss: 0.5078244805335999\n",
      "loss: 0.16203121840953827\n",
      "loss: 0.3436218202114105\n",
      "loss: 0.18736383318901062\n",
      "loss: 0.12448911368846893\n",
      "loss: 0.26300618052482605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss:  2.164316177368164\n",
      "loss: 0.5743978023529053\n",
      "loss: 0.5073972940444946\n",
      "loss: 0.16144664585590363\n",
      "loss: 0.34283578395843506\n",
      "loss: 0.18707358837127686\n",
      "loss: 0.12446510046720505\n",
      "loss: 0.26312723755836487\n",
      "epoch loss:  2.160743474960327\n",
      "loss: 0.5733863711357117\n",
      "loss: 0.5073127746582031\n",
      "loss: 0.1616535633802414\n",
      "loss: 0.34242725372314453\n",
      "loss: 0.18626654148101807\n",
      "loss: 0.12392211705446243\n",
      "loss: 0.26139792799949646\n",
      "epoch loss:  2.1563665866851807\n",
      "loss: 0.5739397406578064\n",
      "loss: 0.507036030292511\n",
      "loss: 0.1611405611038208\n",
      "loss: 0.3415936827659607\n",
      "loss: 0.18535707890987396\n",
      "loss: 0.1237591877579689\n",
      "loss: 0.26182854175567627\n",
      "epoch loss:  2.1546547412872314\n",
      "loss: 0.5740092396736145\n",
      "loss: 0.5063887238502502\n",
      "loss: 0.15998122096061707\n",
      "loss: 0.34301769733428955\n",
      "loss: 0.18569643795490265\n",
      "loss: 0.12409556657075882\n",
      "loss: 0.2607095539569855\n",
      "epoch loss:  2.1538984775543213\n",
      "loss: 0.5726830363273621\n",
      "loss: 0.5046035051345825\n",
      "loss: 0.1605639010667801\n",
      "loss: 0.3412225842475891\n",
      "loss: 0.18532349169254303\n",
      "loss: 0.12371590733528137\n",
      "loss: 0.25981998443603516\n",
      "epoch loss:  2.147932291030884\n",
      "loss: 0.5716375112533569\n",
      "loss: 0.5052216053009033\n",
      "loss: 0.15954676270484924\n",
      "loss: 0.3404422998428345\n",
      "loss: 0.1849522739648819\n",
      "loss: 0.12287837266921997\n",
      "loss: 0.25987908244132996\n",
      "epoch loss:  2.1445579528808594\n",
      "loss: 0.5723597407341003\n",
      "loss: 0.5055921077728271\n",
      "loss: 0.16000734269618988\n",
      "loss: 0.3401218354701996\n",
      "loss: 0.18400724232196808\n",
      "loss: 0.1228577047586441\n",
      "loss: 0.2594567537307739\n",
      "epoch loss:  2.1444029808044434\n",
      "loss: 0.5747647285461426\n",
      "loss: 0.5041587352752686\n",
      "loss: 0.15969184041023254\n",
      "loss: 0.3403076231479645\n",
      "loss: 0.18471801280975342\n",
      "loss: 0.12300699949264526\n",
      "loss: 0.2589563727378845\n",
      "epoch loss:  2.145604372024536\n",
      "loss: 0.5712148547172546\n",
      "loss: 0.5035565495491028\n",
      "loss: 0.1594693809747696\n",
      "loss: 0.33978980779647827\n",
      "loss: 0.18353234231472015\n",
      "loss: 0.12302689254283905\n",
      "loss: 0.25905221700668335\n",
      "epoch loss:  2.1396420001983643\n",
      "loss: 0.570052444934845\n",
      "loss: 0.5032110810279846\n",
      "loss: 0.1585783213376999\n",
      "loss: 0.33852139115333557\n",
      "loss: 0.18411941826343536\n",
      "loss: 0.12306304275989532\n",
      "loss: 0.2578990161418915\n",
      "epoch loss:  2.1354446411132812\n",
      "loss: 0.568569540977478\n",
      "loss: 0.5042710900306702\n",
      "loss: 0.1582147181034088\n",
      "loss: 0.33941829204559326\n",
      "loss: 0.18337303400039673\n",
      "loss: 0.1222214326262474\n",
      "loss: 0.25752878189086914\n",
      "epoch loss:  2.133596897125244\n",
      "loss: 0.572153627872467\n",
      "loss: 0.5032752752304077\n",
      "loss: 0.15844693779945374\n",
      "loss: 0.33745166659355164\n",
      "loss: 0.1837819516658783\n",
      "loss: 0.122123122215271\n",
      "loss: 0.25751903653144836\n",
      "epoch loss:  2.134751796722412\n",
      "loss: 0.5685412883758545\n",
      "loss: 0.5020523071289062\n",
      "loss: 0.1585700511932373\n",
      "loss: 0.33785372972488403\n",
      "loss: 0.18349291384220123\n",
      "loss: 0.1221630647778511\n",
      "loss: 0.25758153200149536\n",
      "epoch loss:  2.1302547454833984\n",
      "loss: 0.5687941312789917\n",
      "loss: 0.5023665428161621\n",
      "loss: 0.15762989223003387\n",
      "loss: 0.33729618787765503\n",
      "loss: 0.18290583789348602\n",
      "loss: 0.12247384339570999\n",
      "loss: 0.25827088952064514\n",
      "epoch loss:  2.129737377166748\n",
      "loss: 0.5673183798789978\n",
      "loss: 0.5042939782142639\n",
      "loss: 0.15880709886550903\n",
      "loss: 0.3398778736591339\n",
      "loss: 0.1837226003408432\n",
      "loss: 0.12318624556064606\n",
      "loss: 0.258086234331131\n",
      "epoch loss:  2.1352922916412354\n",
      "loss: 0.5730857849121094\n",
      "loss: 0.5029394626617432\n",
      "loss: 0.16002388298511505\n",
      "loss: 0.3391743302345276\n",
      "loss: 0.1838289499282837\n",
      "loss: 0.12218742817640305\n",
      "loss: 0.2582474648952484\n",
      "epoch loss:  2.1394872665405273\n",
      "loss: 0.5693437457084656\n",
      "loss: 0.5038754343986511\n",
      "loss: 0.15987488627433777\n",
      "loss: 0.34107664227485657\n",
      "loss: 0.18418961763381958\n",
      "loss: 0.12208186835050583\n",
      "loss: 0.25824183225631714\n",
      "epoch loss:  2.138684034347534\n",
      "loss: 0.5692748427391052\n",
      "loss: 0.5015186667442322\n",
      "loss: 0.15688997507095337\n",
      "loss: 0.33661094307899475\n",
      "loss: 0.18200446665287018\n",
      "loss: 0.12138846516609192\n",
      "loss: 0.2562316954135895\n",
      "epoch loss:  2.1239190101623535\n",
      "loss: 0.5672854781150818\n",
      "loss: 0.5006763935089111\n",
      "loss: 0.15647780895233154\n",
      "loss: 0.33689963817596436\n",
      "loss: 0.1817372590303421\n",
      "loss: 0.12168461829423904\n",
      "loss: 0.2546035945415497\n",
      "epoch loss:  2.1193649768829346\n",
      "loss: 0.5675874352455139\n",
      "loss: 0.5009167790412903\n",
      "loss: 0.15727388858795166\n",
      "loss: 0.33662328124046326\n",
      "loss: 0.18208274245262146\n",
      "loss: 0.12156662344932556\n",
      "loss: 0.25597119331359863\n",
      "epoch loss:  2.1220221519470215\n",
      "loss: 0.5692200064659119\n",
      "loss: 0.5016449093818665\n",
      "loss: 0.1578063815832138\n",
      "loss: 0.3370075821876526\n",
      "loss: 0.18240585923194885\n",
      "loss: 0.12152014672756195\n",
      "loss: 0.25712183117866516\n",
      "epoch loss:  2.1267266273498535\n",
      "loss: 0.5703666806221008\n",
      "loss: 0.5014289021492004\n",
      "loss: 0.15851075947284698\n",
      "loss: 0.3360722064971924\n",
      "loss: 0.18131713569164276\n",
      "loss: 0.12097737938165665\n",
      "loss: 0.25598984956741333\n",
      "epoch loss:  2.1246628761291504\n",
      "loss: 0.5639203190803528\n",
      "loss: 0.4999513328075409\n",
      "loss: 0.1566670835018158\n",
      "loss: 0.33402860164642334\n",
      "loss: 0.18059831857681274\n",
      "loss: 0.1207696795463562\n",
      "loss: 0.25361132621765137\n",
      "epoch loss:  2.109546661376953\n",
      "loss: 0.5702404975891113\n",
      "loss: 0.5003670454025269\n",
      "loss: 0.15635976195335388\n",
      "loss: 0.33496999740600586\n",
      "loss: 0.18080198764801025\n",
      "loss: 0.12094809859991074\n",
      "loss: 0.2557157576084137\n",
      "epoch loss:  2.119403123855591\n",
      "loss: 0.5679893493652344\n",
      "loss: 0.5007977485656738\n",
      "loss: 0.15708258748054504\n",
      "loss: 0.3378097116947174\n",
      "loss: 0.18124938011169434\n",
      "loss: 0.12103722244501114\n",
      "loss: 0.25510174036026\n",
      "epoch loss:  2.121067762374878\n",
      "loss: 0.5654717683792114\n",
      "loss: 0.5004206299781799\n",
      "loss: 0.1571674346923828\n",
      "loss: 0.3333183526992798\n",
      "loss: 0.18021796643733978\n",
      "loss: 0.12061478942632675\n",
      "loss: 0.25353825092315674\n",
      "epoch loss:  2.1107492446899414\n",
      "loss: 0.568444550037384\n",
      "loss: 0.49835366010665894\n",
      "loss: 0.1566741168498993\n",
      "loss: 0.33398714661598206\n",
      "loss: 0.180178701877594\n",
      "loss: 0.12073949724435806\n",
      "loss: 0.2537200450897217\n",
      "epoch loss:  2.11209774017334\n",
      "loss: 0.5663963556289673\n",
      "loss: 0.5020015835762024\n",
      "loss: 0.15763777494430542\n",
      "loss: 0.3351908326148987\n",
      "loss: 0.180528923869133\n",
      "loss: 0.12049498409032822\n",
      "loss: 0.25570106506347656\n",
      "epoch loss:  2.1179513931274414\n",
      "loss: 0.5666142106056213\n",
      "loss: 0.5014047622680664\n",
      "loss: 0.15540780127048492\n",
      "loss: 0.33334627747535706\n",
      "loss: 0.18079973757266998\n",
      "loss: 0.12109079957008362\n",
      "loss: 0.2526554465293884\n",
      "epoch loss:  2.111318826675415\n",
      "loss: 0.569629967212677\n",
      "loss: 0.498073011636734\n",
      "loss: 0.15763050317764282\n",
      "loss: 0.3327540457248688\n",
      "loss: 0.18040038645267487\n",
      "loss: 0.1209513247013092\n",
      "loss: 0.25351497530937195\n",
      "epoch loss:  2.1129541397094727\n",
      "loss: 0.5672845244407654\n",
      "loss: 0.498467355966568\n",
      "loss: 0.15687143802642822\n",
      "loss: 0.33249136805534363\n",
      "loss: 0.18099240958690643\n",
      "loss: 0.121013343334198\n",
      "loss: 0.25334632396698\n",
      "epoch loss:  2.110466957092285\n",
      "loss: 0.5672721266746521\n",
      "loss: 0.4984647035598755\n",
      "loss: 0.1551218032836914\n",
      "loss: 0.3322811722755432\n",
      "loss: 0.17908063530921936\n",
      "loss: 0.12049935758113861\n",
      "loss: 0.25197458267211914\n",
      "epoch loss:  2.104694366455078\n",
      "loss: 0.5652654767036438\n",
      "loss: 0.4991913437843323\n",
      "loss: 0.15494179725646973\n",
      "loss: 0.33233001828193665\n",
      "loss: 0.1806814968585968\n",
      "loss: 0.1199941411614418\n",
      "loss: 0.25304800271987915\n",
      "epoch loss:  2.105452299118042\n",
      "loss: 0.5644988417625427\n",
      "loss: 0.49847325682640076\n",
      "loss: 0.15560810267925262\n",
      "loss: 0.3333567976951599\n",
      "loss: 0.17945919930934906\n",
      "loss: 0.11961959302425385\n",
      "loss: 0.25249770283699036\n",
      "epoch loss:  2.103513479232788\n",
      "loss: 0.5655014514923096\n",
      "loss: 0.4982016980648041\n",
      "loss: 0.15504541993141174\n",
      "loss: 0.33036351203918457\n",
      "loss: 0.17853090167045593\n",
      "loss: 0.12001155316829681\n",
      "loss: 0.2504529654979706\n",
      "epoch loss:  2.0981075763702393\n",
      "loss: 0.564975380897522\n",
      "loss: 0.4987139105796814\n",
      "loss: 0.15532146394252777\n",
      "loss: 0.3325190544128418\n",
      "loss: 0.17877617478370667\n",
      "loss: 0.11912185698747635\n",
      "loss: 0.2524155378341675\n",
      "epoch loss:  2.1018433570861816\n",
      "loss: 0.5646196007728577\n",
      "loss: 0.49573081731796265\n",
      "loss: 0.15443575382232666\n",
      "loss: 0.33046114444732666\n",
      "loss: 0.17814287543296814\n",
      "loss: 0.1195078119635582\n",
      "loss: 0.25239723920822144\n",
      "epoch loss:  2.0952951908111572\n",
      "loss: 0.5646313428878784\n",
      "loss: 0.49539199471473694\n",
      "loss: 0.15447679162025452\n",
      "loss: 0.3297540247440338\n",
      "loss: 0.1782122701406479\n",
      "loss: 0.1189308911561966\n",
      "loss: 0.25115811824798584\n",
      "epoch loss:  2.092555522918701\n",
      "loss: 0.5621038675308228\n",
      "loss: 0.49468815326690674\n",
      "loss: 0.1541943997144699\n",
      "loss: 0.3301706910133362\n",
      "loss: 0.1778712272644043\n",
      "loss: 0.11907145380973816\n",
      "loss: 0.24981436133384705\n",
      "epoch loss:  2.087913990020752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5607642531394958\n",
      "loss: 0.4952254891395569\n",
      "loss: 0.1537228673696518\n",
      "loss: 0.32862481474876404\n",
      "loss: 0.17680121958255768\n",
      "loss: 0.11909927427768707\n",
      "loss: 0.24885429441928864\n",
      "epoch loss:  2.083092212677002\n",
      "loss: 0.5627892017364502\n",
      "loss: 0.49395641684532166\n",
      "loss: 0.1535744071006775\n",
      "loss: 0.3286449611186981\n",
      "loss: 0.17692017555236816\n",
      "loss: 0.1194380670785904\n",
      "loss: 0.24827203154563904\n",
      "epoch loss:  2.0835952758789062\n",
      "loss: 0.5602575540542603\n",
      "loss: 0.49572235345840454\n",
      "loss: 0.15410108864307404\n",
      "loss: 0.3281877338886261\n",
      "loss: 0.17614516615867615\n",
      "loss: 0.1195257157087326\n",
      "loss: 0.2492993324995041\n",
      "epoch loss:  2.0832390785217285\n",
      "loss: 0.559352457523346\n",
      "loss: 0.4945198595523834\n",
      "loss: 0.1521582454442978\n",
      "loss: 0.32771801948547363\n",
      "loss: 0.17614729702472687\n",
      "loss: 0.11934905499219894\n",
      "loss: 0.24821989238262177\n",
      "epoch loss:  2.0774648189544678\n",
      "loss: 0.5627308487892151\n",
      "loss: 0.4954156279563904\n",
      "loss: 0.15314015746116638\n",
      "loss: 0.3268163502216339\n",
      "loss: 0.17615292966365814\n",
      "loss: 0.11831577867269516\n",
      "loss: 0.24706526100635529\n",
      "epoch loss:  2.079637050628662\n",
      "loss: 0.5617967247962952\n",
      "loss: 0.4954356551170349\n",
      "loss: 0.1515827775001526\n",
      "loss: 0.32589706778526306\n",
      "loss: 0.1762845516204834\n",
      "loss: 0.11870494484901428\n",
      "loss: 0.2468789517879486\n",
      "epoch loss:  2.07658052444458\n",
      "loss: 0.5631347894668579\n",
      "loss: 0.4917340576648712\n",
      "loss: 0.15280817449092865\n",
      "loss: 0.32592734694480896\n",
      "loss: 0.17488227784633636\n",
      "loss: 0.11817052215337753\n",
      "loss: 0.24771887063980103\n",
      "epoch loss:  2.074376106262207\n",
      "loss: 0.5599607825279236\n",
      "loss: 0.49335163831710815\n",
      "loss: 0.15130822360515594\n",
      "loss: 0.3251776099205017\n",
      "loss: 0.17514149844646454\n",
      "loss: 0.11785139888525009\n",
      "loss: 0.24720628559589386\n",
      "epoch loss:  2.0699973106384277\n",
      "loss: 0.561043918132782\n",
      "loss: 0.4923624098300934\n",
      "loss: 0.15134914219379425\n",
      "loss: 0.3258246183395386\n",
      "loss: 0.17492514848709106\n",
      "loss: 0.11798691749572754\n",
      "loss: 0.24508774280548096\n",
      "epoch loss:  2.068580150604248\n",
      "loss: 0.5607796907424927\n",
      "loss: 0.49182116985321045\n",
      "loss: 0.15256384015083313\n",
      "loss: 0.32572075724601746\n",
      "loss: 0.17468179762363434\n",
      "loss: 0.11775363236665726\n",
      "loss: 0.2458411455154419\n",
      "epoch loss:  2.069161891937256\n",
      "loss: 0.5580835938453674\n",
      "loss: 0.49089962244033813\n",
      "loss: 0.1510901153087616\n",
      "loss: 0.32579508423805237\n",
      "loss: 0.1746658831834793\n",
      "loss: 0.1172928661108017\n",
      "loss: 0.2458467334508896\n",
      "epoch loss:  2.063673973083496\n",
      "loss: 0.557263195514679\n",
      "loss: 0.491106241941452\n",
      "loss: 0.15263821184635162\n",
      "loss: 0.3256095051765442\n",
      "loss: 0.17427118122577667\n",
      "loss: 0.11786897480487823\n",
      "loss: 0.24447280168533325\n",
      "epoch loss:  2.063230037689209\n",
      "loss: 0.5569422245025635\n",
      "loss: 0.491137832403183\n",
      "loss: 0.15153494477272034\n",
      "loss: 0.32299330830574036\n",
      "loss: 0.17439426481723785\n",
      "loss: 0.11734785884618759\n",
      "loss: 0.24418623745441437\n",
      "epoch loss:  2.0585365295410156\n",
      "loss: 0.558287501335144\n",
      "loss: 0.49228718876838684\n",
      "loss: 0.14951343834400177\n",
      "loss: 0.3224782347679138\n",
      "loss: 0.1736292690038681\n",
      "loss: 0.11716718226671219\n",
      "loss: 0.245819553732872\n",
      "epoch loss:  2.0591824054718018\n",
      "loss: 0.5595356225967407\n",
      "loss: 0.4910906255245209\n",
      "loss: 0.15087173879146576\n",
      "loss: 0.3228622376918793\n",
      "loss: 0.17174610495567322\n",
      "loss: 0.11698351800441742\n",
      "loss: 0.24364618957042694\n",
      "epoch loss:  2.0567362308502197\n",
      "loss: 0.5573703646659851\n",
      "loss: 0.49001941084861755\n",
      "loss: 0.14991597831249237\n",
      "loss: 0.3214310109615326\n",
      "loss: 0.17342481017112732\n",
      "loss: 0.11658790707588196\n",
      "loss: 0.2434065192937851\n",
      "epoch loss:  2.0521559715270996\n",
      "loss: 0.5555269718170166\n",
      "loss: 0.4886886179447174\n",
      "loss: 0.1492958813905716\n",
      "loss: 0.32293403148651123\n",
      "loss: 0.17239315807819366\n",
      "loss: 0.11646345257759094\n",
      "loss: 0.2428838312625885\n",
      "epoch loss:  2.0481860637664795\n",
      "loss: 0.5573585033416748\n",
      "loss: 0.4887017011642456\n",
      "loss: 0.15002630650997162\n",
      "loss: 0.3215126395225525\n",
      "loss: 0.1723775863647461\n",
      "loss: 0.11666899174451828\n",
      "loss: 0.2425311952829361\n",
      "epoch loss:  2.0491769313812256\n",
      "loss: 0.5578649640083313\n",
      "loss: 0.4896850883960724\n",
      "loss: 0.14907889068126678\n",
      "loss: 0.3210051953792572\n",
      "loss: 0.1723722517490387\n",
      "loss: 0.11627204716205597\n",
      "loss: 0.24281054735183716\n",
      "epoch loss:  2.049088954925537\n",
      "loss: 0.5559183955192566\n",
      "loss: 0.4887847900390625\n",
      "loss: 0.1489790827035904\n",
      "loss: 0.3207821846008301\n",
      "loss: 0.17196108400821686\n",
      "loss: 0.11671051383018494\n",
      "loss: 0.24295322597026825\n",
      "epoch loss:  2.0460894107818604\n",
      "loss: 0.5562573075294495\n",
      "loss: 0.48830896615982056\n",
      "loss: 0.1488918513059616\n",
      "loss: 0.32064181566238403\n",
      "loss: 0.17241621017456055\n",
      "loss: 0.11631684750318527\n",
      "loss: 0.242625430226326\n",
      "epoch loss:  2.0454583168029785\n",
      "loss: 0.5580708384513855\n",
      "loss: 0.4873981177806854\n",
      "loss: 0.1489730179309845\n",
      "loss: 0.3208596110343933\n",
      "loss: 0.17268751561641693\n",
      "loss: 0.11628684401512146\n",
      "loss: 0.24233397841453552\n",
      "epoch loss:  2.046609878540039\n",
      "loss: 0.5568276047706604\n",
      "loss: 0.48834049701690674\n",
      "loss: 0.1500602513551712\n",
      "loss: 0.32089364528656006\n",
      "loss: 0.1718718260526657\n",
      "loss: 0.11591848731040955\n",
      "loss: 0.24285747110843658\n",
      "epoch loss:  2.046769857406616\n",
      "loss: 0.5557665228843689\n",
      "loss: 0.48920637369155884\n",
      "loss: 0.149280846118927\n",
      "loss: 0.3208153545856476\n",
      "loss: 0.17176392674446106\n",
      "loss: 0.11588981002569199\n",
      "loss: 0.24165596067905426\n",
      "epoch loss:  2.0443787574768066\n",
      "loss: 0.5565882325172424\n",
      "loss: 0.4897746443748474\n",
      "loss: 0.14786885678768158\n",
      "loss: 0.32078805565834045\n",
      "loss: 0.17123371362686157\n",
      "loss: 0.1158418208360672\n",
      "loss: 0.24207288026809692\n",
      "epoch loss:  2.04416823387146\n",
      "loss: 0.5556850433349609\n",
      "loss: 0.48671281337738037\n",
      "loss: 0.149635910987854\n",
      "loss: 0.31865477561950684\n",
      "loss: 0.17106389999389648\n",
      "loss: 0.1161230206489563\n",
      "loss: 0.24137254059314728\n",
      "epoch loss:  2.039247989654541\n",
      "loss: 0.5541611909866333\n",
      "loss: 0.4890917241573334\n",
      "loss: 0.14919885993003845\n",
      "loss: 0.31914061307907104\n",
      "loss: 0.1713649183511734\n",
      "loss: 0.11635975539684296\n",
      "loss: 0.2421853393316269\n",
      "epoch loss:  2.0415022373199463\n",
      "loss: 0.5538774728775024\n",
      "loss: 0.48970723152160645\n",
      "loss: 0.149014413356781\n",
      "loss: 0.31863391399383545\n",
      "loss: 0.17092785239219666\n",
      "loss: 0.11621195822954178\n",
      "loss: 0.24175269901752472\n",
      "epoch loss:  2.040125608444214\n",
      "loss: 0.5541062951087952\n",
      "loss: 0.4853024184703827\n",
      "loss: 0.1481381356716156\n",
      "loss: 0.3186427652835846\n",
      "loss: 0.17102351784706116\n",
      "loss: 0.11548366397619247\n",
      "loss: 0.23959335684776306\n",
      "epoch loss:  2.032289981842041\n",
      "loss: 0.5555596947669983\n",
      "loss: 0.48624056577682495\n",
      "loss: 0.14800864458084106\n",
      "loss: 0.3173278570175171\n",
      "loss: 0.169845849275589\n",
      "loss: 0.1152518168091774\n",
      "loss: 0.24014095962047577\n",
      "epoch loss:  2.0323753356933594\n",
      "loss: 0.5546730756759644\n",
      "loss: 0.48637279868125916\n",
      "loss: 0.147951140999794\n",
      "loss: 0.3175494372844696\n",
      "loss: 0.17068327963352203\n",
      "loss: 0.11584273725748062\n",
      "loss: 0.24069100618362427\n",
      "epoch loss:  2.0337634086608887\n",
      "loss: 0.5550846457481384\n",
      "loss: 0.48450779914855957\n",
      "loss: 0.14970670640468597\n",
      "loss: 0.31731662154197693\n",
      "loss: 0.17101335525512695\n",
      "loss: 0.11654937267303467\n",
      "loss: 0.23960556089878082\n",
      "epoch loss:  2.0337841510772705\n",
      "loss: 0.5535088181495667\n",
      "loss: 0.4855545461177826\n",
      "loss: 0.14672359824180603\n",
      "loss: 0.31604641675949097\n",
      "loss: 0.17032583057880402\n",
      "loss: 0.11523488163948059\n",
      "loss: 0.2391706109046936\n",
      "epoch loss:  2.026564836502075\n",
      "loss: 0.5524824261665344\n",
      "loss: 0.4849577248096466\n",
      "loss: 0.14885692298412323\n",
      "loss: 0.31625160574913025\n",
      "loss: 0.16947241127490997\n",
      "loss: 0.11471540480852127\n",
      "loss: 0.23798775672912598\n",
      "epoch loss:  2.0247244834899902\n",
      "loss: 0.5516266226768494\n",
      "loss: 0.48479193449020386\n",
      "loss: 0.1464986503124237\n",
      "loss: 0.3165409564971924\n",
      "loss: 0.17016056180000305\n",
      "loss: 0.11527509987354279\n",
      "loss: 0.23817892372608185\n",
      "epoch loss:  2.0230727195739746\n",
      "loss: 0.5586227774620056\n",
      "loss: 0.48498600721359253\n",
      "loss: 0.14788365364074707\n",
      "loss: 0.31596213579177856\n",
      "loss: 0.16918130218982697\n",
      "loss: 0.11530178785324097\n",
      "loss: 0.23919403553009033\n",
      "epoch loss:  2.0311317443847656\n",
      "loss: 0.5517298579216003\n",
      "loss: 0.48353418707847595\n",
      "loss: 0.14677715301513672\n",
      "loss: 0.31581568717956543\n",
      "loss: 0.1687714010477066\n",
      "loss: 0.1141078770160675\n",
      "loss: 0.2378360629081726\n",
      "epoch loss:  2.0185720920562744\n",
      "loss: 0.5511128306388855\n",
      "loss: 0.4840659201145172\n",
      "loss: 0.14623762667179108\n",
      "loss: 0.3146902918815613\n",
      "loss: 0.16833408176898956\n",
      "loss: 0.1141396164894104\n",
      "loss: 0.23785245418548584\n",
      "epoch loss:  2.016432762145996\n",
      "loss: 0.5517364740371704\n",
      "loss: 0.48369693756103516\n",
      "loss: 0.14634136855602264\n",
      "loss: 0.31501466035842896\n",
      "loss: 0.1687667816877365\n",
      "loss: 0.11564988642930984\n",
      "loss: 0.2375262826681137\n",
      "epoch loss:  2.0187323093414307\n",
      "loss: 0.5549951195716858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.4833579659461975\n",
      "loss: 0.1467922031879425\n",
      "loss: 0.3144601583480835\n",
      "loss: 0.16827717423439026\n",
      "loss: 0.11459264159202576\n",
      "loss: 0.2379608303308487\n",
      "epoch loss:  2.0204360485076904\n",
      "loss: 0.5511054396629333\n",
      "loss: 0.48417648673057556\n",
      "loss: 0.14701546728610992\n",
      "loss: 0.3142998516559601\n",
      "loss: 0.16769616305828094\n",
      "loss: 0.1140153780579567\n",
      "loss: 0.23736168444156647\n",
      "epoch loss:  2.0156702995300293\n",
      "loss: 0.5507424473762512\n",
      "loss: 0.4825613796710968\n",
      "loss: 0.14602702856063843\n",
      "loss: 0.3146819770336151\n",
      "loss: 0.16854910552501678\n",
      "loss: 0.11423654109239578\n",
      "loss: 0.2366643249988556\n",
      "epoch loss:  2.013462781906128\n",
      "loss: 0.5525040626525879\n",
      "loss: 0.48430079221725464\n",
      "loss: 0.1465781033039093\n",
      "loss: 0.3131634294986725\n",
      "loss: 0.16791567206382751\n",
      "loss: 0.11449184268712997\n",
      "loss: 0.23672005534172058\n",
      "epoch loss:  2.015673875808716\n",
      "loss: 0.5503508448600769\n",
      "loss: 0.482476145029068\n",
      "loss: 0.14598038792610168\n",
      "loss: 0.3138553202152252\n",
      "loss: 0.1678025871515274\n",
      "loss: 0.1134597510099411\n",
      "loss: 0.23666232824325562\n",
      "epoch loss:  2.010587215423584\n",
      "loss: 0.5508673787117004\n",
      "loss: 0.4831719398498535\n",
      "loss: 0.14560170471668243\n",
      "loss: 0.3128042221069336\n",
      "loss: 0.16763196885585785\n",
      "loss: 0.11452293395996094\n",
      "loss: 0.23663577437400818\n",
      "epoch loss:  2.0112359523773193\n",
      "loss: 0.5535582900047302\n",
      "loss: 0.4829055964946747\n",
      "loss: 0.14499911665916443\n",
      "loss: 0.3131778836250305\n",
      "loss: 0.16743695735931396\n",
      "loss: 0.11354249715805054\n",
      "loss: 0.23620527982711792\n",
      "epoch loss:  2.0118255615234375\n",
      "loss: 0.5498995184898376\n",
      "loss: 0.4829448163509369\n",
      "loss: 0.14617621898651123\n",
      "loss: 0.3134416937828064\n",
      "loss: 0.16724230349063873\n",
      "loss: 0.11347442865371704\n",
      "loss: 0.23574814200401306\n",
      "epoch loss:  2.0089268684387207\n",
      "loss: 0.5508686304092407\n",
      "loss: 0.4823708236217499\n",
      "loss: 0.14592860639095306\n",
      "loss: 0.3127039074897766\n",
      "loss: 0.1675606071949005\n",
      "loss: 0.11351465433835983\n",
      "loss: 0.23555901646614075\n",
      "epoch loss:  2.0085062980651855\n",
      "loss: 0.5530467629432678\n",
      "loss: 0.482408732175827\n",
      "loss: 0.14544005692005157\n",
      "loss: 0.312496155500412\n",
      "loss: 0.16693395376205444\n",
      "loss: 0.11372700333595276\n",
      "loss: 0.23489181697368622\n",
      "epoch loss:  2.008944511413574\n",
      "loss: 0.5518187284469604\n",
      "loss: 0.4804552495479584\n",
      "loss: 0.1450275033712387\n",
      "loss: 0.31153592467308044\n",
      "loss: 0.166078120470047\n",
      "loss: 0.11334606260061264\n",
      "loss: 0.23430132865905762\n",
      "epoch loss:  2.002562999725342\n",
      "loss: 0.5498209595680237\n",
      "loss: 0.4802168011665344\n",
      "loss: 0.1457991898059845\n",
      "loss: 0.31022900342941284\n",
      "loss: 0.16582366824150085\n",
      "loss: 0.1129782572388649\n",
      "loss: 0.23437102138996124\n",
      "epoch loss:  1.9992388486862183\n",
      "loss: 0.5485854148864746\n",
      "loss: 0.4801871180534363\n",
      "loss: 0.1443997025489807\n",
      "loss: 0.30916479229927063\n",
      "loss: 0.16630280017852783\n",
      "loss: 0.11289526522159576\n",
      "loss: 0.23379670083522797\n",
      "epoch loss:  1.9953317642211914\n",
      "loss: 0.5488085746765137\n",
      "loss: 0.47923892736434937\n",
      "loss: 0.14527073502540588\n",
      "loss: 0.31027206778526306\n",
      "loss: 0.16569185256958008\n",
      "loss: 0.11231587827205658\n",
      "loss: 0.2341899871826172\n",
      "epoch loss:  1.9957880973815918\n",
      "loss: 0.5475426912307739\n",
      "loss: 0.48044225573539734\n",
      "loss: 0.14524075388908386\n",
      "loss: 0.3099232316017151\n",
      "loss: 0.16544309258460999\n",
      "loss: 0.11278795450925827\n",
      "loss: 0.23326019942760468\n",
      "epoch loss:  1.9946402311325073\n",
      "loss: 0.5483365654945374\n",
      "loss: 0.48062968254089355\n",
      "loss: 0.1437746286392212\n",
      "loss: 0.30941444635391235\n",
      "loss: 0.16525627672672272\n",
      "loss: 0.11246515810489655\n",
      "loss: 0.2337241917848587\n",
      "epoch loss:  1.9936009645462036\n",
      "loss: 0.5499727725982666\n",
      "loss: 0.4797516465187073\n",
      "loss: 0.14352913200855255\n",
      "loss: 0.3096454441547394\n",
      "loss: 0.1654740273952484\n",
      "loss: 0.11305662244558334\n",
      "loss: 0.23337148129940033\n",
      "epoch loss:  1.9948011636734009\n",
      "loss: 0.5477426648139954\n",
      "loss: 0.4781873822212219\n",
      "loss: 0.14348101615905762\n",
      "loss: 0.30942943692207336\n",
      "loss: 0.1650695949792862\n",
      "loss: 0.11233186721801758\n",
      "loss: 0.2331235557794571\n",
      "epoch loss:  1.9893654584884644\n",
      "loss: 0.5465651154518127\n",
      "loss: 0.47928065061569214\n",
      "loss: 0.14347805082798004\n",
      "loss: 0.3095429539680481\n",
      "loss: 0.16490456461906433\n",
      "loss: 0.11251211166381836\n",
      "loss: 0.23229056596755981\n",
      "epoch loss:  1.9885740280151367\n",
      "loss: 0.5452341437339783\n",
      "loss: 0.48003140091896057\n",
      "loss: 0.1435644030570984\n",
      "loss: 0.3090200424194336\n",
      "loss: 0.16548557579517365\n",
      "loss: 0.11249279230833054\n",
      "loss: 0.23173493146896362\n",
      "epoch loss:  1.9875633716583252\n",
      "loss: 0.5491205453872681\n",
      "loss: 0.47851693630218506\n",
      "loss: 0.14333727955818176\n",
      "loss: 0.3082737922668457\n",
      "loss: 0.1646527647972107\n",
      "loss: 0.11232388019561768\n",
      "loss: 0.23334604501724243\n",
      "epoch loss:  1.9895713329315186\n",
      "loss: 0.5518624782562256\n",
      "loss: 0.47855502367019653\n",
      "loss: 0.14308984577655792\n",
      "loss: 0.3077188730239868\n",
      "loss: 0.16477911174297333\n",
      "loss: 0.11224228143692017\n",
      "loss: 0.2318352311849594\n",
      "epoch loss:  1.990082859992981\n",
      "loss: 0.5467789173126221\n",
      "loss: 0.47930800914764404\n",
      "loss: 0.14311103522777557\n",
      "loss: 0.30716463923454285\n",
      "loss: 0.16468389332294464\n",
      "loss: 0.11220590025186539\n",
      "loss: 0.23188187181949615\n",
      "epoch loss:  1.985134243965149\n",
      "loss: 0.5473451018333435\n",
      "loss: 0.47853514552116394\n",
      "loss: 0.14269964396953583\n",
      "loss: 0.30785176157951355\n",
      "loss: 0.1641552746295929\n",
      "loss: 0.11209499835968018\n",
      "loss: 0.2305426150560379\n",
      "epoch loss:  1.9832245111465454\n",
      "loss: 0.5470826029777527\n",
      "loss: 0.4785465598106384\n",
      "loss: 0.14228671789169312\n",
      "loss: 0.30730071663856506\n",
      "loss: 0.1649446338415146\n",
      "loss: 0.11229170113801956\n",
      "loss: 0.23177418112754822\n",
      "epoch loss:  1.9842270612716675\n",
      "loss: 0.548988401889801\n",
      "loss: 0.4769873023033142\n",
      "loss: 0.140880286693573\n",
      "loss: 0.30673614144325256\n",
      "loss: 0.16436767578125\n",
      "loss: 0.11220981925725937\n",
      "loss: 0.23101606965065002\n",
      "epoch loss:  1.9811856746673584\n",
      "loss: 0.5458831191062927\n",
      "loss: 0.47707492113113403\n",
      "loss: 0.14256103336811066\n",
      "loss: 0.3069162964820862\n",
      "loss: 0.16352783143520355\n",
      "loss: 0.11237893998622894\n",
      "loss: 0.23026232421398163\n",
      "epoch loss:  1.9786045551300049\n",
      "loss: 0.546603262424469\n",
      "loss: 0.4771832823753357\n",
      "loss: 0.14263688027858734\n",
      "loss: 0.3065338134765625\n",
      "loss: 0.16380369663238525\n",
      "loss: 0.11185893416404724\n",
      "loss: 0.23021890223026276\n",
      "epoch loss:  1.9788388013839722\n",
      "loss: 0.5454043745994568\n",
      "loss: 0.4769202172756195\n",
      "loss: 0.14219582080841064\n",
      "loss: 0.3059143126010895\n",
      "loss: 0.1645219922065735\n",
      "loss: 0.11183319985866547\n",
      "loss: 0.23007550835609436\n",
      "epoch loss:  1.976865291595459\n",
      "loss: 0.5448818206787109\n",
      "loss: 0.47670218348503113\n",
      "loss: 0.14270378649234772\n",
      "loss: 0.3061501383781433\n",
      "loss: 0.16357070207595825\n",
      "loss: 0.11152288317680359\n",
      "loss: 0.23001523315906525\n",
      "epoch loss:  1.9755468368530273\n",
      "loss: 0.5444484949111938\n",
      "loss: 0.4758124351501465\n",
      "loss: 0.14168335497379303\n",
      "loss: 0.30561622977256775\n",
      "loss: 0.16288477182388306\n",
      "loss: 0.11141949892044067\n",
      "loss: 0.22851882874965668\n",
      "epoch loss:  1.9703835248947144\n",
      "loss: 0.5453610420227051\n",
      "loss: 0.4752104580402374\n",
      "loss: 0.14208029210567474\n",
      "loss: 0.3059241771697998\n",
      "loss: 0.1634940356016159\n",
      "loss: 0.11185064911842346\n",
      "loss: 0.22841136157512665\n",
      "epoch loss:  1.9723318815231323\n",
      "loss: 0.5420752763748169\n",
      "loss: 0.47569039463996887\n",
      "loss: 0.14143672585487366\n",
      "loss: 0.30462905764579773\n",
      "loss: 0.16249269247055054\n",
      "loss: 0.11069223284721375\n",
      "loss: 0.22964122891426086\n",
      "epoch loss:  1.9666576385498047\n",
      "loss: 0.5424066781997681\n",
      "loss: 0.47602859139442444\n",
      "loss: 0.14054803550243378\n",
      "loss: 0.30360618233680725\n",
      "loss: 0.1629079282283783\n",
      "loss: 0.1107795238494873\n",
      "loss: 0.22881361842155457\n",
      "epoch loss:  1.9650905132293701\n",
      "loss: 0.5451382398605347\n",
      "loss: 0.47725990414619446\n",
      "loss: 0.14121386408805847\n",
      "loss: 0.3043243885040283\n",
      "loss: 0.16201242804527283\n",
      "loss: 0.11039604246616364\n",
      "loss: 0.2280118614435196\n",
      "epoch loss:  1.968356728553772\n",
      "loss: 0.5446997880935669\n",
      "loss: 0.4741809368133545\n",
      "loss: 0.14296381175518036\n",
      "loss: 0.3034612238407135\n",
      "loss: 0.16238020360469818\n",
      "loss: 0.11089062690734863\n",
      "loss: 0.22730326652526855\n",
      "epoch loss:  1.9658797979354858\n",
      "loss: 0.5433620810508728\n",
      "loss: 0.4747864007949829\n",
      "loss: 0.1405048966407776\n",
      "loss: 0.30399882793426514\n",
      "loss: 0.16209308803081512\n",
      "loss: 0.11072927713394165\n",
      "loss: 0.22917678952217102\n",
      "epoch loss:  1.964651107788086\n",
      "loss: 0.5434946417808533\n",
      "loss: 0.4762214422225952\n",
      "loss: 0.14014476537704468\n",
      "loss: 0.30285608768463135\n",
      "loss: 0.16192249953746796\n",
      "loss: 0.11059235036373138\n",
      "loss: 0.22869572043418884\n",
      "epoch loss:  1.9639275074005127\n",
      "loss: 0.5452634692192078\n",
      "loss: 0.47457045316696167\n",
      "loss: 0.14113500714302063\n",
      "loss: 0.30339935421943665\n",
      "loss: 0.1613030582666397\n",
      "loss: 0.11021455377340317\n",
      "loss: 0.22815048694610596\n",
      "epoch loss:  1.9640363454818726\n",
      "loss: 0.5398997664451599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.473579466342926\n",
      "loss: 0.14094235002994537\n",
      "loss: 0.3021235167980194\n",
      "loss: 0.16078901290893555\n",
      "loss: 0.11056685447692871\n",
      "loss: 0.2269517481327057\n",
      "epoch loss:  1.9548527002334595\n",
      "loss: 0.542399525642395\n",
      "loss: 0.4732648432254791\n",
      "loss: 0.1400357037782669\n",
      "loss: 0.30183395743370056\n",
      "loss: 0.16107015311717987\n",
      "loss: 0.11056899279356003\n",
      "loss: 0.22587136924266815\n",
      "epoch loss:  1.9550445079803467\n",
      "loss: 0.5439355373382568\n",
      "loss: 0.47389498353004456\n",
      "loss: 0.13965582847595215\n",
      "loss: 0.3011467456817627\n",
      "loss: 0.16022071242332458\n",
      "loss: 0.11009621620178223\n",
      "loss: 0.2267804890871048\n",
      "epoch loss:  1.9557305574417114\n",
      "loss: 0.5435824394226074\n",
      "loss: 0.4724372327327728\n",
      "loss: 0.14056077599525452\n",
      "loss: 0.30120593309402466\n",
      "loss: 0.1610337346792221\n",
      "loss: 0.1098509356379509\n",
      "loss: 0.22633413970470428\n",
      "epoch loss:  1.9550050497055054\n",
      "loss: 0.5388643741607666\n",
      "loss: 0.47180232405662537\n",
      "loss: 0.13909777998924255\n",
      "loss: 0.300655335187912\n",
      "loss: 0.1607562154531479\n",
      "loss: 0.10984116047620773\n",
      "loss: 0.22554078698158264\n",
      "epoch loss:  1.9465579986572266\n",
      "loss: 0.5401126742362976\n",
      "loss: 0.47214722633361816\n",
      "loss: 0.13876530528068542\n",
      "loss: 0.2997884750366211\n",
      "loss: 0.1606769859790802\n",
      "loss: 0.10959922522306442\n",
      "loss: 0.22518980503082275\n",
      "epoch loss:  1.946279764175415\n",
      "loss: 0.5439456105232239\n",
      "loss: 0.47350674867630005\n",
      "loss: 0.13957306742668152\n",
      "loss: 0.30051666498184204\n",
      "loss: 0.159788116812706\n",
      "loss: 0.1099257543683052\n",
      "loss: 0.225305438041687\n",
      "epoch loss:  1.9525614976882935\n",
      "loss: 0.5428899526596069\n",
      "loss: 0.4717646837234497\n",
      "loss: 0.1388586163520813\n",
      "loss: 0.3008585274219513\n",
      "loss: 0.16046999394893646\n",
      "loss: 0.10998715460300446\n",
      "loss: 0.2263101190328598\n",
      "epoch loss:  1.951138973236084\n",
      "loss: 0.5412365198135376\n",
      "loss: 0.47235292196273804\n",
      "loss: 0.1392223834991455\n",
      "loss: 0.299234002828598\n",
      "loss: 0.15962807834148407\n",
      "loss: 0.10986871272325516\n",
      "loss: 0.22646300494670868\n",
      "epoch loss:  1.9480055570602417\n",
      "loss: 0.5407267808914185\n",
      "loss: 0.4717174768447876\n",
      "loss: 0.13862726092338562\n",
      "loss: 0.2990460693836212\n",
      "loss: 0.15949144959449768\n",
      "loss: 0.10958009213209152\n",
      "loss: 0.225080668926239\n",
      "epoch loss:  1.9442696571350098\n",
      "loss: 0.5407627820968628\n",
      "loss: 0.47095000743865967\n",
      "loss: 0.1390252560377121\n",
      "loss: 0.3008279800415039\n",
      "loss: 0.15944230556488037\n",
      "loss: 0.11042077094316483\n",
      "loss: 0.2251521348953247\n",
      "epoch loss:  1.946581244468689\n",
      "loss: 0.5389004945755005\n",
      "loss: 0.47148269414901733\n",
      "loss: 0.13822948932647705\n",
      "loss: 0.29802581667900085\n",
      "loss: 0.15932969748973846\n",
      "loss: 0.10946545749902725\n",
      "loss: 0.22448347508907318\n",
      "epoch loss:  1.9399170875549316\n",
      "loss: 0.5388850569725037\n",
      "loss: 0.4720260798931122\n",
      "loss: 0.13938994705677032\n",
      "loss: 0.2975727319717407\n",
      "loss: 0.15910200774669647\n",
      "loss: 0.10955781489610672\n",
      "loss: 0.22366863489151\n",
      "epoch loss:  1.940202236175537\n",
      "loss: 0.5410098433494568\n",
      "loss: 0.47138112783432007\n",
      "loss: 0.14025653898715973\n",
      "loss: 0.29923978447914124\n",
      "loss: 0.15928617119789124\n",
      "loss: 0.10963006317615509\n",
      "loss: 0.22398225963115692\n",
      "epoch loss:  1.944785714149475\n",
      "loss: 0.540518045425415\n",
      "loss: 0.47121453285217285\n",
      "loss: 0.13853275775909424\n",
      "loss: 0.29872724413871765\n",
      "loss: 0.15953531861305237\n",
      "loss: 0.10869459807872772\n",
      "loss: 0.22424136102199554\n",
      "epoch loss:  1.941463828086853\n",
      "loss: 0.5397449731826782\n",
      "loss: 0.469984769821167\n",
      "loss: 0.13923977315425873\n",
      "loss: 0.29897892475128174\n",
      "loss: 0.15838901698589325\n",
      "loss: 0.10923609137535095\n",
      "loss: 0.2234448939561844\n",
      "epoch loss:  1.9390184879302979\n",
      "loss: 0.5393351316452026\n",
      "loss: 0.4697922468185425\n",
      "loss: 0.13839299976825714\n",
      "loss: 0.29873791337013245\n",
      "loss: 0.15830986201763153\n",
      "loss: 0.10853910446166992\n",
      "loss: 0.22317613661289215\n",
      "epoch loss:  1.9362833499908447\n",
      "loss: 0.5404553413391113\n",
      "loss: 0.46923014521598816\n",
      "loss: 0.13822776079177856\n",
      "loss: 0.29782888293266296\n",
      "loss: 0.15866994857788086\n",
      "loss: 0.1086682379245758\n",
      "loss: 0.22375106811523438\n",
      "epoch loss:  1.9368313550949097\n",
      "loss: 0.5356504321098328\n",
      "loss: 0.4702729880809784\n",
      "loss: 0.13837255537509918\n",
      "loss: 0.2960931956768036\n",
      "loss: 0.1586814522743225\n",
      "loss: 0.10871978849172592\n",
      "loss: 0.22245624661445618\n",
      "epoch loss:  1.9302465915679932\n",
      "loss: 0.5393927693367004\n",
      "loss: 0.47099387645721436\n",
      "loss: 0.13871951401233673\n",
      "loss: 0.2968696355819702\n",
      "loss: 0.15873168408870697\n",
      "loss: 0.10923979431390762\n",
      "loss: 0.2226136177778244\n",
      "epoch loss:  1.9365609884262085\n",
      "loss: 0.5392192006111145\n",
      "loss: 0.4705090820789337\n",
      "loss: 0.13838136196136475\n",
      "loss: 0.29758167266845703\n",
      "loss: 0.15849460661411285\n",
      "loss: 0.109126016497612\n",
      "loss: 0.22263386845588684\n",
      "epoch loss:  1.935945749282837\n",
      "loss: 0.5390321612358093\n",
      "loss: 0.47130462527275085\n",
      "loss: 0.13783971965312958\n",
      "loss: 0.2979185879230499\n",
      "loss: 0.1581578105688095\n",
      "loss: 0.10877925157546997\n",
      "loss: 0.22241775691509247\n",
      "epoch loss:  1.9354497194290161\n",
      "loss: 0.5395619869232178\n",
      "loss: 0.47033634781837463\n",
      "loss: 0.13714292645454407\n",
      "loss: 0.29692792892456055\n",
      "loss: 0.15813006460666656\n",
      "loss: 0.10830777883529663\n",
      "loss: 0.22290319204330444\n",
      "epoch loss:  1.9333102703094482\n",
      "loss: 0.5377490520477295\n",
      "loss: 0.4694925844669342\n",
      "loss: 0.1373165100812912\n",
      "loss: 0.296450674533844\n",
      "loss: 0.1585053652524948\n",
      "loss: 0.1085386723279953\n",
      "loss: 0.22240857779979706\n",
      "epoch loss:  1.9304612874984741\n",
      "loss: 0.5368254780769348\n",
      "loss: 0.4702794849872589\n",
      "loss: 0.13856284320354462\n",
      "loss: 0.29700568318367004\n",
      "loss: 0.15880811214447021\n",
      "loss: 0.108348049223423\n",
      "loss: 0.22171024978160858\n",
      "epoch loss:  1.93153977394104\n",
      "loss: 0.5371200442314148\n",
      "loss: 0.46897390484809875\n",
      "loss: 0.13683940470218658\n",
      "loss: 0.2951962351799011\n",
      "loss: 0.15755003690719604\n",
      "loss: 0.10840652137994766\n",
      "loss: 0.22203025221824646\n",
      "epoch loss:  1.9261165857315063\n",
      "loss: 0.5379106998443604\n",
      "loss: 0.4678671360015869\n",
      "loss: 0.13744007050991058\n",
      "loss: 0.29588234424591064\n",
      "loss: 0.15674342215061188\n",
      "loss: 0.10826709121465683\n",
      "loss: 0.2215472310781479\n",
      "epoch loss:  1.9256579875946045\n",
      "loss: 0.5345348119735718\n",
      "loss: 0.46701258420944214\n",
      "loss: 0.13572216033935547\n",
      "loss: 0.2939457297325134\n",
      "loss: 0.15681850910186768\n",
      "loss: 0.1080879420042038\n",
      "loss: 0.22005389630794525\n",
      "epoch loss:  1.9161756038665771\n",
      "loss: 0.5371653437614441\n",
      "loss: 0.46751412749290466\n",
      "loss: 0.1368909776210785\n",
      "loss: 0.29381608963012695\n",
      "loss: 0.15655462443828583\n",
      "loss: 0.10797736048698425\n",
      "loss: 0.2197919338941574\n",
      "epoch loss:  1.919710397720337\n",
      "loss: 0.5347269177436829\n",
      "loss: 0.46980032324790955\n",
      "loss: 0.1370316445827484\n",
      "loss: 0.29346194863319397\n",
      "loss: 0.15676826238632202\n",
      "loss: 0.10754042863845825\n",
      "loss: 0.22078150510787964\n",
      "epoch loss:  1.9201109409332275\n",
      "loss: 0.5367159247398376\n",
      "loss: 0.4672902226448059\n",
      "loss: 0.13564009964466095\n",
      "loss: 0.2927582263946533\n",
      "loss: 0.15650756657123566\n",
      "loss: 0.10796507447957993\n",
      "loss: 0.2199300229549408\n",
      "epoch loss:  1.9168072938919067\n",
      "loss: 0.5351419448852539\n",
      "loss: 0.46633991599082947\n",
      "loss: 0.13740871846675873\n",
      "loss: 0.2931496798992157\n",
      "loss: 0.15617649257183075\n",
      "loss: 0.10828588902950287\n",
      "loss: 0.22012822329998016\n",
      "epoch loss:  1.9166308641433716\n",
      "loss: 0.5369647145271301\n",
      "loss: 0.4670688211917877\n",
      "loss: 0.13659065961837769\n",
      "loss: 0.2941701412200928\n",
      "loss: 0.15657345950603485\n",
      "loss: 0.10756344348192215\n",
      "loss: 0.2189968228340149\n",
      "epoch loss:  1.9179282188415527\n",
      "loss: 0.5370728969573975\n",
      "loss: 0.4677203893661499\n",
      "loss: 0.13545890152454376\n",
      "loss: 0.2928592264652252\n",
      "loss: 0.15603673458099365\n",
      "loss: 0.10771137475967407\n",
      "loss: 0.21944710612297058\n",
      "epoch loss:  1.916306734085083\n",
      "loss: 0.5355901718139648\n",
      "loss: 0.46799373626708984\n",
      "loss: 0.13574954867362976\n",
      "loss: 0.29101401567459106\n",
      "loss: 0.15565583109855652\n",
      "loss: 0.10786554962396622\n",
      "loss: 0.2193658947944641\n",
      "epoch loss:  1.9132347106933594\n",
      "loss: 0.5363666415214539\n",
      "loss: 0.465694397687912\n",
      "loss: 0.13590680062770844\n",
      "loss: 0.2935824990272522\n",
      "loss: 0.15603096783161163\n",
      "loss: 0.10736572742462158\n",
      "loss: 0.2199925184249878\n",
      "epoch loss:  1.914939522743225\n",
      "loss: 0.5355384349822998\n",
      "loss: 0.46733957529067993\n",
      "loss: 0.1355791836977005\n",
      "loss: 0.292970210313797\n",
      "loss: 0.1561381071805954\n",
      "loss: 0.10747603327035904\n",
      "loss: 0.21886226534843445\n",
      "epoch loss:  1.9139037132263184\n",
      "loss: 0.5349260568618774\n",
      "loss: 0.4659072160720825\n",
      "loss: 0.1352805197238922\n",
      "loss: 0.2924213111400604\n",
      "loss: 0.1551407277584076\n",
      "loss: 0.10717933624982834\n",
      "loss: 0.21910755336284637\n",
      "epoch loss:  1.9099626541137695\n",
      "loss: 0.534500002861023\n",
      "loss: 0.46582409739494324\n",
      "loss: 0.13513220846652985\n",
      "loss: 0.29345011711120605\n",
      "loss: 0.1553686261177063\n",
      "loss: 0.10779743641614914\n",
      "loss: 0.21852171421051025\n",
      "epoch loss:  1.91059410572052\n",
      "loss: 0.5348092913627625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.4650704562664032\n",
      "loss: 0.13633038103580475\n",
      "loss: 0.2904833257198334\n",
      "loss: 0.15488216280937195\n",
      "loss: 0.10741567611694336\n",
      "loss: 0.21837854385375977\n",
      "epoch loss:  1.90736985206604\n",
      "loss: 0.534217119216919\n",
      "loss: 0.46385717391967773\n",
      "loss: 0.13484002649784088\n",
      "loss: 0.2917906939983368\n",
      "loss: 0.1548757553100586\n",
      "loss: 0.10643579065799713\n",
      "loss: 0.21769143640995026\n",
      "epoch loss:  1.9037079811096191\n",
      "loss: 0.5345015525817871\n",
      "loss: 0.4633285701274872\n",
      "loss: 0.13624247908592224\n",
      "loss: 0.29008492827415466\n",
      "loss: 0.15404626727104187\n",
      "loss: 0.1072128638625145\n",
      "loss: 0.21721157431602478\n",
      "epoch loss:  1.9026284217834473\n",
      "loss: 0.5323505401611328\n",
      "loss: 0.4649980366230011\n",
      "loss: 0.1346813589334488\n",
      "loss: 0.2895457148551941\n",
      "loss: 0.1547623872756958\n",
      "loss: 0.10704650729894638\n",
      "loss: 0.21718449890613556\n",
      "epoch loss:  1.900568962097168\n",
      "loss: 0.534225583076477\n",
      "loss: 0.46395188570022583\n",
      "loss: 0.13519519567489624\n",
      "loss: 0.28953778743743896\n",
      "loss: 0.15458105504512787\n",
      "loss: 0.10723628103733063\n",
      "loss: 0.21746936440467834\n",
      "epoch loss:  1.9021971225738525\n",
      "loss: 0.530045211315155\n",
      "loss: 0.4644794166088104\n",
      "loss: 0.13494272530078888\n",
      "loss: 0.28916916251182556\n",
      "loss: 0.1545766144990921\n",
      "loss: 0.10658147931098938\n",
      "loss: 0.2163846343755722\n",
      "epoch loss:  1.8961793184280396\n",
      "loss: 0.5312916040420532\n",
      "loss: 0.462368905544281\n",
      "loss: 0.13393214344978333\n",
      "loss: 0.28923481702804565\n",
      "loss: 0.15294726192951202\n",
      "loss: 0.1065661758184433\n",
      "loss: 0.21715091168880463\n",
      "epoch loss:  1.8934918642044067\n",
      "loss: 0.5338128209114075\n",
      "loss: 0.46291306614875793\n",
      "loss: 0.13482734560966492\n",
      "loss: 0.2880954146385193\n",
      "loss: 0.15315116941928864\n",
      "loss: 0.10652980208396912\n",
      "loss: 0.21627968549728394\n",
      "epoch loss:  1.8956093788146973\n",
      "loss: 0.5313510298728943\n",
      "loss: 0.4623020887374878\n",
      "loss: 0.13390913605690002\n",
      "loss: 0.2885339558124542\n",
      "loss: 0.15330994129180908\n",
      "loss: 0.10588131844997406\n",
      "loss: 0.2166614681482315\n",
      "epoch loss:  1.891948938369751\n",
      "loss: 0.532172679901123\n",
      "loss: 0.4633466601371765\n",
      "loss: 0.1344843953847885\n",
      "loss: 0.28794148564338684\n",
      "loss: 0.1534910798072815\n",
      "loss: 0.10652493685483932\n",
      "loss: 0.21592645347118378\n",
      "epoch loss:  1.8938875198364258\n",
      "loss: 0.5315998792648315\n",
      "loss: 0.46433162689208984\n",
      "loss: 0.1342177391052246\n",
      "loss: 0.2890733778476715\n",
      "loss: 0.15366557240486145\n",
      "loss: 0.10622483491897583\n",
      "loss: 0.21672624349594116\n",
      "epoch loss:  1.8958392143249512\n",
      "loss: 0.5354223251342773\n",
      "loss: 0.4622840881347656\n",
      "loss: 0.13421331346035004\n",
      "loss: 0.28828534483909607\n",
      "loss: 0.15344475209712982\n",
      "loss: 0.10632907599210739\n",
      "loss: 0.2155047506093979\n",
      "epoch loss:  1.8954837322235107\n",
      "loss: 0.5338726043701172\n",
      "loss: 0.46373021602630615\n",
      "loss: 0.13459326326847076\n",
      "loss: 0.28980934619903564\n",
      "loss: 0.1537027657032013\n",
      "loss: 0.10606596618890762\n",
      "loss: 0.21597133576869965\n",
      "epoch loss:  1.8977454900741577\n",
      "loss: 0.529690146446228\n",
      "loss: 0.46103039383888245\n",
      "loss: 0.1340935230255127\n",
      "loss: 0.2871609330177307\n",
      "loss: 0.15309175848960876\n",
      "loss: 0.10581284761428833\n",
      "loss: 0.21503543853759766\n",
      "epoch loss:  1.8859150409698486\n",
      "loss: 0.5294703841209412\n",
      "loss: 0.46354565024375916\n",
      "loss: 0.13282953202724457\n",
      "loss: 0.28641536831855774\n",
      "loss: 0.15300467610359192\n",
      "loss: 0.10597652941942215\n",
      "loss: 0.2146446406841278\n",
      "epoch loss:  1.885886788368225\n",
      "loss: 0.5308297276496887\n",
      "loss: 0.46056506037712097\n",
      "loss: 0.13322579860687256\n",
      "loss: 0.2860337495803833\n",
      "loss: 0.15322475135326385\n",
      "loss: 0.10567231476306915\n",
      "loss: 0.21449804306030273\n",
      "epoch loss:  1.884049415588379\n",
      "loss: 0.5298075079917908\n",
      "loss: 0.4610264301300049\n",
      "loss: 0.13441921770572662\n",
      "loss: 0.2873867452144623\n",
      "loss: 0.15239514410495758\n",
      "loss: 0.10632365942001343\n",
      "loss: 0.21431873738765717\n",
      "epoch loss:  1.8856775760650635\n",
      "loss: 0.5304062962532043\n",
      "loss: 0.46131524443626404\n",
      "loss: 0.13435016572475433\n",
      "loss: 0.2860909104347229\n",
      "loss: 0.1530853509902954\n",
      "loss: 0.10591887682676315\n",
      "loss: 0.214241161942482\n",
      "epoch loss:  1.8854079246520996\n",
      "loss: 0.5301512479782104\n",
      "loss: 0.4611583948135376\n",
      "loss: 0.13262292742729187\n",
      "loss: 0.2853389084339142\n",
      "loss: 0.15199927985668182\n",
      "loss: 0.10632062703371048\n",
      "loss: 0.21405521035194397\n",
      "epoch loss:  1.8816465139389038\n",
      "loss: 0.5280658602714539\n",
      "loss: 0.46074217557907104\n",
      "loss: 0.13305194675922394\n",
      "loss: 0.2856804132461548\n",
      "loss: 0.15214420855045319\n",
      "loss: 0.10579158365726471\n",
      "loss: 0.21454495191574097\n",
      "epoch loss:  1.880021095275879\n",
      "loss: 0.528723418712616\n",
      "loss: 0.4594804048538208\n",
      "loss: 0.13267353177070618\n",
      "loss: 0.2858446538448334\n",
      "loss: 0.15202374756336212\n",
      "loss: 0.10555648803710938\n",
      "loss: 0.21214254200458527\n",
      "epoch loss:  1.876444935798645\n",
      "loss: 0.5306695103645325\n",
      "loss: 0.460222989320755\n",
      "loss: 0.13265103101730347\n",
      "loss: 0.285124272108078\n",
      "loss: 0.15183530747890472\n",
      "loss: 0.10508598387241364\n",
      "loss: 0.21293754875659943\n",
      "epoch loss:  1.8785266876220703\n",
      "loss: 0.5278794765472412\n",
      "loss: 0.46033236384391785\n",
      "loss: 0.1320171058177948\n",
      "loss: 0.28464916348457336\n",
      "loss: 0.1516888290643692\n",
      "loss: 0.10560049116611481\n",
      "loss: 0.2129276692867279\n",
      "epoch loss:  1.8750951290130615\n",
      "loss: 0.5297737121582031\n",
      "loss: 0.4606344401836395\n",
      "loss: 0.13105355203151703\n",
      "loss: 0.28438395261764526\n",
      "loss: 0.15093831717967987\n",
      "loss: 0.10554991662502289\n",
      "loss: 0.21181777119636536\n",
      "epoch loss:  1.874151587486267\n",
      "loss: 0.5299361348152161\n",
      "loss: 0.45937681198120117\n",
      "loss: 0.13188017904758453\n",
      "loss: 0.2830330431461334\n",
      "loss: 0.15048213303089142\n",
      "loss: 0.1051383838057518\n",
      "loss: 0.2123621255159378\n",
      "epoch loss:  1.8722089529037476\n",
      "loss: 0.5257856845855713\n",
      "loss: 0.45920467376708984\n",
      "loss: 0.13092678785324097\n",
      "loss: 0.28329673409461975\n",
      "loss: 0.15097534656524658\n",
      "loss: 0.10484790056943893\n",
      "loss: 0.21121998131275177\n",
      "epoch loss:  1.8662571907043457\n",
      "loss: 0.5273435115814209\n",
      "loss: 0.458186537027359\n",
      "loss: 0.1303287297487259\n",
      "loss: 0.2849230468273163\n",
      "loss: 0.15056444704532623\n",
      "loss: 0.10503137856721878\n",
      "loss: 0.2123231738805771\n",
      "epoch loss:  1.8687008619308472\n",
      "loss: 0.5271459817886353\n",
      "loss: 0.4599728286266327\n",
      "loss: 0.13175299763679504\n",
      "loss: 0.28366997838020325\n",
      "loss: 0.15076425671577454\n",
      "loss: 0.10558965802192688\n",
      "loss: 0.2110062539577484\n",
      "epoch loss:  1.8699018955230713\n",
      "loss: 0.5269801616668701\n",
      "loss: 0.4586363136768341\n",
      "loss: 0.13015912473201752\n",
      "loss: 0.282015323638916\n",
      "loss: 0.15023525059223175\n",
      "loss: 0.10534413903951645\n",
      "loss: 0.2105380892753601\n",
      "epoch loss:  1.8639085292816162\n",
      "loss: 0.5269460678100586\n",
      "loss: 0.45716848969459534\n",
      "loss: 0.13114793598651886\n",
      "loss: 0.28328806161880493\n",
      "loss: 0.15030941367149353\n",
      "loss: 0.10534632205963135\n",
      "loss: 0.2105197310447693\n",
      "epoch loss:  1.8647260665893555\n",
      "loss: 0.5263298153877258\n",
      "loss: 0.4586489200592041\n",
      "loss: 0.1312122792005539\n",
      "loss: 0.28220468759536743\n",
      "loss: 0.1501103937625885\n",
      "loss: 0.10409948229789734\n",
      "loss: 0.21232302486896515\n",
      "epoch loss:  1.8649287223815918\n",
      "loss: 0.5275281071662903\n",
      "loss: 0.4582565724849701\n",
      "loss: 0.13039202988147736\n",
      "loss: 0.28319936990737915\n",
      "loss: 0.15041789412498474\n",
      "loss: 0.1048268973827362\n",
      "loss: 0.2105577141046524\n",
      "epoch loss:  1.8651787042617798\n",
      "loss: 0.5265003442764282\n",
      "loss: 0.4582308530807495\n",
      "loss: 0.13045090436935425\n",
      "loss: 0.2828728258609772\n",
      "loss: 0.1501101404428482\n",
      "loss: 0.1043015718460083\n",
      "loss: 0.21035617589950562\n",
      "epoch loss:  1.8628227710723877\n",
      "loss: 0.5270823836326599\n",
      "loss: 0.45909276604652405\n",
      "loss: 0.131456658244133\n",
      "loss: 0.28164398670196533\n",
      "loss: 0.15070688724517822\n",
      "loss: 0.10466795414686203\n",
      "loss: 0.21077372133731842\n",
      "epoch loss:  1.8654242753982544\n",
      "loss: 0.528014063835144\n",
      "loss: 0.4601619243621826\n",
      "loss: 0.1319567710161209\n",
      "loss: 0.28328949213027954\n",
      "loss: 0.15046793222427368\n",
      "loss: 0.10483488440513611\n",
      "loss: 0.2108444720506668\n",
      "epoch loss:  1.8695696592330933\n",
      "loss: 0.5289983749389648\n",
      "loss: 0.4587606191635132\n",
      "loss: 0.13223320245742798\n",
      "loss: 0.2814176082611084\n",
      "loss: 0.1504671573638916\n",
      "loss: 0.10507411509752274\n",
      "loss: 0.21158944070339203\n",
      "epoch loss:  1.868540644645691\n",
      "loss: 0.5287748575210571\n",
      "loss: 0.4594232439994812\n",
      "loss: 0.13338974118232727\n",
      "loss: 0.2825171649456024\n",
      "loss: 0.15076783299446106\n",
      "loss: 0.10564549267292023\n",
      "loss: 0.21159623563289642\n",
      "epoch loss:  1.872114658355713\n",
      "loss: 0.5287769436836243\n",
      "loss: 0.4586236774921417\n",
      "loss: 0.13138411939144135\n",
      "loss: 0.28192150592803955\n",
      "loss: 0.1511402726173401\n",
      "loss: 0.1053861454129219\n",
      "loss: 0.21043600142002106\n",
      "epoch loss:  1.867668628692627\n",
      "loss: 0.5256510376930237\n",
      "loss: 0.4576185643672943\n",
      "loss: 0.13010667264461517\n",
      "loss: 0.2813563942909241\n",
      "loss: 0.14948239922523499\n",
      "loss: 0.10417129099369049\n",
      "loss: 0.20932382345199585\n",
      "epoch loss:  1.8577101230621338\n",
      "loss: 0.524620771408081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.4568825662136078\n",
      "loss: 0.13041217625141144\n",
      "loss: 0.2801719903945923\n",
      "loss: 0.14867718517780304\n",
      "loss: 0.10400459170341492\n",
      "loss: 0.20912981033325195\n",
      "epoch loss:  1.8538992404937744\n",
      "loss: 0.5246441960334778\n",
      "loss: 0.45662403106689453\n",
      "loss: 0.13032843172550201\n",
      "loss: 0.27985191345214844\n",
      "loss: 0.14917799830436707\n",
      "loss: 0.10442136973142624\n",
      "loss: 0.20931361615657806\n",
      "epoch loss:  1.854361653327942\n",
      "loss: 0.5284889936447144\n",
      "loss: 0.4586355984210968\n",
      "loss: 0.1302054226398468\n",
      "loss: 0.281062513589859\n",
      "loss: 0.14953386783599854\n",
      "loss: 0.10394299775362015\n",
      "loss: 0.2100769728422165\n",
      "epoch loss:  1.8619462251663208\n",
      "loss: 0.5268982648849487\n",
      "loss: 0.4567541778087616\n",
      "loss: 0.130122572183609\n",
      "loss: 0.28115570545196533\n",
      "loss: 0.15042632818222046\n",
      "loss: 0.1044456884264946\n",
      "loss: 0.2097441405057907\n",
      "epoch loss:  1.8595467805862427\n",
      "loss: 0.5254129767417908\n",
      "loss: 0.4560297727584839\n",
      "loss: 0.13114707171916962\n",
      "loss: 0.27973511815071106\n",
      "loss: 0.14971676468849182\n",
      "loss: 0.1040036678314209\n",
      "loss: 0.209462970495224\n",
      "epoch loss:  1.8555083274841309\n",
      "loss: 0.5255413055419922\n",
      "loss: 0.45712214708328247\n",
      "loss: 0.1299019306898117\n",
      "loss: 0.27831050753593445\n",
      "loss: 0.14898405969142914\n",
      "loss: 0.10367526113986969\n",
      "loss: 0.20764265954494476\n",
      "epoch loss:  1.8511779308319092\n",
      "loss: 0.5226868391036987\n",
      "loss: 0.45513635873794556\n",
      "loss: 0.12957650423049927\n",
      "loss: 0.27871859073638916\n",
      "loss: 0.14873453974723816\n",
      "loss: 0.10404673963785172\n",
      "loss: 0.2079860419034958\n",
      "epoch loss:  1.8468855619430542\n",
      "loss: 0.5247857570648193\n",
      "loss: 0.4552779495716095\n",
      "loss: 0.12873688340187073\n",
      "loss: 0.2790576219558716\n",
      "loss: 0.1480528861284256\n",
      "loss: 0.10367245972156525\n",
      "loss: 0.20745553076267242\n",
      "epoch loss:  1.8470391035079956\n",
      "loss: 0.524803638458252\n",
      "loss: 0.45644065737724304\n",
      "loss: 0.12923745810985565\n",
      "loss: 0.27901431918144226\n",
      "loss: 0.14852777123451233\n",
      "loss: 0.10373754799365997\n",
      "loss: 0.20875747501850128\n",
      "epoch loss:  1.8505189418792725\n",
      "loss: 0.5287026166915894\n",
      "loss: 0.4550986886024475\n",
      "loss: 0.12840192019939423\n",
      "loss: 0.2784882187843323\n",
      "loss: 0.14771497249603271\n",
      "loss: 0.10336232930421829\n",
      "loss: 0.20884400606155396\n",
      "epoch loss:  1.8506128787994385\n",
      "loss: 0.5246568322181702\n",
      "loss: 0.45537400245666504\n",
      "loss: 0.12962451577186584\n",
      "loss: 0.27726274728775024\n",
      "loss: 0.14729635417461395\n",
      "loss: 0.1032402440905571\n",
      "loss: 0.20722545683383942\n",
      "epoch loss:  1.8446800708770752\n",
      "loss: 0.5245584845542908\n",
      "loss: 0.45407748222351074\n",
      "loss: 0.12783946096897125\n",
      "loss: 0.2768169939517975\n",
      "loss: 0.14768028259277344\n",
      "loss: 0.10287769138813019\n",
      "loss: 0.20634394884109497\n",
      "epoch loss:  1.8401944637298584\n",
      "loss: 0.5235456228256226\n",
      "loss: 0.45447975397109985\n",
      "loss: 0.1282159984111786\n",
      "loss: 0.27793633937835693\n",
      "loss: 0.14692874252796173\n",
      "loss: 0.10267243534326553\n",
      "loss: 0.20616930723190308\n",
      "epoch loss:  1.8399481773376465\n",
      "loss: 0.5276933312416077\n",
      "loss: 0.45439890027046204\n",
      "loss: 0.1277725100517273\n",
      "loss: 0.276167631149292\n",
      "loss: 0.14687670767307281\n",
      "loss: 0.10286907851696014\n",
      "loss: 0.2054835706949234\n",
      "epoch loss:  1.841261625289917\n",
      "loss: 0.524061381816864\n",
      "loss: 0.45353931188583374\n",
      "loss: 0.12847892940044403\n",
      "loss: 0.2772340774536133\n",
      "loss: 0.14656539261341095\n",
      "loss: 0.10251753777265549\n",
      "loss: 0.20537258684635162\n",
      "epoch loss:  1.8377691507339478\n",
      "loss: 0.5228031277656555\n",
      "loss: 0.45384788513183594\n",
      "loss: 0.1277109980583191\n",
      "loss: 0.27664297819137573\n",
      "loss: 0.1470831036567688\n",
      "loss: 0.10227024555206299\n",
      "loss: 0.2058386504650116\n",
      "epoch loss:  1.836197018623352\n",
      "loss: 0.5220082402229309\n",
      "loss: 0.45309582352638245\n",
      "loss: 0.12727618217468262\n",
      "loss: 0.27576276659965515\n",
      "loss: 0.14618046581745148\n",
      "loss: 0.10213658958673477\n",
      "loss: 0.20500843226909637\n",
      "epoch loss:  1.8314685821533203\n",
      "loss: 0.5214483141899109\n",
      "loss: 0.45193666219711304\n",
      "loss: 0.12753677368164062\n",
      "loss: 0.27543970942497253\n",
      "loss: 0.1460997462272644\n",
      "loss: 0.102659672498703\n",
      "loss: 0.20600251853466034\n",
      "epoch loss:  1.8311233520507812\n",
      "loss: 0.5204706788063049\n",
      "loss: 0.4528624415397644\n",
      "loss: 0.12738434970378876\n",
      "loss: 0.2747254967689514\n",
      "loss: 0.14581015706062317\n",
      "loss: 0.10227786004543304\n",
      "loss: 0.20402976870536804\n",
      "epoch loss:  1.8275607824325562\n",
      "loss: 0.5210559368133545\n",
      "loss: 0.4541890025138855\n",
      "loss: 0.12664923071861267\n",
      "loss: 0.2757396996021271\n",
      "loss: 0.14582473039627075\n",
      "loss: 0.10176440328359604\n",
      "loss: 0.20520351827144623\n",
      "epoch loss:  1.8304264545440674\n",
      "loss: 0.5196363925933838\n",
      "loss: 0.45229125022888184\n",
      "loss: 0.12653641402721405\n",
      "loss: 0.27496686577796936\n",
      "loss: 0.14570358395576477\n",
      "loss: 0.10201867669820786\n",
      "loss: 0.20378541946411133\n",
      "epoch loss:  1.8249385356903076\n",
      "loss: 0.5248191952705383\n",
      "loss: 0.4525626003742218\n",
      "loss: 0.12688753008842468\n",
      "loss: 0.2744022011756897\n",
      "loss: 0.14590997993946075\n",
      "loss: 0.10221042484045029\n",
      "loss: 0.20561984181404114\n",
      "epoch loss:  1.8324118852615356\n",
      "loss: 0.5208646655082703\n",
      "loss: 0.4518033266067505\n",
      "loss: 0.12736876308918\n",
      "loss: 0.27360999584198\n",
      "loss: 0.14556077122688293\n",
      "loss: 0.10205824673175812\n",
      "loss: 0.20310012996196747\n",
      "epoch loss:  1.8243658542633057\n",
      "loss: 0.5219442844390869\n",
      "loss: 0.45060378313064575\n",
      "loss: 0.12609517574310303\n",
      "loss: 0.2742707431316376\n",
      "loss: 0.14523930847644806\n",
      "loss: 0.10193777829408646\n",
      "loss: 0.20373909175395966\n",
      "epoch loss:  1.823830246925354\n",
      "loss: 0.5212780237197876\n",
      "loss: 0.4511287212371826\n",
      "loss: 0.1259855180978775\n",
      "loss: 0.2744198441505432\n",
      "loss: 0.14471405744552612\n",
      "loss: 0.10174726694822311\n",
      "loss: 0.20315198600292206\n",
      "epoch loss:  1.822425365447998\n",
      "loss: 0.518179714679718\n",
      "loss: 0.45165812969207764\n",
      "loss: 0.1256757527589798\n",
      "loss: 0.2742583751678467\n",
      "loss: 0.1446385532617569\n",
      "loss: 0.1017586961388588\n",
      "loss: 0.20332805812358856\n",
      "epoch loss:  1.8194972276687622\n",
      "loss: 0.5245023965835571\n",
      "loss: 0.4517410099506378\n",
      "loss: 0.1260693073272705\n",
      "loss: 0.27351540327072144\n",
      "loss: 0.14457395672798157\n",
      "loss: 0.1018570214509964\n",
      "loss: 0.2026519477367401\n",
      "epoch loss:  1.8249109983444214\n",
      "loss: 0.519048810005188\n",
      "loss: 0.452315092086792\n",
      "loss: 0.12567490339279175\n",
      "loss: 0.27372246980667114\n",
      "loss: 0.1445624679327011\n",
      "loss: 0.10180480033159256\n",
      "loss: 0.20241183042526245\n",
      "epoch loss:  1.81954026222229\n",
      "loss: 0.5189228653907776\n",
      "loss: 0.44997960329055786\n",
      "loss: 0.1259789764881134\n",
      "loss: 0.27251115441322327\n",
      "loss: 0.14456668496131897\n",
      "loss: 0.10172370076179504\n",
      "loss: 0.2032007873058319\n",
      "epoch loss:  1.8168836832046509\n",
      "loss: 0.518906831741333\n",
      "loss: 0.4490763545036316\n",
      "loss: 0.1250024139881134\n",
      "loss: 0.2730419933795929\n",
      "loss: 0.14396734535694122\n",
      "loss: 0.10089128464460373\n",
      "loss: 0.201547309756279\n",
      "epoch loss:  1.8124334812164307\n"
     ]
    }
   ],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "\n",
    "new_data = new_data.detach().transpose(1,2)\n",
    "for i in range(500):\n",
    "    losses = 0\n",
    "    for x, y in zip(new_data, labels):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x.unsqueeze(0))\n",
    "        loss = loss_function(outputs, x)\n",
    "        print(\"loss: \" + str(loss.item()))\n",
    "        losses += loss\n",
    "    losses.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    print(\"epoch loss: \", str(losses.item()))\n",
    "    if losses < .001:\n",
    "        break\n",
    "\n",
    "        '''        \n",
    "for x, y in zip(new_data, labels):\n",
    "    print(np.argmax(model(x.view(2500,768)).detach().numpy(), axis=1))\n",
    "    print(y.detach().numpy())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model/transformer_768.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForNextSentencePrediction\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')\n",
    "\n",
    "prompt = \"In Italy, pizza served in formal settings, such as at a restaurant, is presented unsliced.\"\n",
    "next_sentence = \"The sky is blue due to the shorter wavelength of blue light.\"\n",
    "encoding = tokenizer(prompt, next_sentence, return_tensors='pt')\n",
    "\n",
    "outputs = model(**encoding, labels=torch.LongTensor([1]))\n",
    "logits = outputs.logits\n",
    "#assert logits[0, 0] < logits[0, 1] # next sentence was random\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'pad_token': 1} not recognized.\n",
      "Keyword arguments {'pad_token': 1} not recognized.\n",
      "Keyword arguments {'pad_token': 1} not recognized.\n",
      "Keyword arguments {'pad_token': 1} not recognized.\n",
      "Keyword arguments {'pad_token': 1} not recognized.\n",
      "Keyword arguments {'pad_token': 1} not recognized.\n",
      "Keyword arguments {'pad_token': 1} not recognized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(42.4789, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "ename": "ModuleAttributeError",
     "evalue": "'GPT2LMHeadModel' object has no attribute 'logits'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-e5e4bb09b885>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    777\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 779\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleAttributeError\u001b[0m: 'GPT2LMHeadModel' object has no attribute 'logits'"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "\n",
    "# define tokenizer and model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# preprocess training labels and tokenize\n",
    "train_labels = list(waveform_lead_rhythm_diag['diagnosis'])\n",
    "inputs = tokenizer(train_labels, padding = True, pad_token = tokenizer.add_special_tokens({'pad_token': '[PAD]'}), verbose = False, return_tensors=\"pt\")\n",
    "\n",
    "# adjust model parameters to account for padding token\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "for i in range(epochs):\n",
    "#model_gpt2DoubleHeadsModel.resize_token_embeddings(len(gpt2_tokenizer))\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(**inputs, labels = inputs[\"input_ids\"])\n",
    "    loss = outputs.loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(loss)\n",
    "    \n",
    "logits = model.logits\n",
    "print(np.argmax(logits[0].detach().numpy(), axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4 - Cohesive 1 Wrapper Transformer Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5 - FNET/Basic Mixup Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
